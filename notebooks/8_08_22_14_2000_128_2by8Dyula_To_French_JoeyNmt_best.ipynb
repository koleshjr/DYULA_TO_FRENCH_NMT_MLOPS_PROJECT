{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lE5vaHavqkE",
        "outputId": "ec658925-1a38-429a-fbd7-2a7b5a89919c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: joeynmt==2.3.0 in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (1.0.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (9.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (1.26.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (71.0.4)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (2.3.1+cu121)\n",
            "Requirement already satisfied: protobuf<3.21,>=3.19.4 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (3.20.3)\n",
            "Requirement already satisfied: tensorboard>=1.15 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (2.17.0)\n",
            "Requirement already satisfied: sacrebleu>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (2.4.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (0.1.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (0.1.99)\n",
            "Requirement already satisfied: subword-nmt in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (0.3.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (0.13.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (6.0.2)\n",
            "Requirement already satisfied: six>=1.12 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (1.16.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (1.16.0)\n",
            "Requirement already satisfied: pylint in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (3.2.6)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (0.40.2)\n",
            "Requirement already satisfied: flake8 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (7.1.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (7.4.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (2.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (24.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (5.15.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.3.0) (2.1.4)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->joeynmt==2.3.0) (2.10.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->joeynmt==2.3.0) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->joeynmt==2.3.0) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->joeynmt==2.3.0) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->joeynmt==2.3.0) (4.9.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->joeynmt==2.3.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->joeynmt==2.3.0) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->joeynmt==2.3.0) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->joeynmt==2.3.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->joeynmt==2.3.0) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (2024.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.3.0) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.12.0->joeynmt==2.3.0) (12.6.20)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->joeynmt==2.3.0) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->joeynmt==2.3.0) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->joeynmt==2.3.0) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->joeynmt==2.3.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->joeynmt==2.3.0) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->joeynmt==2.3.0) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->joeynmt==2.3.0) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->joeynmt==2.3.0) (3.10.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets->joeynmt==2.3.0) (0.23.5)\n",
            "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from flake8->joeynmt==2.3.0) (0.7.0)\n",
            "Requirement already satisfied: pycodestyle<2.13.0,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from flake8->joeynmt==2.3.0) (2.12.1)\n",
            "Requirement already satisfied: pyflakes<3.3.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from flake8->joeynmt==2.3.0) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->joeynmt==2.3.0) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->joeynmt==2.3.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->joeynmt==2.3.0) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->joeynmt==2.3.0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->joeynmt==2.3.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->joeynmt==2.3.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->joeynmt==2.3.0) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->joeynmt==2.3.0) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->joeynmt==2.3.0) (9.0.0)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pylint->joeynmt==2.3.0) (4.2.2)\n",
            "Requirement already satisfied: astroid<=3.3.0-dev0,>=3.2.4 in /usr/local/lib/python3.10/dist-packages (from pylint->joeynmt==2.3.0) (3.2.4)\n",
            "Requirement already satisfied: isort!=5.13.0,<6,>=4.2.5 in /usr/local/lib/python3.10/dist-packages (from pylint->joeynmt==2.3.0) (5.13.2)\n",
            "Requirement already satisfied: tomlkit>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from pylint->joeynmt==2.3.0) (0.13.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pylint->joeynmt==2.3.0) (2.0.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->joeynmt==2.3.0) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->joeynmt==2.3.0) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->joeynmt==2.3.0) (1.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->joeynmt==2.3.0) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->joeynmt==2.3.0) (1.4.2)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.10/dist-packages (from subword-nmt->joeynmt==2.3.0) (5.1.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->joeynmt==2.3.0) (8.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->joeynmt==2.3.0) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->joeynmt==2.3.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->joeynmt==2.3.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->joeynmt==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->joeynmt==2.3.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->joeynmt==2.3.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->joeynmt==2.3.0) (4.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->joeynmt==2.3.0) (3.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->joeynmt==2.3.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->joeynmt==2.3.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->joeynmt==2.3.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->joeynmt==2.3.0) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=1.15->joeynmt==2.3.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->joeynmt==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.10.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.5.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install joeynmt==2.3.0\n",
        "!pip install sacrebleu\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzNeqk_AxQ5d"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import torch\n",
        "from datasets import load_dataset, DatasetDict, Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452,
          "referenced_widgets": [
            "86cbb6199ac846b5861864442270b806",
            "69bb9ccecf6f4dc39e95afc53b064808",
            "d2a9aa16a0954a70b069da16f22d75a1",
            "e68e0ca02cc04a9689fc5a6b8159a0b0",
            "7df9b6cfb56b480c8e8830fe159eab72",
            "bc9977e85e2044c389cf494bfd2e8e10",
            "dccc0e8f2a0142eda729369cb77a4052",
            "dcdd4e34a03e462296e7c19448a09b24",
            "373f924c5e7c4571b5d2924f3dd6e0e2",
            "24addc98f168445d8cb78615e46e17b9",
            "6f36ac6d938f4622a1db82540d4ade79",
            "ae079020874c4143ac2c91e81b7faa96",
            "e6bf4795f6984148938b5c9ea12fc2bb",
            "3647bc3efc254a20b53c1d7ce24d615a",
            "4db51b73bb6b4e97aa4b44274a46c6d7",
            "da759690f2124d43bd2e35accaf42ddb",
            "1f77d9504e69459bbbb44235d690b759",
            "4893f3c1154343e5a6015440cfde2927",
            "b399fd9d8ceb4a7f9a4daf53afeffacb",
            "db16357f666645be97a15853183acfdd",
            "a44407b5aedc41f7adc35b72abc4d073",
            "91583a4064334fd99f0454ac88dd1e37",
            "3edb51310aa04a29b713236f5f005831",
            "e810a4cdfca043878721bcd7b38d33bd",
            "426a3c81b39b4428bb355be1f4b77e40",
            "8816f715061d48ef9e563442dd73d913",
            "dd89f762cd3a46baa14d36f79c9a2183",
            "630e98380a0b493b9a4c34dc5322dd89",
            "2fed48365faf4feba1f441d7f77d59ad",
            "071b00ee9b784232a68e7b35b3939d4a",
            "4427de5f34e94bc28b97b72e7b62acdc",
            "81725190ebfb47a39f3c0d69b6a3bc4c",
            "4526b28abb194675bbb7ce410b1cef46",
            "623a038d4e92438699a13844e617e453",
            "3d1960f96ac348159f625044d3cea888",
            "8e901e515d3843898462ee1d83b42875",
            "e352b51563d64e4fb748cdbbcc625e51",
            "35017c855e7448d89485bdda5755b06e",
            "0d8ecbfa860b4ee79a8926bf9ef5f2a7",
            "3bfc7b87c278422f8c6e446e8276cae6",
            "573bd90b1b944cfca0a0fe1ddb463a1d",
            "eff289ef73294778adbbf82d10ae4308",
            "c51d04ec8a9e464793980f8aee69e2ba",
            "d207c6d2fa7d4203bb04a190d474f00c",
            "33d693b5c9714c0da9f175a3c9a9c794",
            "e0ac7bd53caa4e319d7454f6c5aa9447",
            "2dbf0a4b3e0045a3b2fe6e9f941c42fb",
            "65f83541b6c74adba1311b3eb7f3179b",
            "6729822c2b34464eb2d28b30e6e83b86",
            "99cf1c76dcec48c4bed435757a1b7338",
            "387dec4d234f45af8a02cd067932cc79",
            "e6e167671e2145c2a9e283acb8ceeb16",
            "94087d97c42543bb86f5e7be5a7ad80d",
            "28e04156d2f54a41922e4ad7d7afc99d",
            "a01d986036214cac9f7989ec49d19893",
            "2e29e09b9ad749f5b66707e028684611",
            "c4dbd12987bf496c9f00157b05564099",
            "e0443c2722b5469b9f00eaca30e9fa9f",
            "5d312dcb91e04cdeb6d7e4a4b78c2eda",
            "1117d668a4684f65b536624a1f4e3106",
            "d116fa0e2e7141fd85404e193e2561ec",
            "7751aee579914082bab027e87b665e66",
            "ff411ac53e9a4f0eaba98eacbc33ec0c",
            "94a3a1b8455c411687321bedcf7aa342",
            "847adcc5cd2f4db0a34b60514716f5a8",
            "86755e977ea94e4f912e8c36e2b4e5da"
          ]
        },
        "id": "C5NiWolAwDPH",
        "outputId": "c083f00e-ab22-4190-f745-89b5409ee7b8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/530k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86cbb6199ac846b5861864442270b806"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/102k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae079020874c4143ac2c91e81b7faa96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/55.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3edb51310aa04a29b713236f5f005831"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/8065 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "623a038d4e92438699a13844e617e453"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1471 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33d693b5c9714c0da9f175a3c9a9c794"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1393 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e29e09b9ad749f5b66707e028684611"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['ID', 'translation'],\n",
              "        num_rows: 8065\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['ID', 'translation'],\n",
              "        num_rows: 1471\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['ID', 'translation'],\n",
              "        num_rows: 1393\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "repo_name = \"data354/Koumankan_mt_dyu_fr\"\n",
        "dataset = load_dataset(repo_name)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356,
          "referenced_widgets": [
            "fa15cfc20a894267a4841aa955b03ae1",
            "ba47051858564a199e6fd093d348642b",
            "64bc479d01974ce7ae345f216827cd50",
            "6b29e289b162455880fd15f405203c1c",
            "f791aa5f5b114ef192f44873ecb19786",
            "36977cb95f044eb398561dc83cf1409a",
            "79791f011a1b4abbb4201c2a0ec1bd3f",
            "0b9fa7b41107439087bd21a4e5786284",
            "ec6744a933ca4c47be5628aca6206b88",
            "772acad5b27c4a08bef3c60707cfe422",
            "7131e12f433247c6903fcb29301a3c36",
            "ffbdbe21815a46f78b1ec91f96c8b3d7",
            "8ad7634d658f40f0b65a45f05a613f1b",
            "2a38c62642e84a02864232ca5b121942",
            "e2eba9e03aac466ba19ef17097075aba",
            "e579da44bf8d42f589d005cd289d0e72",
            "e9f03291baeb4d5c93d4e4f01832d9e5",
            "cfab66060b5b4ab2bc86b0348ebf5d6d",
            "1102eddd6c2d47c9a9cefa1f0544c546",
            "4ee8bfda0ded4d12bdc880c67aed6859",
            "4ccbe560ab3f4e48be1f786d2d0f6561",
            "83d8090070d242f181ed637902768d94",
            "0b6eb0ac55a64643a797d3c9ef13b72f",
            "bcb1c133d7904f938eaf0bfeae629cd6",
            "e1a77f01f25b4e33ae09a2363dab7910",
            "65e95854622340e6adcfca1ab9224019",
            "39dc4ff2b3bb42298ff475348e5a7682",
            "fdee8c1ae7a24db4b94a3db6df2d4aeb",
            "f88fbeb447f5460bbddb157c3b4f435d",
            "5c7b0d689f0046c995cc0638af7fc51d",
            "f2ca69b411194b2ba3821a6df7fedb99",
            "74581617f4bf403abb18e152ab7e9b97",
            "b7c62b580a29456b8d3069b20833afc8"
          ]
        },
        "id": "nibwAjLTwJPD",
        "outputId": "7684fe2d-9447-4a30-e668-2b763f37de47"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/8065 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa15cfc20a894267a4841aa955b03ae1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1471 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffbdbe21815a46f78b1ec91f96c8b3d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1393 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b6eb0ac55a64643a797d3c9ef13b72f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['ID', 'translation'],\n",
              "        num_rows: 8065\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['ID', 'translation'],\n",
              "        num_rows: 1471\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['ID', 'translation'],\n",
              "        num_rows: 1393\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "src_lang = 'dyu'\n",
        "trg_lang = 'fr'\n",
        "chars_to_remove_regex = '[!\"&\\(\\),-./:;=?+.\\n\\[\\]]'\n",
        "def remove_special_characters(text):\n",
        "  text = re.sub(chars_to_remove_regex, '', text)\n",
        "  text = text.lower()\n",
        "  return text.strip()\n",
        "\n",
        "def clean_text(batch):\n",
        "    # process source text\n",
        "    batch['translation'][src_lang] = remove_special_characters(batch['translation'][src_lang])\n",
        "    # process target text\n",
        "    batch['translation'][trg_lang] = remove_special_characters(batch['translation'][trg_lang])\n",
        "\n",
        "    return batch\n",
        "\n",
        "\n",
        "dataset = dataset.map(clean_text)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKAW8HkbwrIv",
        "outputId": "0a2302e9-b6da-4895-85b0-331e3fbb030d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'dyu': 'i tɔgɔ bi cogodɔ', 'fr': 'tu portes un nom de fantaisie'},\n",
              " {'dyu': 'puɛn saba fɔlɔ', 'fr': 'trois points d’avance'},\n",
              " {'dyu': 'tile bena', 'fr': 'le soleil s’est couché'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset[\"validation\"][\"translation\"][:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "8ddf2f51eaa24d8a8c5f6de2510647bb",
            "240800939b2a4ffeb320e0266e223753",
            "d2b84a8d88d74329b3e65d468cfb78fb",
            "478f20b743b8400185a791989b2adcf4",
            "7fef453d44ae41a49703a64497e21635",
            "5b4eb33aa693476a95bf8fc8ea80a283",
            "f70f0df417c64fa89a42b5ae76226290",
            "c2eabb820d734461ad1f41e783722343",
            "71ca769d80794cccbc901fc16ba942a1",
            "fb298804b0254e8e9f334805522f1149",
            "b03a0a9c2393413a976a95c66c393486",
            "06db7dfe0782498fac01a7635bbfdbf8",
            "cc670536a52e46269f011ce1f2271555",
            "8f998966e69e4994a49e0fafbdfebf22",
            "afc8e6b0241d4f7c92ed864bb18d2c34",
            "696a2018f5204338aabff0d85aa8e003",
            "dbeb089342434da0bc5b376cd1e2bbbd",
            "84fa6d0eef6c430292a615e1f18b6fef",
            "c9dbf7a8aba242f89d72cb41af6ea387",
            "0b1e72e496cf41be8872b04d0299eb11",
            "56362e99caec4c4380f90e14992fe2cf",
            "b018d74742f148fb97e5a13eefab48f4",
            "00cafe5ca9264bd29841bd9a6aa898c9",
            "39edee19f06242169f97ffe984645356",
            "78630c5e278d45fc90b1d70aea78bcab",
            "b586c5fd617346adaa9e026026dff16e",
            "cea2c8fe3a3d43d1a3b273690dc211d9",
            "d276bbab303c4f4e979df1348489aee4",
            "fec580d4cca946e190c8b4c98357bf15",
            "715dd252373c439290474d619a27efe0",
            "a1d7f65a4fae4752a16f087be6e2a5a8",
            "a6b23e5318c04f71b7b5627a671c1f82",
            "25d6b2b1a41143f0b589017be5a564cc"
          ]
        },
        "id": "uguii6Hfw0n7",
        "outputId": "bb565d42-8c90-4619-b8d8-10c55867211b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/8065 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ddf2f51eaa24d8a8c5f6de2510647bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/1471 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06db7dfe0782498fac01a7635bbfdbf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/1393 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00cafe5ca9264bd29841bd9a6aa898c9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "data_dir = \"../data/dyu_fr\"\n",
        "dataset.save_to_disk(data_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIaifG4VxjrD"
      },
      "source": [
        "### Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeD7lUAQxdtp"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# model dir\n",
        "model_dir = \"../saved_model/dyu_fr\"\n",
        "\n",
        "# Create the config\n",
        "config = \"\"\"\n",
        "name: \"dyu_fr_transformer-sp\"\n",
        "joeynmt_version: \"2.3.0\"\n",
        "model_dir: \"{model_dir}\"\n",
        "use_cuda: True # False for CPU training\n",
        "fp16: True\n",
        "\n",
        "data:\n",
        "    train: \"{data_dir}\"\n",
        "    dev: \"{data_dir}\"\n",
        "    test: \"{data_dir}\"\n",
        "    dataset_type: \"huggingface\"\n",
        "    dataset_cfg:\n",
        "        name: \"dyu-fr\"\n",
        "    sample_dev_subset: 1460\n",
        "    src:\n",
        "        lang: \"dyu\"\n",
        "        max_length: 100\n",
        "        lowercase: False\n",
        "        normalize: False\n",
        "        level: \"bpe\"\n",
        "        voc_limit: 2000\n",
        "        voc_min_freq: 1\n",
        "        voc_file: \"{data_dir}/vocab.txt\"\n",
        "        tokenizer_type: \"sentencepiece\"\n",
        "        tokenizer_cfg:\n",
        "            model_file: \"{data_dir}/sp.model\"\n",
        "    trg:\n",
        "        lang: \"fr\"\n",
        "        max_length: 100\n",
        "        lowercase: False\n",
        "        normalize: False\n",
        "        level: \"bpe\"\n",
        "        voc_limit: 2000\n",
        "        voc_min_freq: 1\n",
        "        voc_file: \"{data_dir}/vocab.txt\"\n",
        "        tokenizer_type: \"sentencepiece\"\n",
        "        tokenizer_cfg:\n",
        "            model_file: \"{data_dir}/sp.model\"\n",
        "    special_symbols:\n",
        "        unk_token: \"<unk>\"\n",
        "        unk_id: 0\n",
        "        pad_token: \"<pad>\"\n",
        "        pad_id: 1\n",
        "        bos_token: \"<s>\"\n",
        "        bos_id: 2\n",
        "        eos_token: \"</s>\"\n",
        "        eos_id: 3\n",
        "\n",
        "\"\"\".format(data_dir=data_dir, model_dir=model_dir)\n",
        "with (Path(data_dir) / \"config.yaml\").open('w') as f:\n",
        "    f.write(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxeET1uqx-5r",
        "outputId": "2f512289-3f1d-47ad-d3e6-a3a3fb54389c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-13 18:12:20--  https://raw.githubusercontent.com/joeynmt/joeynmt/v2.3/scripts/build_vocab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13170 (13K) [text/plain]\n",
            "Saving to: ‘build_vocab.py’\n",
            "\n",
            "build_vocab.py      100%[===================>]  12.86K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-08-13 18:12:20 (18.9 MB/s) - ‘build_vocab.py’ saved [13170/13170]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/joeynmt/joeynmt/v2.3/scripts/build_vocab.py\n",
        "! sudo chmod 777 build_vocab.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMsqTcTmyFgY",
        "outputId": "5ca7cc36-322d-42e6-d8c3-01695230130c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-08-13 18:12:24.287096: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-13 18:12:24.601092: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-13 18:12:24.694871: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-13 18:12:24.968244: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-13 18:12:26.072303: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Dropping NaN...: 100% 8065/8065 [00:00<00:00, 113733.85 examples/s]\n",
            "Preprocessing...: 100% 8065/8065 [00:00<00:00, 11109.99 examples/s]\n",
            "Filter: 100% 8065/8065 [00:00<00:00, 25139.43 examples/s]\n",
            "### Training sentencepiece...\n",
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/tmp/sentencepiece_f4q6au0u.txt --model_prefix=../data/dyu_fr/sp --model_type=unigram --vocab_size=2000 --character_coverage=1.0 --accept_language=dyu,fr --unk_piece=<unk> --bos_piece=<s> --eos_piece=</s> --pad_piece=<pad> --unk_id=0 --bos_id=2 --eos_id=3 --pad_id=1 --vocabulary_output_piece_score=false\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /tmp/sentencepiece_f4q6au0u.txt\n",
            "  input_format: \n",
            "  model_prefix: ../data/dyu_fr/sp\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 2000\n",
            "  accept_language: dyu\n",
            "  accept_language: fr\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 1\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 0\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 2\n",
            "  eos_id: 3\n",
            "  pad_id: 1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(183) LOG(INFO) Loading corpus: /tmp/sentencepiece_f4q6au0u.txt\n",
            "trainer_interface.cc(407) LOG(INFO) Loaded all 16130 sentences\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <pad>\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(537) LOG(INFO) all chars count=469430\n",
            "trainer_interface.cc(558) LOG(INFO) Alphabet size=79\n",
            "trainer_interface.cc(559) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 16130 sentences.\n",
            "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=250301\n",
            "unigram_model_trainer.cc(274) LOG(INFO) Initialized 34076 seed sentencepieces\n",
            "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 16130\n",
            "trainer_interface.cc(608) LOG(INFO) Done! 17239\n",
            "unigram_model_trainer.cc(564) LOG(INFO) Using 17239 sentences for EM training\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=13163 obj=10.6152 num_tokens=33644 num_tokens/piece=2.55595\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=11515 obj=9.33475 num_tokens=34051 num_tokens/piece=2.9571\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=8628 obj=9.36296 num_tokens=36485 num_tokens/piece=4.22867\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=8602 obj=9.30656 num_tokens=36492 num_tokens/piece=4.24227\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=6450 obj=9.50145 num_tokens=39990 num_tokens/piece=6.2\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=6450 obj=9.43635 num_tokens=39992 num_tokens/piece=6.20031\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=4837 obj=9.68748 num_tokens=43737 num_tokens/piece=9.04217\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=4837 obj=9.61753 num_tokens=43741 num_tokens/piece=9.043\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=3627 obj=9.892 num_tokens=47409 num_tokens/piece=13.0711\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=3627 obj=9.82657 num_tokens=47406 num_tokens/piece=13.0703\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2720 obj=10.1348 num_tokens=51192 num_tokens/piece=18.8206\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2720 obj=10.0679 num_tokens=51197 num_tokens/piece=18.8224\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2200 obj=10.2988 num_tokens=53808 num_tokens/piece=24.4582\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2200 obj=10.2489 num_tokens=53814 num_tokens/piece=24.4609\n",
            "trainer_interface.cc(686) LOG(INFO) Saving model: ../data/dyu_fr/sp.model\n",
            "trainer_interface.cc(698) LOG(INFO) Saving vocabs: ../data/dyu_fr/sp.vocab\n",
            "### Copying ../data/dyu_fr/sp.vocab to ../data/dyu_fr/vocab.txt ...\n",
            "### Done.\n"
          ]
        }
      ],
      "source": [
        "!python build_vocab.py {data_dir}/config.yaml --joint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bes68tYtyK_p",
        "outputId": "9e2f74a1-1df4-4ca3-8cfa-547465a30c8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<unk>\n",
            "<pad>\n",
            "<s>\n",
            "</s>\n",
            "s\n",
            "▁a\n",
            "▁ka\n",
            "a\n",
            "'\n",
            "▁\n"
          ]
        }
      ],
      "source": [
        "!head -10 {data_dir}/vocab.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJhojECUygdZ"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tbTLsiipkPU"
      },
      "outputs": [],
      "source": [
        "config += \"\"\"\n",
        "testing:\n",
        "    #load_model: \"{model_dir}/best.ckpt\"\n",
        "    n_best: 1\n",
        "    beam_size: 10\n",
        "    beam_alpha: 1.0\n",
        "    batch_size: 1024\n",
        "    batch_type: \"token\"\n",
        "    max_output_length: 100\n",
        "    eval_metrics: [\"bleu\"]\n",
        "    #return_prob: \"hyp\"\n",
        "    #return_attention: False\n",
        "    sacrebleu_cfg:\n",
        "        tokenize: \"13a\"\n",
        "\n",
        "training:\n",
        "    #load_model: \"{model_dir}/latest.ckpt\"\n",
        "    #reset_best_ckpt: False\n",
        "    #reset_scheduler: False\n",
        "    #reset_optimizer: False\n",
        "    #reset_iter_state: False\n",
        "    random_seed: 42\n",
        "    optimizer: \"adamw\"\n",
        "    normalization: \"tokens\"\n",
        "    adam_betas: [0.9, 0.98]\n",
        "    scheduling: \"plateau\"\n",
        "    learning_rate_warmup: 100\n",
        "    learning_rate: 0.0003\n",
        "    learning_rate_min: 0.00000001\n",
        "    weight_decay: 0.0\n",
        "    label_smoothing: 0.1\n",
        "    loss: \"crossentropy\"\n",
        "    batch_size: 128\n",
        "    batch_type: \"token\"\n",
        "    batch_multiplier: 4\n",
        "    early_stopping_metric: \"bleu\"\n",
        "    epochs: 316\n",
        "    validation_freq: 2000\n",
        "    logging_freq: 2000\n",
        "    overwrite: True\n",
        "    shuffle: True\n",
        "    print_valid_sents: [0, 1, 2, 3]\n",
        "    keep_best_ckpts: 3\n",
        "\n",
        "model:\n",
        "    initializer: \"xavier_uniform\"\n",
        "    bias_initializer: \"zeros\"\n",
        "    init_gain: 1.0\n",
        "    embed_initializer: \"xavier_uniform\"\n",
        "    embed_init_gain: 1.0\n",
        "    tied_embeddings: True\n",
        "    tied_softmax: True\n",
        "    encoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 2\n",
        "        num_heads: 8\n",
        "        embeddings:\n",
        "            embedding_dim: 384\n",
        "            scale: True\n",
        "            dropout: 0.1\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 384\n",
        "        ff_size: 1536\n",
        "        dropout: 0.1\n",
        "        layer_norm: \"pre\"\n",
        "        activation: \"gelu\"\n",
        "    decoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 2\n",
        "        num_heads: 8\n",
        "        embeddings:\n",
        "            embedding_dim: 384\n",
        "            scale: True\n",
        "            dropout: 0.1\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 384\n",
        "        ff_size: 1536\n",
        "        dropout: 0.1\n",
        "        layer_norm: \"pre\"\n",
        "        activation: \"gelu\"\n",
        "\n",
        "\"\"\".format(model_dir=model_dir)\n",
        "with (Path(data_dir) / \"config.yaml\").open('w') as f:\n",
        "    f.write(config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1HczyahzRSP"
      },
      "source": [
        "### Run Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkS5Kp0vzSfL",
        "outputId": "cb6d33e5-3c82-47f9-cf25-59749810f24e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-08-13 18:12:34.962745: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-13 18:12:34.995076: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-13 18:12:35.004758: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-13 18:12:35.026852: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-13 18:12:36.666240: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-08-13 18:12:38,572 - INFO - root - Hello! This is Joey-NMT (version 2.3.0).\n",
            "2024-08-13 18:12:38,572 - INFO - joeynmt.config -                           cfg.name : dyu_fr_transformer-sp\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -                cfg.joeynmt_version : 2.3.0\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -                      cfg.model_dir : ../saved_model/dyu_fr\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -                       cfg.use_cuda : True\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -                           cfg.fp16 : True\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -                     cfg.data.train : ../data/dyu_fr\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -                       cfg.data.dev : ../data/dyu_fr\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -                      cfg.data.test : ../data/dyu_fr\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -              cfg.data.dataset_type : huggingface\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -          cfg.data.dataset_cfg.name : dyu-fr\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -         cfg.data.sample_dev_subset : 1460\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -                  cfg.data.src.lang : dyu\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -            cfg.data.src.max_length : 100\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -             cfg.data.src.lowercase : False\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -             cfg.data.src.normalize : False\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -                 cfg.data.src.level : bpe\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -             cfg.data.src.voc_limit : 2000\n",
            "2024-08-13 18:12:38,573 - INFO - joeynmt.config -          cfg.data.src.voc_min_freq : 1\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config -              cfg.data.src.voc_file : ../data/dyu_fr/vocab.txt\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config -        cfg.data.src.tokenizer_type : sentencepiece\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config - cfg.data.src.tokenizer_cfg.model_file : ../data/dyu_fr/sp.model\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config -                  cfg.data.trg.lang : fr\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config -            cfg.data.trg.max_length : 100\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config -             cfg.data.trg.lowercase : False\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config -             cfg.data.trg.normalize : False\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config -                 cfg.data.trg.level : bpe\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config -             cfg.data.trg.voc_limit : 2000\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config -          cfg.data.trg.voc_min_freq : 1\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config -              cfg.data.trg.voc_file : ../data/dyu_fr/vocab.txt\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config -        cfg.data.trg.tokenizer_type : sentencepiece\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config - cfg.data.trg.tokenizer_cfg.model_file : ../data/dyu_fr/sp.model\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config - cfg.data.special_symbols.unk_token : <unk>\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config -    cfg.data.special_symbols.unk_id : 0\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config - cfg.data.special_symbols.pad_token : <pad>\n",
            "2024-08-13 18:12:38,574 - INFO - joeynmt.config -    cfg.data.special_symbols.pad_id : 1\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config - cfg.data.special_symbols.bos_token : <s>\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config -    cfg.data.special_symbols.bos_id : 2\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config - cfg.data.special_symbols.eos_token : </s>\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config -    cfg.data.special_symbols.eos_id : 3\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config -                 cfg.testing.n_best : 1\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config -              cfg.testing.beam_size : 10\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config -             cfg.testing.beam_alpha : 1.0\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config -             cfg.testing.batch_size : 1024\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config -             cfg.testing.batch_type : token\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config -      cfg.testing.max_output_length : 100\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config -           cfg.testing.eval_metrics : ['bleu']\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config - cfg.testing.sacrebleu_cfg.tokenize : 13a\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config -           cfg.training.random_seed : 42\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config -             cfg.training.optimizer : adamw\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config -         cfg.training.normalization : tokens\n",
            "2024-08-13 18:12:38,575 - INFO - joeynmt.config -            cfg.training.adam_betas : [0.9, 0.98]\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config -            cfg.training.scheduling : plateau\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config -  cfg.training.learning_rate_warmup : 100\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config -         cfg.training.learning_rate : 0.0003\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config -     cfg.training.learning_rate_min : 1e-08\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config -          cfg.training.weight_decay : 0.0\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config -       cfg.training.label_smoothing : 0.1\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config -                  cfg.training.loss : crossentropy\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config -            cfg.training.batch_size : 128\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config -            cfg.training.batch_type : token\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config -      cfg.training.batch_multiplier : 4\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config - cfg.training.early_stopping_metric : bleu\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config -                cfg.training.epochs : 316\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config -       cfg.training.validation_freq : 2000\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config -          cfg.training.logging_freq : 2000\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config -             cfg.training.overwrite : True\n",
            "2024-08-13 18:12:38,576 - INFO - joeynmt.config -               cfg.training.shuffle : True\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config -     cfg.training.print_valid_sents : [0, 1, 2, 3]\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config -       cfg.training.keep_best_ckpts : 3\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config -              cfg.model.initializer : xavier_uniform\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config -         cfg.model.bias_initializer : zeros\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config -                cfg.model.init_gain : 1.0\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config -        cfg.model.embed_initializer : xavier_uniform\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config -          cfg.model.embed_init_gain : 1.0\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config -          cfg.model.tied_embeddings : True\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config -             cfg.model.tied_softmax : True\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config -             cfg.model.encoder.type : transformer\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config -       cfg.model.encoder.num_layers : 2\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config -        cfg.model.encoder.num_heads : 8\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config - cfg.model.encoder.embeddings.embedding_dim : 384\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config - cfg.model.encoder.embeddings.scale : True\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config - cfg.model.encoder.embeddings.dropout : 0.1\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config -      cfg.model.encoder.hidden_size : 384\n",
            "2024-08-13 18:12:38,577 - INFO - joeynmt.config -          cfg.model.encoder.ff_size : 1536\n",
            "2024-08-13 18:12:38,578 - INFO - joeynmt.config -          cfg.model.encoder.dropout : 0.1\n",
            "2024-08-13 18:12:38,578 - INFO - joeynmt.config -       cfg.model.encoder.layer_norm : pre\n",
            "2024-08-13 18:12:38,578 - INFO - joeynmt.config -       cfg.model.encoder.activation : gelu\n",
            "2024-08-13 18:12:38,578 - INFO - joeynmt.config -             cfg.model.decoder.type : transformer\n",
            "2024-08-13 18:12:38,578 - INFO - joeynmt.config -       cfg.model.decoder.num_layers : 2\n",
            "2024-08-13 18:12:38,578 - INFO - joeynmt.config -        cfg.model.decoder.num_heads : 8\n",
            "2024-08-13 18:12:38,578 - INFO - joeynmt.config - cfg.model.decoder.embeddings.embedding_dim : 384\n",
            "2024-08-13 18:12:38,578 - INFO - joeynmt.config - cfg.model.decoder.embeddings.scale : True\n",
            "2024-08-13 18:12:38,578 - INFO - joeynmt.config - cfg.model.decoder.embeddings.dropout : 0.1\n",
            "2024-08-13 18:12:38,578 - INFO - joeynmt.config -      cfg.model.decoder.hidden_size : 384\n",
            "2024-08-13 18:12:38,578 - INFO - joeynmt.config -          cfg.model.decoder.ff_size : 1536\n",
            "2024-08-13 18:12:38,578 - INFO - joeynmt.config -          cfg.model.decoder.dropout : 0.1\n",
            "2024-08-13 18:12:38,578 - INFO - joeynmt.config -       cfg.model.decoder.layer_norm : pre\n",
            "2024-08-13 18:12:38,578 - INFO - joeynmt.config -       cfg.model.decoder.activation : gelu\n",
            "2024-08-13 18:12:38,647 - INFO - joeynmt.data - Building tokenizer...\n",
            "2024-08-13 18:12:38,654 - INFO - joeynmt.tokenizers - dyu tokenizer: SentencePieceTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, 100), pretokenizer=none, tokenizer=SentencePieceProcessor, nbest_size=5, alpha=0.0)\n",
            "2024-08-13 18:12:38,654 - INFO - joeynmt.tokenizers - fr tokenizer: SentencePieceTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, 100), pretokenizer=none, tokenizer=SentencePieceProcessor, nbest_size=5, alpha=0.0)\n",
            "2024-08-13 18:12:38,654 - INFO - joeynmt.data - Loading train set...\n",
            "2024-08-13 18:12:38,781 - INFO - datasets - PyTorch version 2.3.1+cu121 available.\n",
            "2024-08-13 18:12:38,782 - INFO - datasets - Polars version 0.20.2 available.\n",
            "2024-08-13 18:12:38,783 - INFO - datasets - TensorFlow version 2.17.0 available.\n",
            "2024-08-13 18:12:38,784 - INFO - datasets - JAX version 0.4.26 available.\n",
            "Dropping NaN...: 100% 8065/8065 [00:00<00:00, 110303.00 examples/s]\n",
            "Preprocessing...: 100% 8065/8065 [00:00<00:00, 11252.54 examples/s]\n",
            "2024-08-13 18:12:39,731 - INFO - joeynmt.data - Building vocabulary...\n",
            "2024-08-13 18:12:39,783 - INFO - joeynmt.data - Loading dev set...\n",
            "Dropping NaN...: 100% 1471/1471 [00:00<00:00, 98564.17 examples/s]\n",
            "Preprocessing...: 100% 1471/1471 [00:00<00:00, 11090.40 examples/s]\n",
            "2024-08-13 18:12:40,004 - INFO - joeynmt.data - Loading test set...\n",
            "Dropping NaN...: 100% 1393/1393 [00:00<00:00, 101143.67 examples/s]\n",
            "Preprocessing...: 100% 1393/1393 [00:00<00:00, 11608.67 examples/s]\n",
            "2024-08-13 18:12:40,211 - INFO - joeynmt.data - Data loaded.\n",
            "2024-08-13 18:12:40,211 - INFO - joeynmt.data - Train dataset: HuggingfaceTranslationDataset(len=8065, src_lang=\"dyu\", trg_lang=\"fr\", has_trg=True, random_subset=-1, has_src_prompt=False, has_trg_prompt=False, name=dyu-fr, split=train)\n",
            "2024-08-13 18:12:40,211 - INFO - joeynmt.data - Valid dataset: HuggingfaceTranslationDataset(len=1471, src_lang=\"dyu\", trg_lang=\"fr\", has_trg=True, random_subset=1460, has_src_prompt=False, has_trg_prompt=False, name=dyu-fr, split=validation)\n",
            "2024-08-13 18:12:40,211 - INFO - joeynmt.data -  Test dataset: HuggingfaceTranslationDataset(len=1393, src_lang=\"dyu\", trg_lang=\"fr\", has_trg=True, random_subset=-1, has_src_prompt=False, has_trg_prompt=False, name=dyu-fr, split=test)\n",
            "2024-08-13 18:12:40,212 - INFO - joeynmt.data - First training example:\n",
            "\t[SRC] ▁a ▁bi ▁ji ▁min ▁na\n",
            "\t[TRG] ▁il ▁bo it ▁de ▁l ’ eau\n",
            "2024-08-13 18:12:40,212 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) s (5) ▁a (6) ▁ka (7) a (8) ' (9) ▁\n",
            "2024-08-13 18:12:40,212 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) s (5) ▁a (6) ▁ka (7) a (8) ' (9) ▁\n",
            "2024-08-13 18:12:40,212 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2000\n",
            "2024-08-13 18:12:40,212 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2000\n",
            "2024-08-13 18:12:40,214 - WARNING - joeynmt.tokenizers - /content/../saved_model/dyu_fr/sp.model already exists. Stop copying.\n",
            "2024-08-13 18:12:40,215 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
            "2024-08-13 18:12:40,549 - INFO - joeynmt.model - Enc-dec model built.\n",
            "2024-08-13 18:12:40,550 - INFO - joeynmt.model - Total params: 9051648\n",
            "2024-08-13 18:12:40,834 - INFO - joeynmt.prediction - Model(\n",
            "\tencoder=TransformerEncoder(num_layers=2, num_heads=8, alpha=1.0, layer_norm=\"pre\", activation=GELU(approximate='none')),\n",
            "\tdecoder=TransformerDecoder(num_layers=2, num_heads=8, alpha=1.0, layer_norm=\"pre\", activation=GELU(approximate='none')),\n",
            "\tsrc_embed=Embeddings(embedding_dim=384, vocab_size=2000),\n",
            "\ttrg_embed=Embeddings(embedding_dim=384, vocab_size=2000),\n",
            "\tloss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.1))\n",
            "2024-08-13 18:12:42,480 - INFO - joeynmt.builders - AdamW(lr=0.0003, weight_decay=0.0, betas=[0.9, 0.98])\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "2024-08-13 18:12:42,481 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=max, verbose=False, threshold_mode=abs, eps=0.0, factor=0.5, patience=5)\n",
            "2024-08-13 18:12:42,481 - INFO - joeynmt.training - Train config:\n",
            "\tdevice: cuda\n",
            "\tn_gpu: 1\n",
            "\tddp training: False\n",
            "\t16-bits training: True\n",
            "\tgradient accumulation: 4\n",
            "\tbatch size per device: 128\n",
            "\teffective batch size (w. parallel & accumulation): 512\n",
            "2024-08-13 18:12:42,481 - INFO - joeynmt.training - EPOCH 1\n",
            "2024-08-13 18:13:18,139 - INFO - joeynmt.training - Epoch   1, total training loss: 1410.92, num. of seqs: 8065, num. of tokens: 90423, 35.6565[sec]\n",
            "2024-08-13 18:13:18,139 - INFO - joeynmt.training - EPOCH 2\n",
            "2024-08-13 18:13:48,096 - INFO - joeynmt.training - Epoch   2, total training loss: 1219.16, num. of seqs: 8065, num. of tokens: 90423, 29.9552[sec]\n",
            "2024-08-13 18:13:48,097 - INFO - joeynmt.training - EPOCH 3\n",
            "2024-08-13 18:14:18,187 - INFO - joeynmt.training - Epoch   3, total training loss: 1116.71, num. of seqs: 8065, num. of tokens: 90423, 30.0895[sec]\n",
            "2024-08-13 18:14:18,187 - INFO - joeynmt.training - EPOCH 4\n",
            "2024-08-13 18:14:49,553 - INFO - joeynmt.training - Epoch   4, total training loss: 1045.07, num. of seqs: 8065, num. of tokens: 90423, 31.3642[sec]\n",
            "2024-08-13 18:14:49,554 - INFO - joeynmt.training - EPOCH 5\n",
            "2024-08-13 18:15:19,687 - INFO - joeynmt.training - Epoch   5, total training loss: 976.56, num. of seqs: 8065, num. of tokens: 90423, 30.1322[sec]\n",
            "2024-08-13 18:15:19,687 - INFO - joeynmt.training - EPOCH 6\n",
            "2024-08-13 18:15:49,809 - INFO - joeynmt.training - Epoch   6, total training loss: 906.19, num. of seqs: 8065, num. of tokens: 90423, 30.1212[sec]\n",
            "2024-08-13 18:15:49,809 - INFO - joeynmt.training - EPOCH 7\n",
            "2024-08-13 18:16:12,738 - INFO - joeynmt.training - Epoch   7, Step:     2000, Batch Loss:     2.803530, Batch Acc: 0.334058, Tokens per Sec:     2869, Lr: 0.000300\n",
            "2024-08-13 18:16:12,739 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=2042\n",
            "2024-08-13 18:16:12,739 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:12<00:00, 120.48it/s]\n",
            "2024-08-13 18:16:24,858 - INFO - joeynmt.prediction - Generation took 12.1188[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 56288.34 examples/s]\n",
            "2024-08-13 18:16:25,062 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 18:16:25,062 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   2.46, loss:   3.53, ppl:  34.15, acc:   0.26, 0.1083[sec]\n",
            "2024-08-13 18:16:25,063 - INFO - joeynmt.training - Hooray! New best validation result [bleu]!\n",
            "2024-08-13 18:16:25,297 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/2000.ckpt.\n",
            "2024-08-13 18:16:25,299 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 18:16:25,352 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 18:16:25,353 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 18:16:25,353 - INFO - joeynmt.training - \tHypothesis: comment vastu\n",
            "2024-08-13 18:16:25,445 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 18:16:25,490 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 18:16:25,491 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 18:16:25,491 - INFO - joeynmt.training - \tHypothesis: trois trois mois\n",
            "2024-08-13 18:16:25,585 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 18:16:25,630 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 18:16:25,630 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 18:16:25,630 - INFO - joeynmt.training - \tHypothesis: les gens les les rges\n",
            "2024-08-13 18:16:25,725 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 18:16:25,770 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 18:16:25,771 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 18:16:25,771 - INFO - joeynmt.training - \tHypothesis: une une heure\n",
            "2024-08-13 18:16:35,661 - INFO - joeynmt.training - Epoch   7, total training loss: 856.86, num. of seqs: 8065, num. of tokens: 90423, 32.7244[sec]\n",
            "2024-08-13 18:16:35,662 - INFO - joeynmt.training - EPOCH 8\n",
            "2024-08-13 18:17:06,609 - INFO - joeynmt.training - Epoch   8, total training loss: 798.39, num. of seqs: 8065, num. of tokens: 90423, 30.9464[sec]\n",
            "2024-08-13 18:17:06,610 - INFO - joeynmt.training - EPOCH 9\n",
            "2024-08-13 18:17:38,177 - INFO - joeynmt.training - Epoch   9, total training loss: 739.99, num. of seqs: 8065, num. of tokens: 90423, 31.5664[sec]\n",
            "2024-08-13 18:17:38,177 - INFO - joeynmt.training - EPOCH 10\n",
            "2024-08-13 18:18:08,583 - INFO - joeynmt.training - Epoch  10, total training loss: 694.44, num. of seqs: 8065, num. of tokens: 90423, 30.4046[sec]\n",
            "2024-08-13 18:18:08,583 - INFO - joeynmt.training - EPOCH 11\n",
            "2024-08-13 18:18:38,770 - INFO - joeynmt.training - Epoch  11, total training loss: 643.84, num. of seqs: 8065, num. of tokens: 90423, 30.1864[sec]\n",
            "2024-08-13 18:18:38,771 - INFO - joeynmt.training - EPOCH 12\n",
            "2024-08-13 18:19:09,889 - INFO - joeynmt.training - Epoch  12, total training loss: 593.66, num. of seqs: 8065, num. of tokens: 90423, 31.1172[sec]\n",
            "2024-08-13 18:19:09,889 - INFO - joeynmt.training - EPOCH 13\n",
            "2024-08-13 18:19:39,649 - INFO - joeynmt.training - Epoch  13, total training loss: 546.59, num. of seqs: 8065, num. of tokens: 90423, 29.7583[sec]\n",
            "2024-08-13 18:19:39,649 - INFO - joeynmt.training - EPOCH 14\n",
            "2024-08-13 18:19:53,495 - INFO - joeynmt.training - Epoch  14, Step:     4000, Batch Loss:     1.910172, Batch Acc: 0.575310, Tokens per Sec:     3044, Lr: 0.000300\n",
            "2024-08-13 18:19:53,495 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=4042\n",
            "2024-08-13 18:19:53,496 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:08<00:00, 177.98it/s]\n",
            "2024-08-13 18:20:01,700 - INFO - joeynmt.prediction - Generation took 8.2037[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 61769.25 examples/s]\n",
            "2024-08-13 18:20:01,891 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 18:20:01,892 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   4.21, loss:   3.73, ppl:  41.67, acc:   0.29, 0.0953[sec]\n",
            "2024-08-13 18:20:01,892 - INFO - joeynmt.training - Hooray! New best validation result [bleu]!\n",
            "2024-08-13 18:20:02,113 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/4000.ckpt.\n",
            "2024-08-13 18:20:02,115 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 18:20:02,196 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 18:20:02,196 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 18:20:02,196 - INFO - joeynmt.training - \tHypothesis: comment s’appelle votre nom\n",
            "2024-08-13 18:20:02,289 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 18:20:02,335 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 18:20:02,335 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 18:20:02,335 - INFO - joeynmt.training - \tHypothesis: trois point d'avance\n",
            "2024-08-13 18:20:02,435 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 18:20:02,483 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 18:20:02,483 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 18:20:02,483 - INFO - joeynmt.training - \tHypothesis: dans les organs\n",
            "2024-08-13 18:20:02,573 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 18:20:02,616 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 18:20:02,616 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 18:20:02,616 - INFO - joeynmt.training - \tHypothesis: un pachillard\n",
            "2024-08-13 18:20:19,081 - INFO - joeynmt.training - Epoch  14, total training loss: 503.13, num. of seqs: 8065, num. of tokens: 90423, 30.2179[sec]\n",
            "2024-08-13 18:20:19,081 - INFO - joeynmt.training - EPOCH 15\n",
            "2024-08-13 18:20:49,470 - INFO - joeynmt.training - Epoch  15, total training loss: 466.97, num. of seqs: 8065, num. of tokens: 90423, 30.3878[sec]\n",
            "2024-08-13 18:20:49,470 - INFO - joeynmt.training - EPOCH 16\n",
            "2024-08-13 18:21:20,634 - INFO - joeynmt.training - Epoch  16, total training loss: 430.02, num. of seqs: 8065, num. of tokens: 90423, 31.1626[sec]\n",
            "2024-08-13 18:21:20,635 - INFO - joeynmt.training - EPOCH 17\n",
            "2024-08-13 18:21:50,655 - INFO - joeynmt.training - Epoch  17, total training loss: 393.90, num. of seqs: 8065, num. of tokens: 90423, 30.0197[sec]\n",
            "2024-08-13 18:21:50,656 - INFO - joeynmt.training - EPOCH 18\n",
            "2024-08-13 18:22:20,801 - INFO - joeynmt.training - Epoch  18, total training loss: 363.14, num. of seqs: 8065, num. of tokens: 90423, 30.1439[sec]\n",
            "2024-08-13 18:22:20,801 - INFO - joeynmt.training - EPOCH 19\n",
            "2024-08-13 18:22:51,809 - INFO - joeynmt.training - Epoch  19, total training loss: 333.74, num. of seqs: 8065, num. of tokens: 90423, 31.0062[sec]\n",
            "2024-08-13 18:22:51,809 - INFO - joeynmt.training - EPOCH 20\n",
            "2024-08-13 18:23:21,721 - INFO - joeynmt.training - Epoch  20, total training loss: 307.25, num. of seqs: 8065, num. of tokens: 90423, 29.9111[sec]\n",
            "2024-08-13 18:23:21,722 - INFO - joeynmt.training - EPOCH 21\n",
            "2024-08-13 18:23:27,924 - INFO - joeynmt.training - Epoch  21, Step:     6000, Batch Loss:     1.050550, Batch Acc: 0.781054, Tokens per Sec:     2724, Lr: 0.000300\n",
            "2024-08-13 18:23:27,925 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=6042\n",
            "2024-08-13 18:23:27,925 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:06<00:00, 212.20it/s]\n",
            "2024-08-13 18:23:34,807 - INFO - joeynmt.prediction - Generation took 6.8808[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 61229.80 examples/s]\n",
            "2024-08-13 18:23:34,995 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 18:23:34,995 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   4.86, loss:   4.14, ppl:  62.79, acc:   0.29, 0.0986[sec]\n",
            "2024-08-13 18:23:34,996 - INFO - joeynmt.training - Hooray! New best validation result [bleu]!\n",
            "2024-08-13 18:23:35,232 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/6000.ckpt.\n",
            "2024-08-13 18:23:35,234 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 18:23:35,285 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 18:23:35,285 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 18:23:35,285 - INFO - joeynmt.training - \tHypothesis: comment s’appelle votre sœur\n",
            "2024-08-13 18:23:35,382 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 18:23:35,425 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 18:23:35,426 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 18:23:35,426 - INFO - joeynmt.training - \tHypothesis: trois point d'avance\n",
            "2024-08-13 18:23:35,520 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 18:23:35,564 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 18:23:35,564 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 18:23:35,564 - INFO - joeynmt.training - \tHypothesis: des secles monsieursques éclés\n",
            "2024-08-13 18:23:35,669 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 18:23:35,721 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 18:23:35,722 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 18:23:35,722 - INFO - joeynmt.training - \tHypothesis: un autre\n",
            "2024-08-13 18:24:01,365 - INFO - joeynmt.training - Epoch  21, total training loss: 282.83, num. of seqs: 8065, num. of tokens: 90423, 31.7460[sec]\n",
            "2024-08-13 18:24:01,365 - INFO - joeynmt.training - EPOCH 22\n",
            "2024-08-13 18:24:32,090 - INFO - joeynmt.training - Epoch  22, total training loss: 265.67, num. of seqs: 8065, num. of tokens: 90423, 30.7236[sec]\n",
            "2024-08-13 18:24:32,090 - INFO - joeynmt.training - EPOCH 23\n",
            "2024-08-13 18:25:02,411 - INFO - joeynmt.training - Epoch  23, total training loss: 247.48, num. of seqs: 8065, num. of tokens: 90423, 30.3191[sec]\n",
            "2024-08-13 18:25:02,411 - INFO - joeynmt.training - EPOCH 24\n",
            "2024-08-13 18:25:32,507 - INFO - joeynmt.training - Epoch  24, total training loss: 232.50, num. of seqs: 8065, num. of tokens: 90423, 30.0947[sec]\n",
            "2024-08-13 18:25:32,507 - INFO - joeynmt.training - EPOCH 25\n",
            "2024-08-13 18:26:03,025 - INFO - joeynmt.training - Epoch  25, total training loss: 217.37, num. of seqs: 8065, num. of tokens: 90423, 30.5170[sec]\n",
            "2024-08-13 18:26:03,026 - INFO - joeynmt.training - EPOCH 26\n",
            "2024-08-13 18:26:33,842 - INFO - joeynmt.training - Epoch  26, total training loss: 209.09, num. of seqs: 8065, num. of tokens: 90423, 30.8146[sec]\n",
            "2024-08-13 18:26:33,842 - INFO - joeynmt.training - EPOCH 27\n",
            "2024-08-13 18:27:01,921 - INFO - joeynmt.training - Epoch  27, Step:     8000, Batch Loss:     0.711060, Batch Acc: 0.861666, Tokens per Sec:     3016, Lr: 0.000300\n",
            "2024-08-13 18:27:01,921 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=8042\n",
            "2024-08-13 18:27:01,922 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 183.44it/s]\n",
            "2024-08-13 18:27:09,881 - INFO - joeynmt.prediction - Generation took 7.9591[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 52391.85 examples/s]\n",
            "2024-08-13 18:27:10,086 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 18:27:10,087 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   5.40, loss:   4.37, ppl:  79.43, acc:   0.29, 0.1033[sec]\n",
            "2024-08-13 18:27:10,087 - INFO - joeynmt.training - Hooray! New best validation result [bleu]!\n",
            "2024-08-13 18:27:10,374 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/8000.ckpt.\n",
            "2024-08-13 18:27:10,376 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/2000.ckpt\n",
            "2024-08-13 18:27:10,396 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 18:27:10,442 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 18:27:10,442 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 18:27:10,443 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 18:27:10,535 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 18:27:10,581 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 18:27:10,581 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 18:27:10,581 - INFO - joeynmt.training - \tHypothesis: trois point d'avance\n",
            "2024-08-13 18:27:10,675 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 18:27:10,720 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 18:27:10,721 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 18:27:10,721 - INFO - joeynmt.training - \tHypothesis: les orcentes on l'accccémie sont également présents sur les organisés\n",
            "2024-08-13 18:27:10,809 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 18:27:10,856 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 18:27:10,856 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 18:27:10,856 - INFO - joeynmt.training - \tHypothesis: l'un et l'autre\n",
            "2024-08-13 18:27:12,810 - INFO - joeynmt.training - Epoch  27, total training loss: 196.46, num. of seqs: 8065, num. of tokens: 90423, 29.9420[sec]\n",
            "2024-08-13 18:27:12,810 - INFO - joeynmt.training - EPOCH 28\n",
            "2024-08-13 18:27:43,220 - INFO - joeynmt.training - Epoch  28, total training loss: 188.75, num. of seqs: 8065, num. of tokens: 90423, 30.4090[sec]\n",
            "2024-08-13 18:27:43,221 - INFO - joeynmt.training - EPOCH 29\n",
            "2024-08-13 18:28:14,241 - INFO - joeynmt.training - Epoch  29, total training loss: 182.67, num. of seqs: 8065, num. of tokens: 90423, 31.0192[sec]\n",
            "2024-08-13 18:28:14,241 - INFO - joeynmt.training - EPOCH 30\n",
            "2024-08-13 18:28:44,361 - INFO - joeynmt.training - Epoch  30, total training loss: 175.95, num. of seqs: 8065, num. of tokens: 90423, 30.1186[sec]\n",
            "2024-08-13 18:28:44,362 - INFO - joeynmt.training - EPOCH 31\n",
            "2024-08-13 18:29:14,309 - INFO - joeynmt.training - Epoch  31, total training loss: 166.55, num. of seqs: 8065, num. of tokens: 90423, 29.9458[sec]\n",
            "2024-08-13 18:29:14,309 - INFO - joeynmt.training - EPOCH 32\n",
            "2024-08-13 18:29:45,434 - INFO - joeynmt.training - Epoch  32, total training loss: 163.95, num. of seqs: 8065, num. of tokens: 90423, 31.1237[sec]\n",
            "2024-08-13 18:29:45,434 - INFO - joeynmt.training - EPOCH 33\n",
            "2024-08-13 18:30:15,522 - INFO - joeynmt.training - Epoch  33, total training loss: 158.90, num. of seqs: 8065, num. of tokens: 90423, 30.0867[sec]\n",
            "2024-08-13 18:30:15,522 - INFO - joeynmt.training - EPOCH 34\n",
            "2024-08-13 18:30:36,012 - INFO - joeynmt.training - Epoch  34, Step:    10000, Batch Loss:     0.522392, Batch Acc: 0.916727, Tokens per Sec:     2961, Lr: 0.000300\n",
            "2024-08-13 18:30:36,013 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=10042\n",
            "2024-08-13 18:30:36,014 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 201.17it/s]\n",
            "2024-08-13 18:30:43,273 - INFO - joeynmt.prediction - Generation took 7.2578[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 51016.82 examples/s]\n",
            "2024-08-13 18:30:43,484 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 18:30:43,484 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   5.65, loss:   4.44, ppl:  84.90, acc:   0.30, 0.1087[sec]\n",
            "2024-08-13 18:30:43,485 - INFO - joeynmt.training - Hooray! New best validation result [bleu]!\n",
            "2024-08-13 18:30:43,719 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/10000.ckpt.\n",
            "2024-08-13 18:30:43,721 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/4000.ckpt\n",
            "2024-08-13 18:30:43,757 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 18:30:43,832 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 18:30:43,832 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 18:30:43,832 - INFO - joeynmt.training - \tHypothesis: comment s’appelle votre sœur\n",
            "2024-08-13 18:30:43,919 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 18:30:43,966 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 18:30:43,966 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 18:30:43,967 - INFO - joeynmt.training - \tHypothesis: trois point d'avance\n",
            "2024-08-13 18:30:44,054 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 18:30:44,099 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 18:30:44,099 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 18:30:44,099 - INFO - joeynmt.training - \tHypothesis: les ducs étaient làs\n",
            "2024-08-13 18:30:44,193 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 18:30:44,240 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 18:30:44,241 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 18:30:44,241 - INFO - joeynmt.training - \tHypothesis: de mêmes mouvement\n",
            "2024-08-13 18:30:54,932 - INFO - joeynmt.training - Epoch  34, total training loss: 152.11, num. of seqs: 8065, num. of tokens: 90423, 31.0821[sec]\n",
            "2024-08-13 18:30:54,932 - INFO - joeynmt.training - EPOCH 35\n",
            "2024-08-13 18:31:25,703 - INFO - joeynmt.training - Epoch  35, total training loss: 151.02, num. of seqs: 8065, num. of tokens: 90423, 30.7704[sec]\n",
            "2024-08-13 18:31:25,704 - INFO - joeynmt.training - EPOCH 36\n",
            "2024-08-13 18:31:56,646 - INFO - joeynmt.training - Epoch  36, total training loss: 144.37, num. of seqs: 8065, num. of tokens: 90423, 30.9416[sec]\n",
            "2024-08-13 18:31:56,647 - INFO - joeynmt.training - EPOCH 37\n",
            "2024-08-13 18:32:26,628 - INFO - joeynmt.training - Epoch  37, total training loss: 139.76, num. of seqs: 8065, num. of tokens: 90423, 29.9800[sec]\n",
            "2024-08-13 18:32:26,628 - INFO - joeynmt.training - EPOCH 38\n",
            "2024-08-13 18:32:56,779 - INFO - joeynmt.training - Epoch  38, total training loss: 139.20, num. of seqs: 8065, num. of tokens: 90423, 30.1504[sec]\n",
            "2024-08-13 18:32:56,779 - INFO - joeynmt.training - EPOCH 39\n",
            "2024-08-13 18:33:28,005 - INFO - joeynmt.training - Epoch  39, total training loss: 137.01, num. of seqs: 8065, num. of tokens: 90423, 31.2250[sec]\n",
            "2024-08-13 18:33:28,006 - INFO - joeynmt.training - EPOCH 40\n",
            "2024-08-13 18:33:58,046 - INFO - joeynmt.training - Epoch  40, total training loss: 134.57, num. of seqs: 8065, num. of tokens: 90423, 30.0400[sec]\n",
            "2024-08-13 18:33:58,047 - INFO - joeynmt.training - EPOCH 41\n",
            "2024-08-13 18:34:10,536 - INFO - joeynmt.training - Epoch  41, Step:    12000, Batch Loss:     0.418893, Batch Acc: 0.943072, Tokens per Sec:     2957, Lr: 0.000300\n",
            "2024-08-13 18:34:10,537 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=12042\n",
            "2024-08-13 18:34:10,537 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 186.14it/s]\n",
            "2024-08-13 18:34:18,381 - INFO - joeynmt.prediction - Generation took 7.8438[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 54192.07 examples/s]\n",
            "2024-08-13 18:34:18,858 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 18:34:18,858 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   5.48, loss:   4.44, ppl:  85.07, acc:   0.30, 0.3799[sec]\n",
            "2024-08-13 18:34:19,066 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/12000.ckpt.\n",
            "2024-08-13 18:34:19,067 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/6000.ckpt\n",
            "2024-08-13 18:34:19,101 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 18:34:19,169 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 18:34:19,170 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 18:34:19,170 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 18:34:19,260 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 18:34:19,308 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 18:34:19,308 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 18:34:19,308 - INFO - joeynmt.training - \tHypothesis: trois point d'avance\n",
            "2024-08-13 18:34:19,395 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 18:34:19,440 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 18:34:19,440 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 18:34:19,440 - INFO - joeynmt.training - \tHypothesis: les interpes sont d’eau\n",
            "2024-08-13 18:34:19,531 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 18:34:19,575 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 18:34:19,575 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 18:34:19,575 - INFO - joeynmt.training - \tHypothesis: un tour dure\n",
            "2024-08-13 18:34:38,034 - INFO - joeynmt.training - Epoch  41, total training loss: 130.46, num. of seqs: 8065, num. of tokens: 90423, 30.8459[sec]\n",
            "2024-08-13 18:34:38,034 - INFO - joeynmt.training - EPOCH 42\n",
            "2024-08-13 18:35:08,875 - INFO - joeynmt.training - Epoch  42, total training loss: 126.70, num. of seqs: 8065, num. of tokens: 90423, 30.8401[sec]\n",
            "2024-08-13 18:35:08,876 - INFO - joeynmt.training - EPOCH 43\n",
            "2024-08-13 18:35:39,382 - INFO - joeynmt.training - Epoch  43, total training loss: 126.10, num. of seqs: 8065, num. of tokens: 90423, 30.5047[sec]\n",
            "2024-08-13 18:35:39,382 - INFO - joeynmt.training - EPOCH 44\n",
            "2024-08-13 18:36:09,585 - INFO - joeynmt.training - Epoch  44, total training loss: 122.72, num. of seqs: 8065, num. of tokens: 90423, 30.2010[sec]\n",
            "2024-08-13 18:36:09,585 - INFO - joeynmt.training - EPOCH 45\n",
            "2024-08-13 18:36:40,413 - INFO - joeynmt.training - Epoch  45, total training loss: 120.67, num. of seqs: 8065, num. of tokens: 90423, 30.8267[sec]\n",
            "2024-08-13 18:36:40,413 - INFO - joeynmt.training - EPOCH 46\n",
            "2024-08-13 18:37:10,791 - INFO - joeynmt.training - Epoch  46, total training loss: 119.41, num. of seqs: 8065, num. of tokens: 90423, 30.3767[sec]\n",
            "2024-08-13 18:37:10,791 - INFO - joeynmt.training - EPOCH 47\n",
            "2024-08-13 18:37:41,095 - INFO - joeynmt.training - Epoch  47, total training loss: 116.66, num. of seqs: 8065, num. of tokens: 90423, 30.3032[sec]\n",
            "2024-08-13 18:37:41,095 - INFO - joeynmt.training - EPOCH 48\n",
            "2024-08-13 18:37:45,941 - INFO - joeynmt.training - Epoch  48, Step:    14000, Batch Loss:     0.402716, Batch Acc: 0.956044, Tokens per Sec:     2573, Lr: 0.000300\n",
            "2024-08-13 18:37:45,942 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=14042\n",
            "2024-08-13 18:37:45,942 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:06<00:00, 217.06it/s]\n",
            "2024-08-13 18:37:52,670 - INFO - joeynmt.prediction - Generation took 6.7267[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 59382.30 examples/s]\n",
            "2024-08-13 18:37:52,881 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 18:37:52,881 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   5.91, loss:   4.40, ppl:  81.49, acc:   0.31, 0.1103[sec]\n",
            "2024-08-13 18:37:52,882 - INFO - joeynmt.training - Hooray! New best validation result [bleu]!\n",
            "2024-08-13 18:37:53,113 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/14000.ckpt.\n",
            "2024-08-13 18:37:53,114 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/8000.ckpt\n",
            "2024-08-13 18:37:53,141 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 18:37:53,187 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 18:37:53,188 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 18:37:53,188 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 18:37:53,284 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 18:37:53,328 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 18:37:53,328 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 18:37:53,328 - INFO - joeynmt.training - \tHypothesis: trois montée de l'avance\n",
            "2024-08-13 18:37:53,417 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 18:37:53,470 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 18:37:53,470 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 18:37:53,471 - INFO - joeynmt.training - \tHypothesis: les jours s'étouves\n",
            "2024-08-13 18:37:53,584 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 18:37:53,629 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 18:37:53,629 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 18:37:53,629 - INFO - joeynmt.training - \tHypothesis: un de travail\n",
            "2024-08-13 18:38:20,578 - INFO - joeynmt.training - Epoch  48, total training loss: 115.99, num. of seqs: 8065, num. of tokens: 90423, 31.6997[sec]\n",
            "2024-08-13 18:38:20,578 - INFO - joeynmt.training - EPOCH 49\n",
            "2024-08-13 18:38:51,778 - INFO - joeynmt.training - Epoch  49, total training loss: 112.92, num. of seqs: 8065, num. of tokens: 90423, 31.1985[sec]\n",
            "2024-08-13 18:38:51,778 - INFO - joeynmt.training - EPOCH 50\n",
            "2024-08-13 18:39:21,802 - INFO - joeynmt.training - Epoch  50, total training loss: 111.60, num. of seqs: 8065, num. of tokens: 90423, 30.0234[sec]\n",
            "2024-08-13 18:39:21,803 - INFO - joeynmt.training - EPOCH 51\n",
            "2024-08-13 18:39:51,955 - INFO - joeynmt.training - Epoch  51, total training loss: 110.24, num. of seqs: 8065, num. of tokens: 90423, 30.1511[sec]\n",
            "2024-08-13 18:39:51,955 - INFO - joeynmt.training - EPOCH 52\n",
            "2024-08-13 18:40:22,827 - INFO - joeynmt.training - Epoch  52, total training loss: 108.13, num. of seqs: 8065, num. of tokens: 90423, 30.8704[sec]\n",
            "2024-08-13 18:40:22,827 - INFO - joeynmt.training - EPOCH 53\n",
            "2024-08-13 18:40:52,900 - INFO - joeynmt.training - Epoch  53, total training loss: 106.62, num. of seqs: 8065, num. of tokens: 90423, 30.0717[sec]\n",
            "2024-08-13 18:40:52,900 - INFO - joeynmt.training - EPOCH 54\n",
            "2024-08-13 18:41:19,324 - INFO - joeynmt.training - Epoch  54, Step:    16000, Batch Loss:     0.384487, Batch Acc: 0.958648, Tokens per Sec:     2988, Lr: 0.000300\n",
            "2024-08-13 18:41:19,325 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=16042\n",
            "2024-08-13 18:41:19,325 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:08<00:00, 181.14it/s]\n",
            "2024-08-13 18:41:27,386 - INFO - joeynmt.prediction - Generation took 8.0604[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 44496.36 examples/s]\n",
            "2024-08-13 18:41:27,601 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 18:41:27,601 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   5.77, loss:   4.37, ppl:  79.01, acc:   0.31, 0.1117[sec]\n",
            "2024-08-13 18:41:27,830 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/16000.ckpt.\n",
            "2024-08-13 18:41:27,832 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/12000.ckpt\n",
            "2024-08-13 18:41:27,867 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 18:41:27,929 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 18:41:27,929 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 18:41:27,929 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 18:41:28,020 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 18:41:28,071 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 18:41:28,071 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 18:41:28,071 - INFO - joeynmt.training - \tHypothesis: trois point d'avance\n",
            "2024-08-13 18:41:28,161 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 18:41:28,205 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 18:41:28,206 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 18:41:28,206 - INFO - joeynmt.training - \tHypothesis: les ordices sont détarément\n",
            "2024-08-13 18:41:28,314 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 18:41:28,359 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 18:41:28,359 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 18:41:28,359 - INFO - joeynmt.training - \tHypothesis: un tour de l'un\n",
            "2024-08-13 18:41:32,306 - INFO - joeynmt.training - Epoch  54, total training loss: 106.65, num. of seqs: 8065, num. of tokens: 90423, 30.2743[sec]\n",
            "2024-08-13 18:41:32,306 - INFO - joeynmt.training - EPOCH 55\n",
            "2024-08-13 18:42:03,428 - INFO - joeynmt.training - Epoch  55, total training loss: 104.63, num. of seqs: 8065, num. of tokens: 90423, 31.1215[sec]\n",
            "2024-08-13 18:42:03,429 - INFO - joeynmt.training - EPOCH 56\n",
            "2024-08-13 18:42:34,328 - INFO - joeynmt.training - Epoch  56, total training loss: 102.74, num. of seqs: 8065, num. of tokens: 90423, 30.8983[sec]\n",
            "2024-08-13 18:42:34,329 - INFO - joeynmt.training - EPOCH 57\n",
            "2024-08-13 18:43:03,954 - INFO - joeynmt.training - Epoch  57, total training loss: 100.71, num. of seqs: 8065, num. of tokens: 90423, 29.6240[sec]\n",
            "2024-08-13 18:43:03,954 - INFO - joeynmt.training - EPOCH 58\n",
            "2024-08-13 18:43:34,198 - INFO - joeynmt.training - Epoch  58, total training loss: 100.61, num. of seqs: 8065, num. of tokens: 90423, 30.2431[sec]\n",
            "2024-08-13 18:43:34,198 - INFO - joeynmt.training - EPOCH 59\n",
            "2024-08-13 18:44:05,092 - INFO - joeynmt.training - Epoch  59, total training loss: 99.38, num. of seqs: 8065, num. of tokens: 90423, 30.8922[sec]\n",
            "2024-08-13 18:44:05,092 - INFO - joeynmt.training - EPOCH 60\n",
            "2024-08-13 18:44:35,107 - INFO - joeynmt.training - Epoch  60, total training loss: 98.31, num. of seqs: 8065, num. of tokens: 90423, 30.0136[sec]\n",
            "2024-08-13 18:44:35,107 - INFO - joeynmt.training - EPOCH 61\n",
            "2024-08-13 18:44:53,782 - INFO - joeynmt.training - Epoch  61, Step:    18000, Batch Loss:     0.348325, Batch Acc: 0.966857, Tokens per Sec:     2941, Lr: 0.000300\n",
            "2024-08-13 18:44:53,783 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=18042\n",
            "2024-08-13 18:44:53,783 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 193.76it/s]\n",
            "2024-08-13 18:45:01,319 - INFO - joeynmt.prediction - Generation took 7.5355[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 60497.93 examples/s]\n",
            "2024-08-13 18:45:01,529 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 18:45:01,529 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   5.72, loss:   4.36, ppl:  78.48, acc:   0.30, 0.1071[sec]\n",
            "2024-08-13 18:45:01,752 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/18000.ckpt.\n",
            "2024-08-13 18:45:01,753 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/10000.ckpt\n",
            "2024-08-13 18:45:01,786 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 18:45:01,871 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 18:45:01,871 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 18:45:01,871 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 18:45:01,962 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 18:45:02,007 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 18:45:02,007 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 18:45:02,007 - INFO - joeynmt.training - \tHypothesis: trois montée de l'enclos\n",
            "2024-08-13 18:45:02,098 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 18:45:02,142 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 18:45:02,142 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 18:45:02,142 - INFO - joeynmt.training - \tHypothesis: les ordis sont mûres\n",
            "2024-08-13 18:45:02,236 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 18:45:02,284 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 18:45:02,285 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 18:45:02,285 - INFO - joeynmt.training - \tHypothesis: un tour de travail\n",
            "2024-08-13 18:45:14,973 - INFO - joeynmt.training - Epoch  61, total training loss: 97.12, num. of seqs: 8065, num. of tokens: 90423, 31.2714[sec]\n",
            "2024-08-13 18:45:14,973 - INFO - joeynmt.training - EPOCH 62\n",
            "2024-08-13 18:45:45,586 - INFO - joeynmt.training - Epoch  62, total training loss: 95.08, num. of seqs: 8065, num. of tokens: 90423, 30.6119[sec]\n",
            "2024-08-13 18:45:45,586 - INFO - joeynmt.training - EPOCH 63\n",
            "2024-08-13 18:46:16,021 - INFO - joeynmt.training - Epoch  63, total training loss: 95.16, num. of seqs: 8065, num. of tokens: 90423, 30.4335[sec]\n",
            "2024-08-13 18:46:16,021 - INFO - joeynmt.training - EPOCH 64\n",
            "2024-08-13 18:46:46,220 - INFO - joeynmt.training - Epoch  64, total training loss: 93.83, num. of seqs: 8065, num. of tokens: 90423, 30.1977[sec]\n",
            "2024-08-13 18:46:46,220 - INFO - joeynmt.training - EPOCH 65\n",
            "2024-08-13 18:47:16,698 - INFO - joeynmt.training - Epoch  65, total training loss: 93.21, num. of seqs: 8065, num. of tokens: 90423, 30.4764[sec]\n",
            "2024-08-13 18:47:16,698 - INFO - joeynmt.training - EPOCH 66\n",
            "2024-08-13 18:47:47,245 - INFO - joeynmt.training - Epoch  66, total training loss: 92.50, num. of seqs: 8065, num. of tokens: 90423, 30.5450[sec]\n",
            "2024-08-13 18:47:47,245 - INFO - joeynmt.training - EPOCH 67\n",
            "2024-08-13 18:48:17,264 - INFO - joeynmt.training - Epoch  67, total training loss: 91.35, num. of seqs: 8065, num. of tokens: 90423, 30.0182[sec]\n",
            "2024-08-13 18:48:17,265 - INFO - joeynmt.training - EPOCH 68\n",
            "2024-08-13 18:48:27,800 - INFO - joeynmt.training - Epoch  68, Step:    20000, Batch Loss:     0.282247, Batch Acc: 0.973153, Tokens per Sec:     2942, Lr: 0.000300\n",
            "2024-08-13 18:48:27,801 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=20042\n",
            "2024-08-13 18:48:27,801 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 182.62it/s]\n",
            "2024-08-13 18:48:35,797 - INFO - joeynmt.prediction - Generation took 7.9952[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 60769.65 examples/s]\n",
            "2024-08-13 18:48:35,993 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 18:48:35,993 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   5.78, loss:   4.29, ppl:  73.24, acc:   0.31, 0.1026[sec]\n",
            "2024-08-13 18:48:36,237 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/20000.ckpt.\n",
            "2024-08-13 18:48:36,238 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/18000.ckpt\n",
            "2024-08-13 18:48:36,269 - INFO - joeynmt.helpers - delete /saved_model/dyu_fr/18000.ckpt\n",
            "2024-08-13 18:48:36,269 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /saved_model/dyu_fr/18000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/saved_model/dyu_fr/18000.ckpt')\n",
            "2024-08-13 18:48:36,269 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 18:48:36,315 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 18:48:36,316 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 18:48:36,316 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 18:48:36,407 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 18:48:36,453 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 18:48:36,454 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 18:48:36,454 - INFO - joeynmt.training - \tHypothesis: trois montée de l'enclos\n",
            "2024-08-13 18:48:36,546 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 18:48:36,590 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 18:48:36,591 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 18:48:36,591 - INFO - joeynmt.training - \tHypothesis: monsieur les jours s'écoulèrent\n",
            "2024-08-13 18:48:36,692 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 18:48:36,741 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 18:48:36,742 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 18:48:36,742 - INFO - joeynmt.training - \tHypothesis: un de travail\n",
            "2024-08-13 18:48:57,320 - INFO - joeynmt.training - Epoch  68, total training loss: 89.90, num. of seqs: 8065, num. of tokens: 90423, 31.0213[sec]\n",
            "2024-08-13 18:48:57,320 - INFO - joeynmt.training - EPOCH 69\n",
            "2024-08-13 18:49:28,763 - INFO - joeynmt.training - Epoch  69, total training loss: 89.02, num. of seqs: 8065, num. of tokens: 90423, 31.4422[sec]\n",
            "2024-08-13 18:49:28,763 - INFO - joeynmt.training - EPOCH 70\n",
            "2024-08-13 18:49:58,865 - INFO - joeynmt.training - Epoch  70, total training loss: 88.77, num. of seqs: 8065, num. of tokens: 90423, 30.1007[sec]\n",
            "2024-08-13 18:49:58,865 - INFO - joeynmt.training - EPOCH 71\n",
            "2024-08-13 18:50:29,023 - INFO - joeynmt.training - Epoch  71, total training loss: 88.16, num. of seqs: 8065, num. of tokens: 90423, 30.1567[sec]\n",
            "2024-08-13 18:50:29,023 - INFO - joeynmt.training - EPOCH 72\n",
            "2024-08-13 18:51:00,163 - INFO - joeynmt.training - Epoch  72, total training loss: 87.20, num. of seqs: 8065, num. of tokens: 90423, 31.1395[sec]\n",
            "2024-08-13 18:51:00,164 - INFO - joeynmt.training - EPOCH 73\n",
            "2024-08-13 18:51:30,477 - INFO - joeynmt.training - Epoch  73, total training loss: 87.07, num. of seqs: 8065, num. of tokens: 90423, 30.3126[sec]\n",
            "2024-08-13 18:51:30,477 - INFO - joeynmt.training - EPOCH 74\n",
            "2024-08-13 18:52:01,034 - INFO - joeynmt.training - Epoch  74, total training loss: 85.79, num. of seqs: 8065, num. of tokens: 90423, 30.5559[sec]\n",
            "2024-08-13 18:52:01,034 - INFO - joeynmt.training - EPOCH 75\n",
            "2024-08-13 18:52:03,358 - INFO - joeynmt.training - Epoch  75, Step:    22000, Batch Loss:     0.271806, Batch Acc: 0.977917, Tokens per Sec:     2399, Lr: 0.000300\n",
            "2024-08-13 18:52:03,359 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=22042\n",
            "2024-08-13 18:52:03,359 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:06<00:00, 211.83it/s]\n",
            "2024-08-13 18:52:10,252 - INFO - joeynmt.prediction - Generation took 6.8926[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 56717.82 examples/s]\n",
            "2024-08-13 18:52:10,450 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 18:52:10,451 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.12, loss:   4.32, ppl:  75.48, acc:   0.31, 0.1040[sec]\n",
            "2024-08-13 18:52:10,452 - INFO - joeynmt.training - Hooray! New best validation result [bleu]!\n",
            "2024-08-13 18:52:10,681 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/22000.ckpt.\n",
            "2024-08-13 18:52:10,682 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/16000.ckpt\n",
            "2024-08-13 18:52:10,714 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 18:52:10,763 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 18:52:10,763 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 18:52:10,763 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 18:52:10,855 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 18:52:10,900 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 18:52:10,900 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 18:52:10,900 - INFO - joeynmt.training - \tHypothesis: trois montée de l'avance\n",
            "2024-08-13 18:52:11,006 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 18:52:11,051 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 18:52:11,051 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 18:52:11,051 - INFO - joeynmt.training - \tHypothesis: des seges passentres\n",
            "2024-08-13 18:52:11,147 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 18:52:11,194 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 18:52:11,195 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 18:52:11,195 - INFO - joeynmt.training - \tHypothesis: un tour duil\n",
            "2024-08-13 18:52:41,617 - INFO - joeynmt.training - Epoch  75, total training loss: 85.59, num. of seqs: 8065, num. of tokens: 90423, 32.6491[sec]\n",
            "2024-08-13 18:52:41,617 - INFO - joeynmt.training - EPOCH 76\n",
            "2024-08-13 18:53:11,921 - INFO - joeynmt.training - Epoch  76, total training loss: 84.87, num. of seqs: 8065, num. of tokens: 90423, 30.3026[sec]\n",
            "2024-08-13 18:53:11,922 - INFO - joeynmt.training - EPOCH 77\n",
            "2024-08-13 18:53:42,138 - INFO - joeynmt.training - Epoch  77, total training loss: 83.69, num. of seqs: 8065, num. of tokens: 90423, 30.2151[sec]\n",
            "2024-08-13 18:53:42,138 - INFO - joeynmt.training - EPOCH 78\n",
            "2024-08-13 18:54:12,896 - INFO - joeynmt.training - Epoch  78, total training loss: 82.71, num. of seqs: 8065, num. of tokens: 90423, 30.7572[sec]\n",
            "2024-08-13 18:54:12,897 - INFO - joeynmt.training - EPOCH 79\n",
            "2024-08-13 18:54:43,033 - INFO - joeynmt.training - Epoch  79, total training loss: 82.84, num. of seqs: 8065, num. of tokens: 90423, 30.1345[sec]\n",
            "2024-08-13 18:54:43,033 - INFO - joeynmt.training - EPOCH 80\n",
            "2024-08-13 18:55:12,819 - INFO - joeynmt.training - Epoch  80, total training loss: 79.91, num. of seqs: 8065, num. of tokens: 90423, 29.7845[sec]\n",
            "2024-08-13 18:55:12,819 - INFO - joeynmt.training - EPOCH 81\n",
            "2024-08-13 18:55:37,380 - INFO - joeynmt.training - Epoch  81, Step:    24000, Batch Loss:     0.266612, Batch Acc: 0.977253, Tokens per Sec:     2971, Lr: 0.000300\n",
            "2024-08-13 18:55:37,381 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=24042\n",
            "2024-08-13 18:55:37,381 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 191.06it/s]\n",
            "2024-08-13 18:55:45,023 - INFO - joeynmt.prediction - Generation took 7.6417[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 60165.20 examples/s]\n",
            "2024-08-13 18:55:45,219 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 18:55:45,219 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.19, loss:   4.29, ppl:  73.14, acc:   0.31, 0.1020[sec]\n",
            "2024-08-13 18:55:45,220 - INFO - joeynmt.training - Hooray! New best validation result [bleu]!\n",
            "2024-08-13 18:55:45,449 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/24000.ckpt.\n",
            "2024-08-13 18:55:45,450 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/20000.ckpt\n",
            "2024-08-13 18:55:45,481 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 18:55:45,538 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 18:55:45,539 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 18:55:45,539 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 18:55:45,627 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 18:55:45,672 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 18:55:45,672 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 18:55:45,672 - INFO - joeynmt.training - \tHypothesis: trois point d’avance\n",
            "2024-08-13 18:55:45,763 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 18:55:45,807 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 18:55:45,807 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 18:55:45,807 - INFO - joeynmt.training - \tHypothesis: des ducle d’entrer\n",
            "2024-08-13 18:55:45,896 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 18:55:45,940 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 18:55:45,941 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 18:55:45,941 - INFO - joeynmt.training - \tHypothesis: d'un tonn\n",
            "2024-08-13 18:55:51,791 - INFO - joeynmt.training - Epoch  81, total training loss: 80.36, num. of seqs: 8065, num. of tokens: 90423, 30.3112[sec]\n",
            "2024-08-13 18:55:51,791 - INFO - joeynmt.training - EPOCH 82\n",
            "2024-08-13 18:56:23,592 - INFO - joeynmt.training - Epoch  82, total training loss: 80.57, num. of seqs: 8065, num. of tokens: 90423, 31.8002[sec]\n",
            "2024-08-13 18:56:23,593 - INFO - joeynmt.training - EPOCH 83\n",
            "2024-08-13 18:56:53,815 - INFO - joeynmt.training - Epoch  83, total training loss: 80.24, num. of seqs: 8065, num. of tokens: 90423, 30.2216[sec]\n",
            "2024-08-13 18:56:53,816 - INFO - joeynmt.training - EPOCH 84\n",
            "2024-08-13 18:57:24,232 - INFO - joeynmt.training - Epoch  84, total training loss: 79.43, num. of seqs: 8065, num. of tokens: 90423, 30.4150[sec]\n",
            "2024-08-13 18:57:24,232 - INFO - joeynmt.training - EPOCH 85\n",
            "2024-08-13 18:57:55,442 - INFO - joeynmt.training - Epoch  85, total training loss: 78.10, num. of seqs: 8065, num. of tokens: 90423, 31.2090[sec]\n",
            "2024-08-13 18:57:55,442 - INFO - joeynmt.training - EPOCH 86\n",
            "2024-08-13 18:58:25,834 - INFO - joeynmt.training - Epoch  86, total training loss: 78.29, num. of seqs: 8065, num. of tokens: 90423, 30.3911[sec]\n",
            "2024-08-13 18:58:25,834 - INFO - joeynmt.training - EPOCH 87\n",
            "2024-08-13 18:58:56,190 - INFO - joeynmt.training - Epoch  87, total training loss: 77.69, num. of seqs: 8065, num. of tokens: 90423, 30.3548[sec]\n",
            "2024-08-13 18:58:56,190 - INFO - joeynmt.training - EPOCH 88\n",
            "2024-08-13 18:59:13,770 - INFO - joeynmt.training - Epoch  88, Step:    26000, Batch Loss:     0.252209, Batch Acc: 0.979532, Tokens per Sec:     2832, Lr: 0.000300\n",
            "2024-08-13 18:59:13,771 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=26042\n",
            "2024-08-13 18:59:13,771 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 197.49it/s]\n",
            "2024-08-13 18:59:21,164 - INFO - joeynmt.prediction - Generation took 7.3930[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 48987.44 examples/s]\n",
            "2024-08-13 18:59:21,366 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 18:59:21,366 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.07, loss:   4.27, ppl:  71.48, acc:   0.31, 0.1040[sec]\n",
            "2024-08-13 18:59:21,591 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/26000.ckpt.\n",
            "2024-08-13 18:59:21,592 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/14000.ckpt\n",
            "2024-08-13 18:59:21,616 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 18:59:21,664 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 18:59:21,664 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 18:59:21,664 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 18:59:21,769 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 18:59:21,813 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 18:59:21,814 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 18:59:21,814 - INFO - joeynmt.training - \tHypothesis: trois points d'avance\n",
            "2024-08-13 18:59:21,907 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 18:59:21,954 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 18:59:21,954 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 18:59:21,954 - INFO - joeynmt.training - \tHypothesis: les étés du mondent\n",
            "2024-08-13 18:59:22,044 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 18:59:22,089 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 18:59:22,089 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 18:59:22,089 - INFO - joeynmt.training - \tHypothesis: mêmes mouvements\n",
            "2024-08-13 18:59:36,735 - INFO - joeynmt.training - Epoch  88, total training loss: 76.39, num. of seqs: 8065, num. of tokens: 90423, 32.1296[sec]\n",
            "2024-08-13 18:59:36,735 - INFO - joeynmt.training - EPOCH 89\n",
            "2024-08-13 19:00:07,837 - INFO - joeynmt.training - Epoch  89, total training loss: 76.97, num. of seqs: 8065, num. of tokens: 90423, 31.0999[sec]\n",
            "2024-08-13 19:00:07,837 - INFO - joeynmt.training - EPOCH 90\n",
            "2024-08-13 19:00:38,058 - INFO - joeynmt.training - Epoch  90, total training loss: 75.98, num. of seqs: 8065, num. of tokens: 90423, 30.2199[sec]\n",
            "2024-08-13 19:00:38,058 - INFO - joeynmt.training - EPOCH 91\n",
            "2024-08-13 19:01:09,386 - INFO - joeynmt.training - Epoch  91, total training loss: 76.20, num. of seqs: 8065, num. of tokens: 90423, 31.3267[sec]\n",
            "2024-08-13 19:01:09,386 - INFO - joeynmt.training - EPOCH 92\n",
            "2024-08-13 19:01:39,598 - INFO - joeynmt.training - Epoch  92, total training loss: 75.88, num. of seqs: 8065, num. of tokens: 90423, 30.2102[sec]\n",
            "2024-08-13 19:01:39,598 - INFO - joeynmt.training - EPOCH 93\n",
            "2024-08-13 19:02:09,823 - INFO - joeynmt.training - Epoch  93, total training loss: 75.08, num. of seqs: 8065, num. of tokens: 90423, 30.2234[sec]\n",
            "2024-08-13 19:02:09,823 - INFO - joeynmt.training - EPOCH 94\n",
            "2024-08-13 19:02:40,838 - INFO - joeynmt.training - Epoch  94, total training loss: 73.55, num. of seqs: 8065, num. of tokens: 90423, 31.0144[sec]\n",
            "2024-08-13 19:02:40,839 - INFO - joeynmt.training - EPOCH 95\n",
            "2024-08-13 19:02:48,573 - INFO - joeynmt.training - Epoch  95, Step:    28000, Batch Loss:     0.236150, Batch Acc: 0.981811, Tokens per Sec:     3178, Lr: 0.000300\n",
            "2024-08-13 19:02:48,573 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=28042\n",
            "2024-08-13 19:02:48,574 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 183.82it/s]\n",
            "2024-08-13 19:02:56,517 - INFO - joeynmt.prediction - Generation took 7.9429[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 59947.74 examples/s]\n",
            "2024-08-13 19:02:56,711 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:02:56,711 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.11, loss:   4.26, ppl:  70.47, acc:   0.31, 0.1026[sec]\n",
            "2024-08-13 19:02:56,949 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/28000.ckpt.\n",
            "2024-08-13 19:02:56,950 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/26000.ckpt\n",
            "2024-08-13 19:02:56,978 - INFO - joeynmt.helpers - delete /saved_model/dyu_fr/26000.ckpt\n",
            "2024-08-13 19:02:56,978 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /saved_model/dyu_fr/26000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/saved_model/dyu_fr/26000.ckpt')\n",
            "2024-08-13 19:02:56,978 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:02:57,026 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:02:57,027 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:02:57,027 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 19:02:57,127 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:02:57,170 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:02:57,171 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:02:57,171 - INFO - joeynmt.training - \tHypothesis: trois point d’avance\n",
            "2024-08-13 19:02:57,263 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:02:57,311 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:02:57,311 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:02:57,311 - INFO - joeynmt.training - \tHypothesis: je n’ai pas dans les mains\n",
            "2024-08-13 19:02:57,402 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:02:57,449 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:02:57,450 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:02:57,450 - INFO - joeynmt.training - \tHypothesis: un autre « vous\n",
            "2024-08-13 19:03:20,951 - INFO - joeynmt.training - Epoch  95, total training loss: 74.04, num. of seqs: 8065, num. of tokens: 90423, 31.1391[sec]\n",
            "2024-08-13 19:03:20,951 - INFO - joeynmt.training - EPOCH 96\n",
            "2024-08-13 19:03:51,424 - INFO - joeynmt.training - Epoch  96, total training loss: 73.57, num. of seqs: 8065, num. of tokens: 90423, 30.4716[sec]\n",
            "2024-08-13 19:03:51,424 - INFO - joeynmt.training - EPOCH 97\n",
            "2024-08-13 19:04:21,386 - INFO - joeynmt.training - Epoch  97, total training loss: 72.22, num. of seqs: 8065, num. of tokens: 90423, 29.9613[sec]\n",
            "2024-08-13 19:04:21,387 - INFO - joeynmt.training - EPOCH 98\n",
            "2024-08-13 19:04:52,468 - INFO - joeynmt.training - Epoch  98, total training loss: 72.20, num. of seqs: 8065, num. of tokens: 90423, 31.0805[sec]\n",
            "2024-08-13 19:04:52,468 - INFO - joeynmt.training - EPOCH 99\n",
            "2024-08-13 19:05:22,537 - INFO - joeynmt.training - Epoch  99, total training loss: 71.85, num. of seqs: 8065, num. of tokens: 90423, 30.0676[sec]\n",
            "2024-08-13 19:05:22,537 - INFO - joeynmt.training - EPOCH 100\n",
            "2024-08-13 19:05:52,950 - INFO - joeynmt.training - Epoch 100, total training loss: 72.55, num. of seqs: 8065, num. of tokens: 90423, 30.4112[sec]\n",
            "2024-08-13 19:05:52,950 - INFO - joeynmt.training - EPOCH 101\n",
            "2024-08-13 19:06:23,846 - INFO - joeynmt.training - Epoch 101, Step:    30000, Batch Loss:     0.245615, Batch Acc: 0.982913, Tokens per Sec:     2913, Lr: 0.000300\n",
            "2024-08-13 19:06:23,847 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=30042\n",
            "2024-08-13 19:06:23,847 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 206.11it/s]\n",
            "2024-08-13 19:06:30,932 - INFO - joeynmt.prediction - Generation took 7.0839[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 59711.03 examples/s]\n",
            "2024-08-13 19:06:31,132 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:06:31,132 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.52, loss:   4.26, ppl:  70.91, acc:   0.32, 0.1014[sec]\n",
            "2024-08-13 19:06:31,133 - INFO - joeynmt.training - Hooray! New best validation result [bleu]!\n",
            "2024-08-13 19:06:31,382 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/30000.ckpt.\n",
            "2024-08-13 19:06:31,383 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/28000.ckpt\n",
            "2024-08-13 19:06:31,415 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:06:31,499 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:06:31,500 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:06:31,500 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 19:06:31,639 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:06:31,730 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:06:31,731 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:06:31,731 - INFO - joeynmt.training - \tHypothesis: trois point d'avance\n",
            "2024-08-13 19:06:31,891 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:06:31,967 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:06:31,967 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:06:31,968 - INFO - joeynmt.training - \tHypothesis: les trésports éclatent\n",
            "2024-08-13 19:06:32,126 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:06:32,203 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:06:32,204 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:06:32,204 - INFO - joeynmt.training - \tHypothesis: un d'oiseau\n",
            "2024-08-13 19:06:32,540 - INFO - joeynmt.training - Epoch 101, total training loss: 71.45, num. of seqs: 8065, num. of tokens: 90423, 31.0655[sec]\n",
            "2024-08-13 19:06:32,540 - INFO - joeynmt.training - EPOCH 102\n",
            "2024-08-13 19:07:04,414 - INFO - joeynmt.training - Epoch 102, total training loss: 70.14, num. of seqs: 8065, num. of tokens: 90423, 31.8720[sec]\n",
            "2024-08-13 19:07:04,414 - INFO - joeynmt.training - EPOCH 103\n",
            "2024-08-13 19:07:34,662 - INFO - joeynmt.training - Epoch 103, total training loss: 70.11, num. of seqs: 8065, num. of tokens: 90423, 30.2471[sec]\n",
            "2024-08-13 19:07:34,662 - INFO - joeynmt.training - EPOCH 104\n",
            "2024-08-13 19:08:06,010 - INFO - joeynmt.training - Epoch 104, total training loss: 70.96, num. of seqs: 8065, num. of tokens: 90423, 31.3467[sec]\n",
            "2024-08-13 19:08:06,010 - INFO - joeynmt.training - EPOCH 105\n",
            "2024-08-13 19:08:36,151 - INFO - joeynmt.training - Epoch 105, total training loss: 69.93, num. of seqs: 8065, num. of tokens: 90423, 30.1405[sec]\n",
            "2024-08-13 19:08:36,152 - INFO - joeynmt.training - EPOCH 106\n",
            "2024-08-13 19:09:06,286 - INFO - joeynmt.training - Epoch 106, total training loss: 69.58, num. of seqs: 8065, num. of tokens: 90423, 30.1341[sec]\n",
            "2024-08-13 19:09:06,287 - INFO - joeynmt.training - EPOCH 107\n",
            "2024-08-13 19:09:37,123 - INFO - joeynmt.training - Epoch 107, total training loss: 67.75, num. of seqs: 8065, num. of tokens: 90423, 30.8354[sec]\n",
            "2024-08-13 19:09:37,123 - INFO - joeynmt.training - EPOCH 108\n",
            "2024-08-13 19:09:58,559 - INFO - joeynmt.training - Epoch 108, Step:    32000, Batch Loss:     0.265211, Batch Acc: 0.984140, Tokens per Sec:     3044, Lr: 0.000300\n",
            "2024-08-13 19:09:58,560 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=32042\n",
            "2024-08-13 19:09:58,560 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 183.33it/s]\n",
            "2024-08-13 19:10:06,525 - INFO - joeynmt.prediction - Generation took 7.9643[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 58299.91 examples/s]\n",
            "2024-08-13 19:10:06,739 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:10:06,739 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.34, loss:   4.25, ppl:  70.19, acc:   0.31, 0.1177[sec]\n",
            "2024-08-13 19:10:06,969 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/32000.ckpt.\n",
            "2024-08-13 19:10:06,970 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/22000.ckpt\n",
            "2024-08-13 19:10:07,001 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:10:07,051 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:10:07,052 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:10:07,052 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 19:10:07,140 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:10:07,185 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:10:07,185 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:10:07,185 - INFO - joeynmt.training - \tHypothesis: trois point d'avance\n",
            "2024-08-13 19:10:07,278 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:10:07,323 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:10:07,324 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:10:07,324 - INFO - joeynmt.training - \tHypothesis: dans les saleuvés\n",
            "2024-08-13 19:10:07,415 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:10:07,462 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:10:07,462 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:10:07,463 - INFO - joeynmt.training - \tHypothesis: l'un et l'autre\n",
            "2024-08-13 19:10:16,800 - INFO - joeynmt.training - Epoch 108, total training loss: 68.77, num. of seqs: 8065, num. of tokens: 90423, 30.6793[sec]\n",
            "2024-08-13 19:10:16,800 - INFO - joeynmt.training - EPOCH 109\n",
            "2024-08-13 19:10:47,552 - INFO - joeynmt.training - Epoch 109, total training loss: 68.85, num. of seqs: 8065, num. of tokens: 90423, 30.7510[sec]\n",
            "2024-08-13 19:10:47,553 - INFO - joeynmt.training - EPOCH 110\n",
            "2024-08-13 19:11:17,872 - INFO - joeynmt.training - Epoch 110, total training loss: 67.44, num. of seqs: 8065, num. of tokens: 90423, 30.3191[sec]\n",
            "2024-08-13 19:11:17,873 - INFO - joeynmt.training - EPOCH 111\n",
            "2024-08-13 19:11:49,043 - INFO - joeynmt.training - Epoch 111, total training loss: 68.12, num. of seqs: 8065, num. of tokens: 90423, 31.1690[sec]\n",
            "2024-08-13 19:11:49,043 - INFO - joeynmt.training - EPOCH 112\n",
            "2024-08-13 19:12:19,179 - INFO - joeynmt.training - Epoch 112, total training loss: 66.90, num. of seqs: 8065, num. of tokens: 90423, 30.1346[sec]\n",
            "2024-08-13 19:12:19,179 - INFO - joeynmt.training - EPOCH 113\n",
            "2024-08-13 19:12:49,818 - INFO - joeynmt.training - Epoch 113, total training loss: 66.75, num. of seqs: 8065, num. of tokens: 90423, 30.6383[sec]\n",
            "2024-08-13 19:12:49,819 - INFO - joeynmt.training - EPOCH 114\n",
            "2024-08-13 19:13:20,639 - INFO - joeynmt.training - Epoch 114, total training loss: 66.77, num. of seqs: 8065, num. of tokens: 90423, 30.8189[sec]\n",
            "2024-08-13 19:13:20,639 - INFO - joeynmt.training - EPOCH 115\n",
            "2024-08-13 19:13:34,480 - INFO - joeynmt.training - Epoch 115, Step:    34000, Batch Loss:     0.216533, Batch Acc: 0.986286, Tokens per Sec:     3014, Lr: 0.000300\n",
            "2024-08-13 19:13:34,481 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=34042\n",
            "2024-08-13 19:13:34,481 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 188.98it/s]\n",
            "2024-08-13 19:13:42,208 - INFO - joeynmt.prediction - Generation took 7.7262[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 34948.38 examples/s]\n",
            "2024-08-13 19:13:42,551 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:13:42,551 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.08, loss:   4.24, ppl:  69.34, acc:   0.31, 0.1715[sec]\n",
            "2024-08-13 19:13:42,552 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:13:42,638 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:13:42,638 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:13:42,638 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 19:13:42,800 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:13:42,887 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:13:42,887 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:13:42,888 - INFO - joeynmt.training - \tHypothesis: trois fois plus grand\n",
            "2024-08-13 19:13:43,046 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:13:43,136 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:13:43,136 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:13:43,136 - INFO - joeynmt.training - \tHypothesis: monsieur la journée\n",
            "2024-08-13 19:13:43,296 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:13:43,374 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:13:43,374 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:13:43,375 - INFO - joeynmt.training - \tHypothesis: un tour d'entre\n",
            "2024-08-13 19:14:00,768 - INFO - joeynmt.training - Epoch 115, total training loss: 65.71, num. of seqs: 8065, num. of tokens: 90423, 30.7047[sec]\n",
            "2024-08-13 19:14:00,769 - INFO - joeynmt.training - EPOCH 116\n",
            "2024-08-13 19:14:31,237 - INFO - joeynmt.training - Epoch 116, total training loss: 65.75, num. of seqs: 8065, num. of tokens: 90423, 30.4677[sec]\n",
            "2024-08-13 19:14:31,238 - INFO - joeynmt.training - EPOCH 117\n",
            "2024-08-13 19:15:02,225 - INFO - joeynmt.training - Epoch 117, total training loss: 65.55, num. of seqs: 8065, num. of tokens: 90423, 30.9864[sec]\n",
            "2024-08-13 19:15:02,226 - INFO - joeynmt.training - EPOCH 118\n",
            "2024-08-13 19:15:32,289 - INFO - joeynmt.training - Epoch 118, total training loss: 65.20, num. of seqs: 8065, num. of tokens: 90423, 30.0628[sec]\n",
            "2024-08-13 19:15:32,290 - INFO - joeynmt.training - EPOCH 119\n",
            "2024-08-13 19:16:02,146 - INFO - joeynmt.training - Epoch 119, total training loss: 64.79, num. of seqs: 8065, num. of tokens: 90423, 29.8548[sec]\n",
            "2024-08-13 19:16:02,146 - INFO - joeynmt.training - EPOCH 120\n",
            "2024-08-13 19:16:33,414 - INFO - joeynmt.training - Epoch 120, total training loss: 64.60, num. of seqs: 8065, num. of tokens: 90423, 31.2673[sec]\n",
            "2024-08-13 19:16:33,414 - INFO - joeynmt.training - EPOCH 121\n",
            "2024-08-13 19:17:03,503 - INFO - joeynmt.training - Epoch 121, total training loss: 63.85, num. of seqs: 8065, num. of tokens: 90423, 30.0873[sec]\n",
            "2024-08-13 19:17:03,503 - INFO - joeynmt.training - EPOCH 122\n",
            "2024-08-13 19:17:09,962 - INFO - joeynmt.training - Epoch 122, Step:    36000, Batch Loss:     0.221640, Batch Acc: 0.986762, Tokens per Sec:     2971, Lr: 0.000300\n",
            "2024-08-13 19:17:09,963 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=36042\n",
            "2024-08-13 19:17:09,963 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 188.08it/s]\n",
            "2024-08-13 19:17:17,727 - INFO - joeynmt.prediction - Generation took 7.7630[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 58776.44 examples/s]\n",
            "2024-08-13 19:17:17,927 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:17:17,927 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.31, loss:   4.24, ppl:  69.49, acc:   0.31, 0.1070[sec]\n",
            "2024-08-13 19:17:18,158 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/36000.ckpt.\n",
            "2024-08-13 19:17:18,159 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/24000.ckpt\n",
            "2024-08-13 19:17:18,192 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:17:18,238 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:17:18,238 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:17:18,238 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 19:17:18,336 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:17:18,389 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:17:18,389 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:17:18,389 - INFO - joeynmt.training - \tHypothesis: trois points d'avance\n",
            "2024-08-13 19:17:18,494 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:17:18,541 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:17:18,541 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:17:18,541 - INFO - joeynmt.training - \tHypothesis: monsieur t’assait\n",
            "2024-08-13 19:17:18,633 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:17:18,677 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:17:18,678 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:17:18,678 - INFO - joeynmt.training - \tHypothesis: un autre changement\n",
            "2024-08-13 19:17:43,989 - INFO - joeynmt.training - Epoch 122, total training loss: 63.68, num. of seqs: 8065, num. of tokens: 90423, 31.6710[sec]\n",
            "2024-08-13 19:17:43,989 - INFO - joeynmt.training - EPOCH 123\n",
            "2024-08-13 19:18:15,037 - INFO - joeynmt.training - Epoch 123, total training loss: 63.99, num. of seqs: 8065, num. of tokens: 90423, 31.0471[sec]\n",
            "2024-08-13 19:18:15,037 - INFO - joeynmt.training - EPOCH 124\n",
            "2024-08-13 19:18:45,991 - INFO - joeynmt.training - Epoch 124, total training loss: 64.32, num. of seqs: 8065, num. of tokens: 90423, 30.9528[sec]\n",
            "2024-08-13 19:18:45,992 - INFO - joeynmt.training - EPOCH 125\n",
            "2024-08-13 19:19:16,361 - INFO - joeynmt.training - Epoch 125, total training loss: 63.14, num. of seqs: 8065, num. of tokens: 90423, 30.3684[sec]\n",
            "2024-08-13 19:19:16,361 - INFO - joeynmt.training - EPOCH 126\n",
            "2024-08-13 19:19:47,524 - INFO - joeynmt.training - Epoch 126, total training loss: 63.12, num. of seqs: 8065, num. of tokens: 90423, 31.1613[sec]\n",
            "2024-08-13 19:19:47,524 - INFO - joeynmt.training - EPOCH 127\n",
            "2024-08-13 19:20:18,081 - INFO - joeynmt.training - Epoch 127, total training loss: 62.32, num. of seqs: 8065, num. of tokens: 90423, 30.5560[sec]\n",
            "2024-08-13 19:20:18,081 - INFO - joeynmt.training - EPOCH 128\n",
            "2024-08-13 19:20:46,709 - INFO - joeynmt.training - Epoch 128, Step:    38000, Batch Loss:     0.235440, Batch Acc: 0.986893, Tokens per Sec:     2932, Lr: 0.000300\n",
            "2024-08-13 19:20:46,709 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=38042\n",
            "2024-08-13 19:20:46,710 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:08<00:00, 179.19it/s]\n",
            "2024-08-13 19:20:54,858 - INFO - joeynmt.prediction - Generation took 8.1482[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 40991.68 examples/s]\n",
            "2024-08-13 19:20:55,065 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:20:55,065 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.48, loss:   4.22, ppl:  68.15, acc:   0.31, 0.1014[sec]\n",
            "2024-08-13 19:20:55,286 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/38000.ckpt.\n",
            "2024-08-13 19:20:55,287 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/36000.ckpt\n",
            "2024-08-13 19:20:55,322 - INFO - joeynmt.helpers - delete /saved_model/dyu_fr/36000.ckpt\n",
            "2024-08-13 19:20:55,322 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /saved_model/dyu_fr/36000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/saved_model/dyu_fr/36000.ckpt')\n",
            "2024-08-13 19:20:55,323 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:20:55,379 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:20:55,379 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:20:55,379 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 19:20:55,471 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:20:55,515 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:20:55,515 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:20:55,515 - INFO - joeynmt.training - \tHypothesis: trois montée de l'enclos\n",
            "2024-08-13 19:20:55,607 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:20:55,652 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:20:55,653 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:20:55,653 - INFO - joeynmt.training - \tHypothesis: je ne vois pas l’acle\n",
            "2024-08-13 19:20:55,759 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:20:55,804 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:20:55,804 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:20:55,804 - INFO - joeynmt.training - \tHypothesis: de même une chose\n",
            "2024-08-13 19:20:58,103 - INFO - joeynmt.training - Epoch 128, total training loss: 63.32, num. of seqs: 8065, num. of tokens: 90423, 30.8342[sec]\n",
            "2024-08-13 19:20:58,103 - INFO - joeynmt.training - EPOCH 129\n",
            "2024-08-13 19:21:28,940 - INFO - joeynmt.training - Epoch 129, total training loss: 62.25, num. of seqs: 8065, num. of tokens: 90423, 30.8361[sec]\n",
            "2024-08-13 19:21:28,941 - INFO - joeynmt.training - EPOCH 130\n",
            "2024-08-13 19:22:00,298 - INFO - joeynmt.training - Epoch 130, total training loss: 61.55, num. of seqs: 8065, num. of tokens: 90423, 31.3569[sec]\n",
            "2024-08-13 19:22:00,299 - INFO - joeynmt.training - EPOCH 131\n",
            "2024-08-13 19:22:30,634 - INFO - joeynmt.training - Epoch 131, total training loss: 61.28, num. of seqs: 8065, num. of tokens: 90423, 30.3335[sec]\n",
            "2024-08-13 19:22:30,634 - INFO - joeynmt.training - EPOCH 132\n",
            "2024-08-13 19:23:01,136 - INFO - joeynmt.training - Epoch 132, total training loss: 61.88, num. of seqs: 8065, num. of tokens: 90423, 30.5012[sec]\n",
            "2024-08-13 19:23:01,136 - INFO - joeynmt.training - EPOCH 133\n",
            "2024-08-13 19:23:32,084 - INFO - joeynmt.training - Epoch 133, total training loss: 61.37, num. of seqs: 8065, num. of tokens: 90423, 30.9460[sec]\n",
            "2024-08-13 19:23:32,084 - INFO - joeynmt.training - EPOCH 134\n",
            "2024-08-13 19:24:02,112 - INFO - joeynmt.training - Epoch 134, total training loss: 60.37, num. of seqs: 8065, num. of tokens: 90423, 30.0269[sec]\n",
            "2024-08-13 19:24:02,113 - INFO - joeynmt.training - EPOCH 135\n",
            "2024-08-13 19:24:22,778 - INFO - joeynmt.training - Epoch 135, Step:    40000, Batch Loss:     0.208422, Batch Acc: 0.988742, Tokens per Sec:     2910, Lr: 0.000300\n",
            "2024-08-13 19:24:22,779 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=40042\n",
            "2024-08-13 19:24:22,779 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 195.73it/s]\n",
            "2024-08-13 19:24:30,240 - INFO - joeynmt.prediction - Generation took 7.4599[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 59251.71 examples/s]\n",
            "2024-08-13 19:24:30,440 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:24:30,440 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.28, loss:   4.20, ppl:  66.60, acc:   0.31, 0.1064[sec]\n",
            "2024-08-13 19:24:30,441 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:24:30,489 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:24:30,489 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:24:30,489 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 19:24:30,591 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:24:30,637 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:24:30,637 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:24:30,637 - INFO - joeynmt.training - \tHypothesis: trois point d’avance\n",
            "2024-08-13 19:24:30,725 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:24:30,770 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:24:30,770 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:24:30,770 - INFO - joeynmt.training - \tHypothesis: il n'est pas exletra pas dans les pachles\n",
            "2024-08-13 19:24:30,934 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:24:31,019 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:24:31,019 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:24:31,019 - INFO - joeynmt.training - \tHypothesis: un autre\n",
            "2024-08-13 19:24:42,240 - INFO - joeynmt.training - Epoch 135, total training loss: 60.91, num. of seqs: 8065, num. of tokens: 90423, 31.7272[sec]\n",
            "2024-08-13 19:24:42,241 - INFO - joeynmt.training - EPOCH 136\n",
            "2024-08-13 19:25:13,687 - INFO - joeynmt.training - Epoch 136, total training loss: 60.27, num. of seqs: 8065, num. of tokens: 90423, 31.4451[sec]\n",
            "2024-08-13 19:25:13,687 - INFO - joeynmt.training - EPOCH 137\n",
            "2024-08-13 19:25:44,041 - INFO - joeynmt.training - Epoch 137, total training loss: 60.08, num. of seqs: 8065, num. of tokens: 90423, 30.3535[sec]\n",
            "2024-08-13 19:25:44,042 - INFO - joeynmt.training - EPOCH 138\n",
            "2024-08-13 19:26:14,114 - INFO - joeynmt.training - Epoch 138, total training loss: 60.60, num. of seqs: 8065, num. of tokens: 90423, 30.0709[sec]\n",
            "2024-08-13 19:26:14,114 - INFO - joeynmt.training - EPOCH 139\n",
            "2024-08-13 19:26:44,985 - INFO - joeynmt.training - Epoch 139, total training loss: 59.58, num. of seqs: 8065, num. of tokens: 90423, 30.8706[sec]\n",
            "2024-08-13 19:26:44,985 - INFO - joeynmt.training - EPOCH 140\n",
            "2024-08-13 19:27:14,979 - INFO - joeynmt.training - Epoch 140, total training loss: 59.37, num. of seqs: 8065, num. of tokens: 90423, 29.9933[sec]\n",
            "2024-08-13 19:27:14,980 - INFO - joeynmt.training - EPOCH 141\n",
            "2024-08-13 19:27:45,500 - INFO - joeynmt.training - Epoch 141, total training loss: 59.00, num. of seqs: 8065, num. of tokens: 90423, 30.5198[sec]\n",
            "2024-08-13 19:27:45,501 - INFO - joeynmt.training - EPOCH 142\n",
            "2024-08-13 19:27:57,953 - INFO - joeynmt.training - Epoch 142, Step:    42000, Batch Loss:     0.202109, Batch Acc: 0.989284, Tokens per Sec:     2938, Lr: 0.000300\n",
            "2024-08-13 19:27:57,954 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=42042\n",
            "2024-08-13 19:27:57,954 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:08<00:00, 177.27it/s]\n",
            "2024-08-13 19:28:06,191 - INFO - joeynmt.prediction - Generation took 8.2364[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 57775.27 examples/s]\n",
            "2024-08-13 19:28:06,398 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:28:06,398 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.77, loss:   4.20, ppl:  66.90, acc:   0.32, 0.1069[sec]\n",
            "2024-08-13 19:28:06,399 - INFO - joeynmt.training - Hooray! New best validation result [bleu]!\n",
            "2024-08-13 19:28:06,635 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/42000.ckpt.\n",
            "2024-08-13 19:28:06,636 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/32000.ckpt\n",
            "2024-08-13 19:28:06,668 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:28:06,715 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:28:06,715 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:28:06,715 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 19:28:06,808 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:28:06,852 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:28:06,853 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:28:06,853 - INFO - joeynmt.training - \tHypothesis: trois point d'avance\n",
            "2024-08-13 19:28:06,947 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:28:06,992 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:28:06,992 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:28:06,992 - INFO - joeynmt.training - \tHypothesis: des joueurs de l'est\n",
            "2024-08-13 19:28:07,080 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:28:07,125 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:28:07,125 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:28:07,125 - INFO - joeynmt.training - \tHypothesis: un d'où sontil\n",
            "2024-08-13 19:28:26,659 - INFO - joeynmt.training - Epoch 142, total training loss: 58.71, num. of seqs: 8065, num. of tokens: 90423, 31.8940[sec]\n",
            "2024-08-13 19:28:26,659 - INFO - joeynmt.training - EPOCH 143\n",
            "2024-08-13 19:28:57,489 - INFO - joeynmt.training - Epoch 143, total training loss: 59.35, num. of seqs: 8065, num. of tokens: 90423, 30.8284[sec]\n",
            "2024-08-13 19:28:57,489 - INFO - joeynmt.training - EPOCH 144\n",
            "2024-08-13 19:29:27,720 - INFO - joeynmt.training - Epoch 144, total training loss: 59.32, num. of seqs: 8065, num. of tokens: 90423, 30.2294[sec]\n",
            "2024-08-13 19:29:27,720 - INFO - joeynmt.training - EPOCH 145\n",
            "2024-08-13 19:29:59,089 - INFO - joeynmt.training - Epoch 145, total training loss: 59.25, num. of seqs: 8065, num. of tokens: 90423, 31.3689[sec]\n",
            "2024-08-13 19:29:59,090 - INFO - joeynmt.training - EPOCH 146\n",
            "2024-08-13 19:30:29,271 - INFO - joeynmt.training - Epoch 146, total training loss: 58.36, num. of seqs: 8065, num. of tokens: 90423, 30.1799[sec]\n",
            "2024-08-13 19:30:29,271 - INFO - joeynmt.training - EPOCH 147\n",
            "2024-08-13 19:30:59,515 - INFO - joeynmt.training - Epoch 147, total training loss: 57.73, num. of seqs: 8065, num. of tokens: 90423, 30.2433[sec]\n",
            "2024-08-13 19:30:59,516 - INFO - joeynmt.training - EPOCH 148\n",
            "2024-08-13 19:31:30,497 - INFO - joeynmt.training - Epoch 148, total training loss: 57.83, num. of seqs: 8065, num. of tokens: 90423, 30.9807[sec]\n",
            "2024-08-13 19:31:30,498 - INFO - joeynmt.training - EPOCH 149\n",
            "2024-08-13 19:31:34,051 - INFO - joeynmt.training - Epoch 149, Step:    44000, Batch Loss:     0.193352, Batch Acc: 0.989188, Tokens per Sec:     3229, Lr: 0.000300\n",
            "2024-08-13 19:31:34,052 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=44042\n",
            "2024-08-13 19:31:34,052 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 195.95it/s]\n",
            "2024-08-13 19:31:41,504 - INFO - joeynmt.prediction - Generation took 7.4512[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 32914.49 examples/s]\n",
            "2024-08-13 19:31:41,869 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:31:41,870 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.17, loss:   4.21, ppl:  67.40, acc:   0.32, 0.1873[sec]\n",
            "2024-08-13 19:31:41,871 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:31:41,950 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:31:41,950 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:31:41,951 - INFO - joeynmt.training - \tHypothesis: comment s’appelle votre sœur\n",
            "2024-08-13 19:31:42,105 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:31:42,187 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:31:42,187 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:31:42,187 - INFO - joeynmt.training - \tHypothesis: trois points d’avance\n",
            "2024-08-13 19:31:42,341 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:31:42,399 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:31:42,399 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:31:42,399 - INFO - joeynmt.training - \tHypothesis: lesges n’est pas quint\n",
            "2024-08-13 19:31:42,493 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:31:42,536 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:31:42,536 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:31:42,536 - INFO - joeynmt.training - \tHypothesis: de même une chose\n",
            "2024-08-13 19:32:09,682 - INFO - joeynmt.training - Epoch 149, total training loss: 57.64, num. of seqs: 8065, num. of tokens: 90423, 30.6087[sec]\n",
            "2024-08-13 19:32:09,683 - INFO - joeynmt.training - EPOCH 150\n",
            "2024-08-13 19:32:40,383 - INFO - joeynmt.training - Epoch 150, total training loss: 57.77, num. of seqs: 8065, num. of tokens: 90423, 30.7000[sec]\n",
            "2024-08-13 19:32:40,384 - INFO - joeynmt.training - EPOCH 151\n",
            "2024-08-13 19:33:10,815 - INFO - joeynmt.training - Epoch 151, total training loss: 56.51, num. of seqs: 8065, num. of tokens: 90423, 30.4304[sec]\n",
            "2024-08-13 19:33:10,816 - INFO - joeynmt.training - EPOCH 152\n",
            "2024-08-13 19:33:41,913 - INFO - joeynmt.training - Epoch 152, total training loss: 57.51, num. of seqs: 8065, num. of tokens: 90423, 31.0956[sec]\n",
            "2024-08-13 19:33:41,913 - INFO - joeynmt.training - EPOCH 153\n",
            "2024-08-13 19:34:11,734 - INFO - joeynmt.training - Epoch 153, total training loss: 57.32, num. of seqs: 8065, num. of tokens: 90423, 29.8195[sec]\n",
            "2024-08-13 19:34:11,734 - INFO - joeynmt.training - EPOCH 154\n",
            "2024-08-13 19:34:41,654 - INFO - joeynmt.training - Epoch 154, total training loss: 56.99, num. of seqs: 8065, num. of tokens: 90423, 29.9192[sec]\n",
            "2024-08-13 19:34:41,654 - INFO - joeynmt.training - EPOCH 155\n",
            "2024-08-13 19:35:07,435 - INFO - joeynmt.training - Epoch 155, Step:    46000, Batch Loss:     0.218324, Batch Acc: 0.990045, Tokens per Sec:     3000, Lr: 0.000300\n",
            "2024-08-13 19:35:07,436 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=46042\n",
            "2024-08-13 19:35:07,437 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:08<00:00, 182.22it/s]\n",
            "2024-08-13 19:35:15,450 - INFO - joeynmt.prediction - Generation took 8.0128[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 60582.29 examples/s]\n",
            "2024-08-13 19:35:15,662 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:35:15,662 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.22, loss:   4.21, ppl:  67.16, acc:   0.31, 0.1066[sec]\n",
            "2024-08-13 19:35:15,663 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:35:15,708 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:35:15,708 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:35:15,708 - INFO - joeynmt.training - \tHypothesis: comment s’appelle votre sœur\n",
            "2024-08-13 19:35:15,796 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:35:15,849 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:35:15,849 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:35:15,849 - INFO - joeynmt.training - \tHypothesis: trois points d’avance\n",
            "2024-08-13 19:35:15,937 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:35:15,991 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:35:15,992 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:35:15,992 - INFO - joeynmt.training - \tHypothesis: desges ne va pass pas\n",
            "2024-08-13 19:35:16,080 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:35:16,126 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:35:16,126 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:35:16,126 - INFO - joeynmt.training - \tHypothesis: d'autres animaux\n",
            "2024-08-13 19:35:20,526 - INFO - joeynmt.training - Epoch 155, total training loss: 56.91, num. of seqs: 8065, num. of tokens: 90423, 30.0891[sec]\n",
            "2024-08-13 19:35:20,526 - INFO - joeynmt.training - EPOCH 156\n",
            "2024-08-13 19:35:52,228 - INFO - joeynmt.training - Epoch 156, total training loss: 56.53, num. of seqs: 8065, num. of tokens: 90423, 31.7013[sec]\n",
            "2024-08-13 19:35:52,229 - INFO - joeynmt.training - EPOCH 157\n",
            "2024-08-13 19:36:22,677 - INFO - joeynmt.training - Epoch 157, total training loss: 56.14, num. of seqs: 8065, num. of tokens: 90423, 30.4482[sec]\n",
            "2024-08-13 19:36:22,678 - INFO - joeynmt.training - EPOCH 158\n",
            "2024-08-13 19:36:53,879 - INFO - joeynmt.training - Epoch 158, total training loss: 56.03, num. of seqs: 8065, num. of tokens: 90423, 31.2004[sec]\n",
            "2024-08-13 19:36:53,880 - INFO - joeynmt.training - EPOCH 159\n",
            "2024-08-13 19:37:25,627 - INFO - joeynmt.training - Epoch 159, total training loss: 55.97, num. of seqs: 8065, num. of tokens: 90423, 31.7460[sec]\n",
            "2024-08-13 19:37:25,627 - INFO - joeynmt.training - EPOCH 160\n",
            "2024-08-13 19:37:58,576 - INFO - joeynmt.training - Epoch 160, total training loss: 55.41, num. of seqs: 8065, num. of tokens: 90423, 32.9473[sec]\n",
            "2024-08-13 19:37:58,576 - INFO - joeynmt.training - EPOCH 161\n",
            "2024-08-13 19:38:31,904 - INFO - joeynmt.training - Epoch 161, total training loss: 55.51, num. of seqs: 8065, num. of tokens: 90423, 33.3257[sec]\n",
            "2024-08-13 19:38:31,904 - INFO - joeynmt.training - EPOCH 162\n",
            "2024-08-13 19:38:50,938 - INFO - joeynmt.training - Epoch 162, Step:    48000, Batch Loss:     0.175676, Batch Acc: 0.989653, Tokens per Sec:     2778, Lr: 0.000300\n",
            "2024-08-13 19:38:50,939 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=48042\n",
            "2024-08-13 19:38:50,939 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:08<00:00, 165.20it/s]\n",
            "2024-08-13 19:38:59,777 - INFO - joeynmt.prediction - Generation took 8.8380[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 33095.46 examples/s]\n",
            "2024-08-13 19:39:00,010 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:39:00,010 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.70, loss:   4.19, ppl:  66.04, acc:   0.32, 0.1135[sec]\n",
            "2024-08-13 19:39:00,262 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/48000.ckpt.\n",
            "2024-08-13 19:39:00,263 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/38000.ckpt\n",
            "2024-08-13 19:39:00,296 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:39:00,356 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:39:00,356 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:39:00,356 - INFO - joeynmt.training - \tHypothesis: comment s’appelle votre sœur\n",
            "2024-08-13 19:39:00,460 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:39:00,507 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:39:00,507 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:39:00,507 - INFO - joeynmt.training - \tHypothesis: trois points d’avance\n",
            "2024-08-13 19:39:00,611 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:39:00,663 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:39:00,663 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:39:00,663 - INFO - joeynmt.training - \tHypothesis: je ne va pas très bien\n",
            "2024-08-13 19:39:00,771 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:39:00,822 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:39:00,822 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:39:00,822 - INFO - joeynmt.training - \tHypothesis: l'un et l'autre\n",
            "2024-08-13 19:39:15,116 - INFO - joeynmt.training - Epoch 162, total training loss: 56.10, num. of seqs: 8065, num. of tokens: 90423, 33.2160[sec]\n",
            "2024-08-13 19:39:15,116 - INFO - joeynmt.training - EPOCH 163\n",
            "2024-08-13 19:39:47,576 - INFO - joeynmt.training - Epoch 163, total training loss: 55.39, num. of seqs: 8065, num. of tokens: 90423, 32.4584[sec]\n",
            "2024-08-13 19:39:47,576 - INFO - joeynmt.training - EPOCH 164\n",
            "2024-08-13 19:40:17,964 - INFO - joeynmt.training - Epoch 164, total training loss: 55.15, num. of seqs: 8065, num. of tokens: 90423, 30.3868[sec]\n",
            "2024-08-13 19:40:17,964 - INFO - joeynmt.training - EPOCH 165\n",
            "2024-08-13 19:40:48,146 - INFO - joeynmt.training - Epoch 165, total training loss: 55.04, num. of seqs: 8065, num. of tokens: 90423, 30.1802[sec]\n",
            "2024-08-13 19:40:48,146 - INFO - joeynmt.training - EPOCH 166\n",
            "2024-08-13 19:41:20,144 - INFO - joeynmt.training - Epoch 166, total training loss: 54.22, num. of seqs: 8065, num. of tokens: 90423, 31.9971[sec]\n",
            "2024-08-13 19:41:20,144 - INFO - joeynmt.training - EPOCH 167\n",
            "2024-08-13 19:41:50,184 - INFO - joeynmt.training - Epoch 167, total training loss: 54.17, num. of seqs: 8065, num. of tokens: 90423, 30.0395[sec]\n",
            "2024-08-13 19:41:50,185 - INFO - joeynmt.training - EPOCH 168\n",
            "2024-08-13 19:42:20,385 - INFO - joeynmt.training - Epoch 168, total training loss: 53.92, num. of seqs: 8065, num. of tokens: 90423, 30.1998[sec]\n",
            "2024-08-13 19:42:20,386 - INFO - joeynmt.training - EPOCH 169\n",
            "2024-08-13 19:42:30,399 - INFO - joeynmt.training - Epoch 169, Step:    50000, Batch Loss:     0.174281, Batch Acc: 0.991926, Tokens per Sec:     2944, Lr: 0.000300\n",
            "2024-08-13 19:42:30,400 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=50042\n",
            "2024-08-13 19:42:30,400 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:08<00:00, 181.01it/s]\n",
            "2024-08-13 19:42:38,467 - INFO - joeynmt.prediction - Generation took 8.0661[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 58903.25 examples/s]\n",
            "2024-08-13 19:42:38,685 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:42:38,685 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   5.84, loss:   4.22, ppl:  68.00, acc:   0.31, 0.1135[sec]\n",
            "2024-08-13 19:42:38,686 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:42:38,731 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:42:38,731 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:42:38,731 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 19:42:38,825 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:42:38,872 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:42:38,872 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:42:38,872 - INFO - joeynmt.training - \tHypothesis: trois point d’avance\n",
            "2024-08-13 19:42:38,966 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:42:39,012 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:42:39,012 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:42:39,012 - INFO - joeynmt.training - \tHypothesis: on n’est pas du pain\n",
            "2024-08-13 19:42:39,103 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:42:39,151 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:42:39,151 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:42:39,151 - INFO - joeynmt.training - \tHypothesis: un jour ou l'un\n",
            "2024-08-13 19:42:59,794 - INFO - joeynmt.training - Epoch 169, total training loss: 54.11, num. of seqs: 8065, num. of tokens: 90423, 30.5650[sec]\n",
            "2024-08-13 19:42:59,794 - INFO - joeynmt.training - EPOCH 170\n",
            "2024-08-13 19:43:30,893 - INFO - joeynmt.training - Epoch 170, total training loss: 53.86, num. of seqs: 8065, num. of tokens: 90423, 31.0986[sec]\n",
            "2024-08-13 19:43:30,894 - INFO - joeynmt.training - EPOCH 171\n",
            "2024-08-13 19:44:01,638 - INFO - joeynmt.training - Epoch 171, total training loss: 53.83, num. of seqs: 8065, num. of tokens: 90423, 30.7434[sec]\n",
            "2024-08-13 19:44:01,639 - INFO - joeynmt.training - EPOCH 172\n",
            "2024-08-13 19:44:31,413 - INFO - joeynmt.training - Epoch 172, total training loss: 54.29, num. of seqs: 8065, num. of tokens: 90423, 29.7732[sec]\n",
            "2024-08-13 19:44:31,413 - INFO - joeynmt.training - EPOCH 173\n",
            "2024-08-13 19:45:02,325 - INFO - joeynmt.training - Epoch 173, total training loss: 53.81, num. of seqs: 8065, num. of tokens: 90423, 30.9114[sec]\n",
            "2024-08-13 19:45:02,325 - INFO - joeynmt.training - EPOCH 174\n",
            "2024-08-13 19:45:32,068 - INFO - joeynmt.training - Epoch 174, total training loss: 53.46, num. of seqs: 8065, num. of tokens: 90423, 29.7416[sec]\n",
            "2024-08-13 19:45:32,068 - INFO - joeynmt.training - EPOCH 175\n",
            "2024-08-13 19:46:01,628 - INFO - joeynmt.training - Epoch 175, total training loss: 53.28, num. of seqs: 8065, num. of tokens: 90423, 29.5589[sec]\n",
            "2024-08-13 19:46:01,629 - INFO - joeynmt.training - EPOCH 176\n",
            "2024-08-13 19:46:03,374 - INFO - joeynmt.training - Epoch 176, Step:    52000, Batch Loss:     0.181111, Batch Acc: 0.990983, Tokens per Sec:     2735, Lr: 0.000300\n",
            "2024-08-13 19:46:03,375 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=52042\n",
            "2024-08-13 19:46:03,375 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 190.92it/s]\n",
            "2024-08-13 19:46:11,023 - INFO - joeynmt.prediction - Generation took 7.6477[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 60490.82 examples/s]\n",
            "2024-08-13 19:46:11,230 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:46:11,231 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.47, loss:   4.21, ppl:  67.14, acc:   0.32, 0.1063[sec]\n",
            "2024-08-13 19:46:11,232 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:46:11,278 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:46:11,278 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:46:11,278 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 19:46:11,376 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:46:11,428 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:46:11,428 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:46:11,428 - INFO - joeynmt.training - \tHypothesis: trois points d'avance\n",
            "2024-08-13 19:46:11,520 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:46:11,563 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:46:11,563 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:46:11,563 - INFO - joeynmt.training - \tHypothesis: où est les monsieur le tirer\n",
            "2024-08-13 19:46:11,654 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:46:11,704 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:46:11,705 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:46:11,705 - INFO - joeynmt.training - \tHypothesis: un autres réformations\n",
            "2024-08-13 19:46:41,112 - INFO - joeynmt.training - Epoch 176, total training loss: 53.01, num. of seqs: 8065, num. of tokens: 90423, 31.0543[sec]\n",
            "2024-08-13 19:46:41,113 - INFO - joeynmt.training - EPOCH 177\n",
            "2024-08-13 19:47:13,207 - INFO - joeynmt.training - Epoch 177, total training loss: 53.20, num. of seqs: 8065, num. of tokens: 90423, 32.0927[sec]\n",
            "2024-08-13 19:47:13,207 - INFO - joeynmt.training - EPOCH 178\n",
            "2024-08-13 19:47:42,863 - INFO - joeynmt.training - Epoch 178, total training loss: 52.76, num. of seqs: 8065, num. of tokens: 90423, 29.6555[sec]\n",
            "2024-08-13 19:47:42,864 - INFO - joeynmt.training - EPOCH 179\n",
            "2024-08-13 19:48:12,428 - INFO - joeynmt.training - Epoch 179, total training loss: 52.22, num. of seqs: 8065, num. of tokens: 90423, 29.5634[sec]\n",
            "2024-08-13 19:48:12,428 - INFO - joeynmt.training - EPOCH 180\n",
            "2024-08-13 19:48:42,685 - INFO - joeynmt.training - Epoch 180, total training loss: 52.02, num. of seqs: 8065, num. of tokens: 90423, 30.2560[sec]\n",
            "2024-08-13 19:48:42,686 - INFO - joeynmt.training - EPOCH 181\n",
            "2024-08-13 19:49:12,943 - INFO - joeynmt.training - Epoch 181, total training loss: 52.29, num. of seqs: 8065, num. of tokens: 90423, 30.2555[sec]\n",
            "2024-08-13 19:49:12,943 - INFO - joeynmt.training - EPOCH 182\n",
            "2024-08-13 19:49:37,316 - INFO - joeynmt.training - Epoch 182, Step:    54000, Batch Loss:     0.185086, Batch Acc: 0.991269, Tokens per Sec:     2895, Lr: 0.000300\n",
            "2024-08-13 19:49:37,317 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=54042\n",
            "2024-08-13 19:49:37,318 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 193.45it/s]\n",
            "2024-08-13 19:49:44,866 - INFO - joeynmt.prediction - Generation took 7.5476[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 60842.16 examples/s]\n",
            "2024-08-13 19:49:45,084 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:49:45,084 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.37, loss:   4.20, ppl:  66.85, acc:   0.32, 0.1158[sec]\n",
            "2024-08-13 19:49:45,086 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:49:45,135 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:49:45,135 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:49:45,135 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 19:49:45,234 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:49:45,279 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:49:45,280 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:49:45,280 - INFO - joeynmt.training - \tHypothesis: trois point d’avance\n",
            "2024-08-13 19:49:45,369 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:49:45,413 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:49:45,414 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:49:45,414 - INFO - joeynmt.training - \tHypothesis: des coges duresques\n",
            "2024-08-13 19:49:45,512 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:49:45,556 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:49:45,556 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:49:45,556 - INFO - joeynmt.training - \tHypothesis: l'un et l'autre\n",
            "2024-08-13 19:49:53,248 - INFO - joeynmt.training - Epoch 182, total training loss: 51.15, num. of seqs: 8065, num. of tokens: 90423, 31.9733[sec]\n",
            "2024-08-13 19:49:53,248 - INFO - joeynmt.training - EPOCH 183\n",
            "2024-08-13 19:50:23,675 - INFO - joeynmt.training - Epoch 183, total training loss: 46.70, num. of seqs: 8065, num. of tokens: 90423, 30.4257[sec]\n",
            "2024-08-13 19:50:23,675 - INFO - joeynmt.training - EPOCH 184\n",
            "2024-08-13 19:50:54,316 - INFO - joeynmt.training - Epoch 184, total training loss: 42.93, num. of seqs: 8065, num. of tokens: 90423, 30.6400[sec]\n",
            "2024-08-13 19:50:54,316 - INFO - joeynmt.training - EPOCH 185\n",
            "2024-08-13 19:51:24,216 - INFO - joeynmt.training - Epoch 185, total training loss: 41.71, num. of seqs: 8065, num. of tokens: 90423, 29.8986[sec]\n",
            "2024-08-13 19:51:24,217 - INFO - joeynmt.training - EPOCH 186\n",
            "2024-08-13 19:51:53,992 - INFO - joeynmt.training - Epoch 186, total training loss: 40.75, num. of seqs: 8065, num. of tokens: 90423, 29.7746[sec]\n",
            "2024-08-13 19:51:53,993 - INFO - joeynmt.training - EPOCH 187\n",
            "2024-08-13 19:52:24,047 - INFO - joeynmt.training - Epoch 187, total training loss: 39.80, num. of seqs: 8065, num. of tokens: 90423, 30.0532[sec]\n",
            "2024-08-13 19:52:24,047 - INFO - joeynmt.training - EPOCH 188\n",
            "2024-08-13 19:52:55,311 - INFO - joeynmt.training - Epoch 188, total training loss: 38.92, num. of seqs: 8065, num. of tokens: 90423, 31.2618[sec]\n",
            "2024-08-13 19:52:55,311 - INFO - joeynmt.training - EPOCH 189\n",
            "2024-08-13 19:53:10,657 - INFO - joeynmt.training - Epoch 189, Step:    56000, Batch Loss:     0.126157, Batch Acc: 0.995995, Tokens per Sec:     3092, Lr: 0.000150\n",
            "2024-08-13 19:53:10,658 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=56042\n",
            "2024-08-13 19:53:10,658 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:08<00:00, 180.46it/s]\n",
            "2024-08-13 19:53:18,749 - INFO - joeynmt.prediction - Generation took 8.0907[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 59617.56 examples/s]\n",
            "2024-08-13 19:53:18,949 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:53:18,950 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.64, loss:   4.14, ppl:  62.59, acc:   0.32, 0.1063[sec]\n",
            "2024-08-13 19:53:19,169 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/56000.ckpt.\n",
            "2024-08-13 19:53:19,171 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/30000.ckpt\n",
            "2024-08-13 19:53:19,203 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:53:19,254 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:53:19,254 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:53:19,255 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 19:53:19,343 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:53:19,398 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:53:19,398 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:53:19,398 - INFO - joeynmt.training - \tHypothesis: trois points d’avance\n",
            "2024-08-13 19:53:19,498 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:53:19,542 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:53:19,542 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:53:19,542 - INFO - joeynmt.training - \tHypothesis: des coges sont mûres\n",
            "2024-08-13 19:53:19,634 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:53:19,677 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:53:19,677 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:53:19,677 - INFO - joeynmt.training - \tHypothesis: de même un chapeau\n",
            "2024-08-13 19:53:34,670 - INFO - joeynmt.training - Epoch 189, total training loss: 39.06, num. of seqs: 8065, num. of tokens: 90423, 30.2493[sec]\n",
            "2024-08-13 19:53:34,670 - INFO - joeynmt.training - EPOCH 190\n",
            "2024-08-13 19:54:04,629 - INFO - joeynmt.training - Epoch 190, total training loss: 38.41, num. of seqs: 8065, num. of tokens: 90423, 29.9578[sec]\n",
            "2024-08-13 19:54:04,632 - INFO - joeynmt.training - EPOCH 191\n",
            "2024-08-13 19:54:35,591 - INFO - joeynmt.training - Epoch 191, total training loss: 38.51, num. of seqs: 8065, num. of tokens: 90423, 30.9575[sec]\n",
            "2024-08-13 19:54:35,592 - INFO - joeynmt.training - EPOCH 192\n",
            "2024-08-13 19:55:05,323 - INFO - joeynmt.training - Epoch 192, total training loss: 37.84, num. of seqs: 8065, num. of tokens: 90423, 29.7292[sec]\n",
            "2024-08-13 19:55:05,323 - INFO - joeynmt.training - EPOCH 193\n",
            "2024-08-13 19:55:36,183 - INFO - joeynmt.training - Epoch 193, total training loss: 37.68, num. of seqs: 8065, num. of tokens: 90423, 30.8590[sec]\n",
            "2024-08-13 19:55:36,183 - INFO - joeynmt.training - EPOCH 194\n",
            "2024-08-13 19:56:06,917 - INFO - joeynmt.training - Epoch 194, total training loss: 37.28, num. of seqs: 8065, num. of tokens: 90423, 30.7328[sec]\n",
            "2024-08-13 19:56:06,917 - INFO - joeynmt.training - EPOCH 195\n",
            "2024-08-13 19:56:36,634 - INFO - joeynmt.training - Epoch 195, total training loss: 36.99, num. of seqs: 8065, num. of tokens: 90423, 29.7157[sec]\n",
            "2024-08-13 19:56:36,634 - INFO - joeynmt.training - EPOCH 196\n",
            "2024-08-13 19:56:44,185 - INFO - joeynmt.training - Epoch 196, Step:    58000, Batch Loss:     0.125012, Batch Acc: 0.997030, Tokens per Sec:     3078, Lr: 0.000150\n",
            "2024-08-13 19:56:44,186 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=58042\n",
            "2024-08-13 19:56:44,186 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 188.96it/s]\n",
            "2024-08-13 19:56:51,914 - INFO - joeynmt.prediction - Generation took 7.7269[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 61143.64 examples/s]\n",
            "2024-08-13 19:56:52,115 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 19:56:52,115 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.70, loss:   4.14, ppl:  62.55, acc:   0.32, 0.1051[sec]\n",
            "2024-08-13 19:56:52,336 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/58000.ckpt.\n",
            "2024-08-13 19:56:52,338 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/56000.ckpt\n",
            "2024-08-13 19:56:52,362 - INFO - joeynmt.helpers - delete /saved_model/dyu_fr/56000.ckpt\n",
            "2024-08-13 19:56:52,363 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /saved_model/dyu_fr/56000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/saved_model/dyu_fr/56000.ckpt')\n",
            "2024-08-13 19:56:52,363 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 19:56:52,411 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 19:56:52,411 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 19:56:52,411 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 19:56:52,510 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 19:56:52,553 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 19:56:52,554 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 19:56:52,554 - INFO - joeynmt.training - \tHypothesis: trois points d’avance\n",
            "2024-08-13 19:56:52,646 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 19:56:52,700 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 19:56:52,701 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 19:56:52,701 - INFO - joeynmt.training - \tHypothesis: des jours s’est passé\n",
            "2024-08-13 19:56:52,788 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 19:56:52,831 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 19:56:52,832 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 19:56:52,832 - INFO - joeynmt.training - \tHypothesis: de même un\n",
            "2024-08-13 19:57:16,415 - INFO - joeynmt.training - Epoch 196, total training loss: 37.01, num. of seqs: 8065, num. of tokens: 90423, 31.0418[sec]\n",
            "2024-08-13 19:57:16,416 - INFO - joeynmt.training - EPOCH 197\n",
            "2024-08-13 19:57:46,168 - INFO - joeynmt.training - Epoch 197, total training loss: 36.58, num. of seqs: 8065, num. of tokens: 90423, 29.7509[sec]\n",
            "2024-08-13 19:57:46,169 - INFO - joeynmt.training - EPOCH 198\n",
            "2024-08-13 19:58:16,746 - INFO - joeynmt.training - Epoch 198, total training loss: 36.69, num. of seqs: 8065, num. of tokens: 90423, 30.5765[sec]\n",
            "2024-08-13 19:58:16,747 - INFO - joeynmt.training - EPOCH 199\n",
            "2024-08-13 19:58:47,363 - INFO - joeynmt.training - Epoch 199, total training loss: 36.29, num. of seqs: 8065, num. of tokens: 90423, 30.6146[sec]\n",
            "2024-08-13 19:58:47,363 - INFO - joeynmt.training - EPOCH 200\n",
            "2024-08-13 19:59:17,010 - INFO - joeynmt.training - Epoch 200, total training loss: 36.68, num. of seqs: 8065, num. of tokens: 90423, 29.6465[sec]\n",
            "2024-08-13 19:59:17,010 - INFO - joeynmt.training - EPOCH 201\n",
            "2024-08-13 19:59:47,260 - INFO - joeynmt.training - Epoch 201, total training loss: 36.34, num. of seqs: 8065, num. of tokens: 90423, 30.2482[sec]\n",
            "2024-08-13 19:59:47,260 - INFO - joeynmt.training - EPOCH 202\n",
            "2024-08-13 20:00:17,031 - INFO - joeynmt.training - Epoch 202, total training loss: 35.88, num. of seqs: 8065, num. of tokens: 90423, 29.7696[sec]\n",
            "2024-08-13 20:00:17,031 - INFO - joeynmt.training - EPOCH 203\n",
            "2024-08-13 20:00:17,120 - INFO - joeynmt.training - Epoch 203, Step:    60000, Batch Loss:     0.131616, Batch Acc: 0.989324, Tokens per Sec:     3214, Lr: 0.000150\n",
            "2024-08-13 20:00:17,120 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=60042\n",
            "2024-08-13 20:00:17,120 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 207.16it/s]\n",
            "2024-08-13 20:00:24,169 - INFO - joeynmt.prediction - Generation took 7.0479[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 60652.56 examples/s]\n",
            "2024-08-13 20:00:24,451 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:00:24,451 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.86, loss:   4.14, ppl:  62.53, acc:   0.32, 0.1873[sec]\n",
            "2024-08-13 20:00:24,452 - INFO - joeynmt.training - Hooray! New best validation result [bleu]!\n",
            "2024-08-13 20:00:24,787 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/60000.ckpt.\n",
            "2024-08-13 20:00:24,788 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/48000.ckpt\n",
            "2024-08-13 20:00:24,827 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:00:24,918 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:00:24,918 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:00:24,918 - INFO - joeynmt.training - \tHypothesis: comment s’appelle votre sœur\n",
            "2024-08-13 20:00:25,077 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:00:25,156 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:00:25,156 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:00:25,156 - INFO - joeynmt.training - \tHypothesis: trois point d’avance\n",
            "2024-08-13 20:00:25,689 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:00:25,769 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:00:25,769 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:00:25,769 - INFO - joeynmt.training - \tHypothesis: des jourss qui n'est passer\n",
            "2024-08-13 20:00:25,929 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:00:26,020 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:00:26,020 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:00:26,020 - INFO - joeynmt.training - \tHypothesis: de même\n",
            "2024-08-13 20:00:56,981 - INFO - joeynmt.training - Epoch 203, total training loss: 36.07, num. of seqs: 8065, num. of tokens: 90423, 30.8876[sec]\n",
            "2024-08-13 20:00:56,981 - INFO - joeynmt.training - EPOCH 204\n",
            "2024-08-13 20:01:27,679 - INFO - joeynmt.training - Epoch 204, total training loss: 35.95, num. of seqs: 8065, num. of tokens: 90423, 30.6970[sec]\n",
            "2024-08-13 20:01:27,679 - INFO - joeynmt.training - EPOCH 205\n",
            "2024-08-13 20:01:58,035 - INFO - joeynmt.training - Epoch 205, total training loss: 35.74, num. of seqs: 8065, num. of tokens: 90423, 30.3547[sec]\n",
            "2024-08-13 20:01:58,035 - INFO - joeynmt.training - EPOCH 206\n",
            "2024-08-13 20:02:27,845 - INFO - joeynmt.training - Epoch 206, total training loss: 35.96, num. of seqs: 8065, num. of tokens: 90423, 29.8079[sec]\n",
            "2024-08-13 20:02:27,845 - INFO - joeynmt.training - EPOCH 207\n",
            "2024-08-13 20:02:57,439 - INFO - joeynmt.training - Epoch 207, total training loss: 35.52, num. of seqs: 8065, num. of tokens: 90423, 29.5937[sec]\n",
            "2024-08-13 20:02:57,440 - INFO - joeynmt.training - EPOCH 208\n",
            "2024-08-13 20:03:27,399 - INFO - joeynmt.training - Epoch 208, total training loss: 35.79, num. of seqs: 8065, num. of tokens: 90423, 29.9586[sec]\n",
            "2024-08-13 20:03:27,400 - INFO - joeynmt.training - EPOCH 209\n",
            "2024-08-13 20:03:48,999 - INFO - joeynmt.training - Epoch 209, Step:    62000, Batch Loss:     0.112713, Batch Acc: 0.996950, Tokens per Sec:     3036, Lr: 0.000150\n",
            "2024-08-13 20:03:49,000 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=62042\n",
            "2024-08-13 20:03:49,000 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:08<00:00, 181.01it/s]\n",
            "2024-08-13 20:03:57,067 - INFO - joeynmt.prediction - Generation took 8.0664[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 57748.77 examples/s]\n",
            "2024-08-13 20:03:57,262 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:03:57,263 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.82, loss:   4.12, ppl:  61.50, acc:   0.33, 0.1036[sec]\n",
            "2024-08-13 20:03:57,482 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/62000.ckpt.\n",
            "2024-08-13 20:03:57,483 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/58000.ckpt\n",
            "2024-08-13 20:03:57,513 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:03:57,560 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:03:57,560 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:03:57,560 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 20:03:57,650 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:03:57,694 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:03:57,694 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:03:57,694 - INFO - joeynmt.training - \tHypothesis: trois points d’avance\n",
            "2024-08-13 20:03:57,790 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:03:57,834 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:03:57,834 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:03:57,834 - INFO - joeynmt.training - \tHypothesis: on ne sait pas s’est\n",
            "2024-08-13 20:03:57,922 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:03:57,966 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:03:57,966 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:03:57,966 - INFO - joeynmt.training - \tHypothesis: un autre être\n",
            "2024-08-13 20:04:07,777 - INFO - joeynmt.training - Epoch 209, total training loss: 35.68, num. of seqs: 8065, num. of tokens: 90423, 31.3171[sec]\n",
            "2024-08-13 20:04:07,778 - INFO - joeynmt.training - EPOCH 210\n",
            "2024-08-13 20:04:38,197 - INFO - joeynmt.training - Epoch 210, total training loss: 35.11, num. of seqs: 8065, num. of tokens: 90423, 30.4174[sec]\n",
            "2024-08-13 20:04:38,197 - INFO - joeynmt.training - EPOCH 211\n",
            "2024-08-13 20:05:08,074 - INFO - joeynmt.training - Epoch 211, total training loss: 35.21, num. of seqs: 8065, num. of tokens: 90423, 29.8762[sec]\n",
            "2024-08-13 20:05:08,074 - INFO - joeynmt.training - EPOCH 212\n",
            "2024-08-13 20:05:38,896 - INFO - joeynmt.training - Epoch 212, total training loss: 35.01, num. of seqs: 8065, num. of tokens: 90423, 30.8204[sec]\n",
            "2024-08-13 20:05:38,896 - INFO - joeynmt.training - EPOCH 213\n",
            "2024-08-13 20:06:08,965 - INFO - joeynmt.training - Epoch 213, total training loss: 35.03, num. of seqs: 8065, num. of tokens: 90423, 30.0671[sec]\n",
            "2024-08-13 20:06:08,965 - INFO - joeynmt.training - EPOCH 214\n",
            "2024-08-13 20:06:38,723 - INFO - joeynmt.training - Epoch 214, total training loss: 35.37, num. of seqs: 8065, num. of tokens: 90423, 29.7577[sec]\n",
            "2024-08-13 20:06:38,723 - INFO - joeynmt.training - EPOCH 215\n",
            "2024-08-13 20:07:08,860 - INFO - joeynmt.training - Epoch 215, total training loss: 34.67, num. of seqs: 8065, num. of tokens: 90423, 30.1359[sec]\n",
            "2024-08-13 20:07:08,860 - INFO - joeynmt.training - EPOCH 216\n",
            "2024-08-13 20:07:22,867 - INFO - joeynmt.training - Epoch 216, Step:    64000, Batch Loss:     0.105212, Batch Acc: 0.997044, Tokens per Sec:     2923, Lr: 0.000150\n",
            "2024-08-13 20:07:22,868 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=64042\n",
            "2024-08-13 20:07:22,868 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:06<00:00, 213.00it/s]\n",
            "2024-08-13 20:07:29,724 - INFO - joeynmt.prediction - Generation took 6.8547[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 59554.26 examples/s]\n",
            "2024-08-13 20:07:29,932 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:07:29,932 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.85, loss:   4.14, ppl:  62.77, acc:   0.32, 0.1163[sec]\n",
            "2024-08-13 20:07:30,155 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/64000.ckpt.\n",
            "2024-08-13 20:07:30,156 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/42000.ckpt\n",
            "2024-08-13 20:07:30,189 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:07:30,251 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:07:30,252 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:07:30,252 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 20:07:30,341 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:07:30,384 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:07:30,384 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:07:30,384 - INFO - joeynmt.training - \tHypothesis: trois points d’avance\n",
            "2024-08-13 20:07:30,477 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:07:30,521 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:07:30,521 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:07:30,521 - INFO - joeynmt.training - \tHypothesis: on ne sait pas quand la route\n",
            "2024-08-13 20:07:30,616 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:07:30,662 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:07:30,662 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:07:30,662 - INFO - joeynmt.training - \tHypothesis: un autre être\n",
            "2024-08-13 20:07:47,958 - INFO - joeynmt.training - Epoch 216, total training loss: 34.63, num. of seqs: 8065, num. of tokens: 90423, 31.1981[sec]\n",
            "2024-08-13 20:07:47,959 - INFO - joeynmt.training - EPOCH 217\n",
            "2024-08-13 20:08:18,344 - INFO - joeynmt.training - Epoch 217, total training loss: 34.79, num. of seqs: 8065, num. of tokens: 90423, 30.3842[sec]\n",
            "2024-08-13 20:08:18,345 - INFO - joeynmt.training - EPOCH 218\n",
            "2024-08-13 20:08:47,804 - INFO - joeynmt.training - Epoch 218, total training loss: 34.57, num. of seqs: 8065, num. of tokens: 90423, 29.4580[sec]\n",
            "2024-08-13 20:08:47,804 - INFO - joeynmt.training - EPOCH 219\n",
            "2024-08-13 20:09:17,255 - INFO - joeynmt.training - Epoch 219, total training loss: 34.05, num. of seqs: 8065, num. of tokens: 90423, 29.4500[sec]\n",
            "2024-08-13 20:09:17,256 - INFO - joeynmt.training - EPOCH 220\n",
            "2024-08-13 20:09:47,849 - INFO - joeynmt.training - Epoch 220, total training loss: 34.30, num. of seqs: 8065, num. of tokens: 90423, 30.5916[sec]\n",
            "2024-08-13 20:09:47,849 - INFO - joeynmt.training - EPOCH 221\n",
            "2024-08-13 20:10:17,744 - INFO - joeynmt.training - Epoch 221, total training loss: 34.74, num. of seqs: 8065, num. of tokens: 90423, 29.8941[sec]\n",
            "2024-08-13 20:10:17,745 - INFO - joeynmt.training - EPOCH 222\n",
            "2024-08-13 20:10:47,357 - INFO - joeynmt.training - Epoch 222, total training loss: 34.21, num. of seqs: 8065, num. of tokens: 90423, 29.6117[sec]\n",
            "2024-08-13 20:10:47,357 - INFO - joeynmt.training - EPOCH 223\n",
            "2024-08-13 20:10:54,050 - INFO - joeynmt.training - Epoch 223, Step:    66000, Batch Loss:     0.107297, Batch Acc: 0.997877, Tokens per Sec:     2816, Lr: 0.000150\n",
            "2024-08-13 20:10:54,051 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=66042\n",
            "2024-08-13 20:10:54,051 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 201.31it/s]\n",
            "2024-08-13 20:11:01,304 - INFO - joeynmt.prediction - Generation took 7.2527[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 31771.10 examples/s]\n",
            "2024-08-13 20:11:01,669 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:11:01,669 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.60, loss:   4.14, ppl:  62.52, acc:   0.32, 0.2009[sec]\n",
            "2024-08-13 20:11:01,671 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:11:01,752 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:11:01,752 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:11:01,752 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 20:11:01,910 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:11:01,988 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:11:01,988 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:11:01,988 - INFO - joeynmt.training - \tHypothesis: trois point d’avance\n",
            "2024-08-13 20:11:02,137 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:11:02,216 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:11:02,216 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:11:02,216 - INFO - joeynmt.training - \tHypothesis: il ne va pas quiait pas\n",
            "2024-08-13 20:11:02,374 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:11:02,455 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:11:02,456 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:11:02,456 - INFO - joeynmt.training - \tHypothesis: un autre être favorable\n",
            "2024-08-13 20:11:26,822 - INFO - joeynmt.training - Epoch 223, total training loss: 34.14, num. of seqs: 8065, num. of tokens: 90423, 30.9028[sec]\n",
            "2024-08-13 20:11:26,823 - INFO - joeynmt.training - EPOCH 224\n",
            "2024-08-13 20:11:57,258 - INFO - joeynmt.training - Epoch 224, total training loss: 34.10, num. of seqs: 8065, num. of tokens: 90423, 30.4338[sec]\n",
            "2024-08-13 20:11:57,258 - INFO - joeynmt.training - EPOCH 225\n",
            "2024-08-13 20:12:26,759 - INFO - joeynmt.training - Epoch 225, total training loss: 34.02, num. of seqs: 8065, num. of tokens: 90423, 29.5002[sec]\n",
            "2024-08-13 20:12:26,759 - INFO - joeynmt.training - EPOCH 226\n",
            "2024-08-13 20:12:56,285 - INFO - joeynmt.training - Epoch 226, total training loss: 33.79, num. of seqs: 8065, num. of tokens: 90423, 29.5246[sec]\n",
            "2024-08-13 20:12:56,285 - INFO - joeynmt.training - EPOCH 227\n",
            "2024-08-13 20:13:26,613 - INFO - joeynmt.training - Epoch 227, total training loss: 33.86, num. of seqs: 8065, num. of tokens: 90423, 30.3276[sec]\n",
            "2024-08-13 20:13:26,614 - INFO - joeynmt.training - EPOCH 228\n",
            "2024-08-13 20:13:56,361 - INFO - joeynmt.training - Epoch 228, total training loss: 33.98, num. of seqs: 8065, num. of tokens: 90423, 29.7460[sec]\n",
            "2024-08-13 20:13:56,362 - INFO - joeynmt.training - EPOCH 229\n",
            "2024-08-13 20:14:24,298 - INFO - joeynmt.training - Epoch 229, Step:    68000, Batch Loss:     0.109875, Batch Acc: 0.997243, Tokens per Sec:     3077, Lr: 0.000150\n",
            "2024-08-13 20:14:24,299 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=68042\n",
            "2024-08-13 20:14:24,299 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:08<00:00, 181.28it/s]\n",
            "2024-08-13 20:14:32,354 - INFO - joeynmt.prediction - Generation took 8.0544[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 58768.04 examples/s]\n",
            "2024-08-13 20:14:32,558 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:14:32,558 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.54, loss:   4.12, ppl:  61.84, acc:   0.32, 0.1071[sec]\n",
            "2024-08-13 20:14:32,559 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:14:32,605 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:14:32,605 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:14:32,606 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 20:14:32,707 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:14:32,753 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:14:32,753 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:14:32,753 - INFO - joeynmt.training - \tHypothesis: trois points d’avance\n",
            "2024-08-13 20:14:32,840 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:14:32,883 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:14:32,883 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:14:32,883 - INFO - joeynmt.training - \tHypothesis: des jours s'est passé\n",
            "2024-08-13 20:14:32,974 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:14:33,020 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:14:33,020 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:14:33,020 - INFO - joeynmt.training - \tHypothesis: de même un\n",
            "2024-08-13 20:14:34,588 - INFO - joeynmt.training - Epoch 229, total training loss: 33.84, num. of seqs: 8065, num. of tokens: 90423, 29.4053[sec]\n",
            "2024-08-13 20:14:34,588 - INFO - joeynmt.training - EPOCH 230\n",
            "2024-08-13 20:15:04,906 - INFO - joeynmt.training - Epoch 230, total training loss: 33.76, num. of seqs: 8065, num. of tokens: 90423, 30.3166[sec]\n",
            "2024-08-13 20:15:04,906 - INFO - joeynmt.training - EPOCH 231\n",
            "2024-08-13 20:15:34,948 - INFO - joeynmt.training - Epoch 231, total training loss: 33.85, num. of seqs: 8065, num. of tokens: 90423, 30.0417[sec]\n",
            "2024-08-13 20:15:34,949 - INFO - joeynmt.training - EPOCH 232\n",
            "2024-08-13 20:16:04,956 - INFO - joeynmt.training - Epoch 232, total training loss: 33.69, num. of seqs: 8065, num. of tokens: 90423, 30.0060[sec]\n",
            "2024-08-13 20:16:04,956 - INFO - joeynmt.training - EPOCH 233\n",
            "2024-08-13 20:16:34,464 - INFO - joeynmt.training - Epoch 233, total training loss: 33.68, num. of seqs: 8065, num. of tokens: 90423, 29.5075[sec]\n",
            "2024-08-13 20:16:34,465 - INFO - joeynmt.training - EPOCH 234\n",
            "2024-08-13 20:17:04,012 - INFO - joeynmt.training - Epoch 234, total training loss: 33.81, num. of seqs: 8065, num. of tokens: 90423, 29.5460[sec]\n",
            "2024-08-13 20:17:04,012 - INFO - joeynmt.training - EPOCH 235\n",
            "2024-08-13 20:17:34,621 - INFO - joeynmt.training - Epoch 235, total training loss: 33.62, num. of seqs: 8065, num. of tokens: 90423, 30.6079[sec]\n",
            "2024-08-13 20:17:34,621 - INFO - joeynmt.training - EPOCH 236\n",
            "2024-08-13 20:17:54,156 - INFO - joeynmt.training - Epoch 236, Step:    70000, Batch Loss:     0.099482, Batch Acc: 0.997506, Tokens per Sec:     3120, Lr: 0.000150\n",
            "2024-08-13 20:17:54,157 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=70042\n",
            "2024-08-13 20:17:54,157 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 184.43it/s]\n",
            "2024-08-13 20:18:02,074 - INFO - joeynmt.prediction - Generation took 7.9164[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 61067.39 examples/s]\n",
            "2024-08-13 20:18:02,291 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:18:02,291 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.35, loss:   4.15, ppl:  63.18, acc:   0.32, 0.1242[sec]\n",
            "2024-08-13 20:18:02,292 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:18:02,340 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:18:02,341 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:18:02,341 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 20:18:02,432 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:18:02,477 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:18:02,477 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:18:02,477 - INFO - joeynmt.training - \tHypothesis: trois point de l’avance\n",
            "2024-08-13 20:18:02,564 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:18:02,611 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:18:02,611 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:18:02,611 - INFO - joeynmt.training - \tHypothesis: des journées quint passent\n",
            "2024-08-13 20:18:02,700 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:18:02,743 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:18:02,743 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:18:02,743 - INFO - joeynmt.training - \tHypothesis: de même une chose\n",
            "2024-08-13 20:18:13,189 - INFO - joeynmt.training - Epoch 236, total training loss: 33.30, num. of seqs: 8065, num. of tokens: 90423, 29.8899[sec]\n",
            "2024-08-13 20:18:13,189 - INFO - joeynmt.training - EPOCH 237\n",
            "2024-08-13 20:18:43,247 - INFO - joeynmt.training - Epoch 237, total training loss: 33.65, num. of seqs: 8065, num. of tokens: 90423, 30.0565[sec]\n",
            "2024-08-13 20:18:43,247 - INFO - joeynmt.training - EPOCH 238\n",
            "2024-08-13 20:19:12,864 - INFO - joeynmt.training - Epoch 238, total training loss: 33.70, num. of seqs: 8065, num. of tokens: 90423, 29.6167[sec]\n",
            "2024-08-13 20:19:12,865 - INFO - joeynmt.training - EPOCH 239\n",
            "2024-08-13 20:19:43,130 - INFO - joeynmt.training - Epoch 239, total training loss: 33.35, num. of seqs: 8065, num. of tokens: 90423, 30.2642[sec]\n",
            "2024-08-13 20:19:43,130 - INFO - joeynmt.training - EPOCH 240\n",
            "2024-08-13 20:20:12,768 - INFO - joeynmt.training - Epoch 240, total training loss: 33.10, num. of seqs: 8065, num. of tokens: 90423, 29.6366[sec]\n",
            "2024-08-13 20:20:12,769 - INFO - joeynmt.training - EPOCH 241\n",
            "2024-08-13 20:20:42,213 - INFO - joeynmt.training - Epoch 241, total training loss: 33.32, num. of seqs: 8065, num. of tokens: 90423, 29.4439[sec]\n",
            "2024-08-13 20:20:42,214 - INFO - joeynmt.training - EPOCH 242\n",
            "2024-08-13 20:21:11,880 - INFO - joeynmt.training - Epoch 242, total training loss: 32.92, num. of seqs: 8065, num. of tokens: 90423, 29.6661[sec]\n",
            "2024-08-13 20:21:11,881 - INFO - joeynmt.training - EPOCH 243\n",
            "2024-08-13 20:21:23,926 - INFO - joeynmt.training - Epoch 243, Step:    72000, Batch Loss:     0.114390, Batch Acc: 0.996665, Tokens per Sec:     3112, Lr: 0.000150\n",
            "2024-08-13 20:21:23,928 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=72042\n",
            "2024-08-13 20:21:23,928 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 184.43it/s]\n",
            "2024-08-13 20:21:31,845 - INFO - joeynmt.prediction - Generation took 7.9169[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 58751.81 examples/s]\n",
            "2024-08-13 20:21:32,043 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:21:32,044 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.91, loss:   4.15, ppl:  63.24, acc:   0.32, 0.1042[sec]\n",
            "2024-08-13 20:21:32,044 - INFO - joeynmt.training - Hooray! New best validation result [bleu]!\n",
            "2024-08-13 20:21:32,284 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/72000.ckpt.\n",
            "2024-08-13 20:21:32,285 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/62000.ckpt\n",
            "2024-08-13 20:21:32,312 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:21:32,360 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:21:32,360 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:21:32,361 - INFO - joeynmt.training - \tHypothesis: comment s’appelle votre sœur\n",
            "2024-08-13 20:21:32,452 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:21:32,496 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:21:32,496 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:21:32,497 - INFO - joeynmt.training - \tHypothesis: trois points d'avance\n",
            "2024-08-13 20:21:32,594 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:21:32,639 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:21:32,639 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:21:32,639 - INFO - joeynmt.training - \tHypothesis: des jourss qui n'est passer\n",
            "2024-08-13 20:21:32,727 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:21:32,771 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:21:32,772 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:21:32,772 - INFO - joeynmt.training - \tHypothesis: l'un et l'autre\n",
            "2024-08-13 20:21:51,082 - INFO - joeynmt.training - Epoch 243, total training loss: 33.19, num. of seqs: 8065, num. of tokens: 90423, 30.2606[sec]\n",
            "2024-08-13 20:21:51,082 - INFO - joeynmt.training - EPOCH 244\n",
            "2024-08-13 20:22:21,572 - INFO - joeynmt.training - Epoch 244, total training loss: 32.91, num. of seqs: 8065, num. of tokens: 90423, 30.4883[sec]\n",
            "2024-08-13 20:22:21,572 - INFO - joeynmt.training - EPOCH 245\n",
            "2024-08-13 20:22:51,024 - INFO - joeynmt.training - Epoch 245, total training loss: 32.91, num. of seqs: 8065, num. of tokens: 90423, 29.4499[sec]\n",
            "2024-08-13 20:22:51,024 - INFO - joeynmt.training - EPOCH 246\n",
            "2024-08-13 20:23:20,639 - INFO - joeynmt.training - Epoch 246, total training loss: 32.55, num. of seqs: 8065, num. of tokens: 90423, 29.6145[sec]\n",
            "2024-08-13 20:23:20,640 - INFO - joeynmt.training - EPOCH 247\n",
            "2024-08-13 20:23:51,369 - INFO - joeynmt.training - Epoch 247, total training loss: 32.82, num. of seqs: 8065, num. of tokens: 90423, 30.7281[sec]\n",
            "2024-08-13 20:23:51,369 - INFO - joeynmt.training - EPOCH 248\n",
            "2024-08-13 20:24:21,131 - INFO - joeynmt.training - Epoch 248, total training loss: 33.05, num. of seqs: 8065, num. of tokens: 90423, 29.7610[sec]\n",
            "2024-08-13 20:24:21,132 - INFO - joeynmt.training - EPOCH 249\n",
            "2024-08-13 20:24:50,868 - INFO - joeynmt.training - Epoch 249, total training loss: 32.84, num. of seqs: 8065, num. of tokens: 90423, 29.7356[sec]\n",
            "2024-08-13 20:24:50,869 - INFO - joeynmt.training - EPOCH 250\n",
            "2024-08-13 20:24:56,652 - INFO - joeynmt.training - Epoch 250, Step:    74000, Batch Loss:     0.100776, Batch Acc: 0.997830, Tokens per Sec:     2630, Lr: 0.000150\n",
            "2024-08-13 20:24:56,653 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=74042\n",
            "2024-08-13 20:24:56,654 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 203.50it/s]\n",
            "2024-08-13 20:25:03,829 - INFO - joeynmt.prediction - Generation took 7.1749[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 59792.04 examples/s]\n",
            "2024-08-13 20:25:04,041 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:25:04,042 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.81, loss:   4.13, ppl:  62.32, acc:   0.32, 0.1190[sec]\n",
            "2024-08-13 20:25:04,043 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:25:04,093 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:25:04,093 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:25:04,093 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 20:25:04,185 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:25:04,229 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:25:04,230 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:25:04,230 - INFO - joeynmt.training - \tHypothesis: trois points d’avance\n",
            "2024-08-13 20:25:04,324 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:25:04,381 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:25:04,381 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:25:04,381 - INFO - joeynmt.training - \tHypothesis: il ne s’est pas d’un jeu\n",
            "2024-08-13 20:25:04,477 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:25:04,521 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:25:04,521 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:25:04,522 - INFO - joeynmt.training - \tHypothesis: l'un et l'autre\n",
            "2024-08-13 20:25:30,556 - INFO - joeynmt.training - Epoch 250, total training loss: 32.45, num. of seqs: 8065, num. of tokens: 90423, 31.7213[sec]\n",
            "2024-08-13 20:25:30,557 - INFO - joeynmt.training - EPOCH 251\n",
            "2024-08-13 20:26:01,435 - INFO - joeynmt.training - Epoch 251, total training loss: 32.76, num. of seqs: 8065, num. of tokens: 90423, 30.8770[sec]\n",
            "2024-08-13 20:26:01,435 - INFO - joeynmt.training - EPOCH 252\n",
            "2024-08-13 20:26:31,054 - INFO - joeynmt.training - Epoch 252, total training loss: 32.94, num. of seqs: 8065, num. of tokens: 90423, 29.6181[sec]\n",
            "2024-08-13 20:26:31,055 - INFO - joeynmt.training - EPOCH 253\n",
            "2024-08-13 20:27:00,364 - INFO - joeynmt.training - Epoch 253, total training loss: 32.46, num. of seqs: 8065, num. of tokens: 90423, 29.3087[sec]\n",
            "2024-08-13 20:27:00,365 - INFO - joeynmt.training - EPOCH 254\n",
            "2024-08-13 20:27:30,704 - INFO - joeynmt.training - Epoch 254, total training loss: 32.98, num. of seqs: 8065, num. of tokens: 90423, 30.3386[sec]\n",
            "2024-08-13 20:27:30,704 - INFO - joeynmt.training - EPOCH 255\n",
            "2024-08-13 20:28:00,120 - INFO - joeynmt.training - Epoch 255, total training loss: 32.54, num. of seqs: 8065, num. of tokens: 90423, 29.4145[sec]\n",
            "2024-08-13 20:28:00,120 - INFO - joeynmt.training - EPOCH 256\n",
            "2024-08-13 20:28:27,060 - INFO - joeynmt.training - Epoch 256, Step:    76000, Batch Loss:     0.111226, Batch Acc: 0.997054, Tokens per Sec:     3062, Lr: 0.000150\n",
            "2024-08-13 20:28:27,061 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=76042\n",
            "2024-08-13 20:28:27,061 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 185.63it/s]\n",
            "2024-08-13 20:28:34,927 - INFO - joeynmt.prediction - Generation took 7.8653[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 59685.04 examples/s]\n",
            "2024-08-13 20:28:35,163 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:28:35,163 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.90, loss:   4.13, ppl:  61.95, acc:   0.32, 0.1085[sec]\n",
            "2024-08-13 20:28:35,387 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/76000.ckpt.\n",
            "2024-08-13 20:28:35,388 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/64000.ckpt\n",
            "2024-08-13 20:28:35,419 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:28:35,479 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:28:35,480 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:28:35,480 - INFO - joeynmt.training - \tHypothesis: comment s’appelle votre sœur\n",
            "2024-08-13 20:28:35,567 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:28:35,610 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:28:35,610 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:28:35,610 - INFO - joeynmt.training - \tHypothesis: trois point d’avance\n",
            "2024-08-13 20:28:35,706 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:28:35,751 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:28:35,751 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:28:35,751 - INFO - joeynmt.training - \tHypothesis: des jours s'est passé\n",
            "2024-08-13 20:28:35,838 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:28:35,885 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:28:35,885 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:28:35,885 - INFO - joeynmt.training - \tHypothesis: l'un et l'autre\n",
            "2024-08-13 20:28:38,661 - INFO - joeynmt.training - Epoch 256, total training loss: 32.51, num. of seqs: 8065, num. of tokens: 90423, 29.6185[sec]\n",
            "2024-08-13 20:28:38,661 - INFO - joeynmt.training - EPOCH 257\n",
            "2024-08-13 20:29:08,846 - INFO - joeynmt.training - Epoch 257, total training loss: 32.08, num. of seqs: 8065, num. of tokens: 90423, 30.1835[sec]\n",
            "2024-08-13 20:29:08,846 - INFO - joeynmt.training - EPOCH 258\n",
            "2024-08-13 20:29:39,003 - INFO - joeynmt.training - Epoch 258, total training loss: 32.51, num. of seqs: 8065, num. of tokens: 90423, 30.1556[sec]\n",
            "2024-08-13 20:29:39,003 - INFO - joeynmt.training - EPOCH 259\n",
            "2024-08-13 20:30:08,742 - INFO - joeynmt.training - Epoch 259, total training loss: 32.60, num. of seqs: 8065, num. of tokens: 90423, 29.7378[sec]\n",
            "2024-08-13 20:30:08,743 - INFO - joeynmt.training - EPOCH 260\n",
            "2024-08-13 20:30:38,356 - INFO - joeynmt.training - Epoch 260, total training loss: 32.50, num. of seqs: 8065, num. of tokens: 90423, 29.6120[sec]\n",
            "2024-08-13 20:30:38,356 - INFO - joeynmt.training - EPOCH 261\n",
            "2024-08-13 20:31:07,721 - INFO - joeynmt.training - Epoch 261, total training loss: 32.14, num. of seqs: 8065, num. of tokens: 90423, 29.3639[sec]\n",
            "2024-08-13 20:31:07,722 - INFO - joeynmt.training - EPOCH 262\n",
            "2024-08-13 20:31:38,014 - INFO - joeynmt.training - Epoch 262, total training loss: 32.11, num. of seqs: 8065, num. of tokens: 90423, 30.2920[sec]\n",
            "2024-08-13 20:31:38,015 - INFO - joeynmt.training - EPOCH 263\n",
            "2024-08-13 20:31:57,549 - INFO - joeynmt.training - Epoch 263, Step:    78000, Batch Loss:     0.104589, Batch Acc: 0.997061, Tokens per Sec:     3136, Lr: 0.000150\n",
            "2024-08-13 20:31:57,550 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=78042\n",
            "2024-08-13 20:31:57,551 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:08<00:00, 181.63it/s]\n",
            "2024-08-13 20:32:05,590 - INFO - joeynmt.prediction - Generation took 8.0388[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 40218.64 examples/s]\n",
            "2024-08-13 20:32:05,798 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:32:05,798 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.94, loss:   4.13, ppl:  62.34, acc:   0.32, 0.1031[sec]\n",
            "2024-08-13 20:32:05,799 - INFO - joeynmt.training - Hooray! New best validation result [bleu]!\n",
            "2024-08-13 20:32:06,024 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/78000.ckpt.\n",
            "2024-08-13 20:32:06,025 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/60000.ckpt\n",
            "2024-08-13 20:32:06,056 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:32:06,104 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:32:06,105 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:32:06,105 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 20:32:06,193 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:32:06,237 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:32:06,237 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:32:06,237 - INFO - joeynmt.training - \tHypothesis: trois point d’avance\n",
            "2024-08-13 20:32:06,330 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:32:06,375 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:32:06,375 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:32:06,375 - INFO - joeynmt.training - \tHypothesis: des jours s’est passent\n",
            "2024-08-13 20:32:06,471 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:32:06,515 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:32:06,515 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:32:06,515 - INFO - joeynmt.training - \tHypothesis: un kilomètre de route\n",
            "2024-08-13 20:32:16,978 - INFO - joeynmt.training - Epoch 263, total training loss: 32.09, num. of seqs: 8065, num. of tokens: 90423, 29.9031[sec]\n",
            "2024-08-13 20:32:16,978 - INFO - joeynmt.training - EPOCH 264\n",
            "2024-08-13 20:32:47,111 - INFO - joeynmt.training - Epoch 264, total training loss: 32.71, num. of seqs: 8065, num. of tokens: 90423, 30.1310[sec]\n",
            "2024-08-13 20:32:47,111 - INFO - joeynmt.training - EPOCH 265\n",
            "2024-08-13 20:33:16,747 - INFO - joeynmt.training - Epoch 265, total training loss: 32.39, num. of seqs: 8065, num. of tokens: 90423, 29.6357[sec]\n",
            "2024-08-13 20:33:16,748 - INFO - joeynmt.training - EPOCH 266\n",
            "2024-08-13 20:33:47,448 - INFO - joeynmt.training - Epoch 266, total training loss: 32.17, num. of seqs: 8065, num. of tokens: 90423, 30.6997[sec]\n",
            "2024-08-13 20:33:47,449 - INFO - joeynmt.training - EPOCH 267\n",
            "2024-08-13 20:34:17,027 - INFO - joeynmt.training - Epoch 267, total training loss: 32.30, num. of seqs: 8065, num. of tokens: 90423, 29.5778[sec]\n",
            "2024-08-13 20:34:17,028 - INFO - joeynmt.training - EPOCH 268\n",
            "2024-08-13 20:34:47,049 - INFO - joeynmt.training - Epoch 268, total training loss: 32.30, num. of seqs: 8065, num. of tokens: 90423, 30.0200[sec]\n",
            "2024-08-13 20:34:47,049 - INFO - joeynmt.training - EPOCH 269\n",
            "2024-08-13 20:35:17,894 - INFO - joeynmt.training - Epoch 269, total training loss: 32.40, num. of seqs: 8065, num. of tokens: 90423, 30.8437[sec]\n",
            "2024-08-13 20:35:17,894 - INFO - joeynmt.training - EPOCH 270\n",
            "2024-08-13 20:35:29,310 - INFO - joeynmt.training - Epoch 270, Step:    80000, Batch Loss:     0.098173, Batch Acc: 0.997294, Tokens per Sec:     3044, Lr: 0.000150\n",
            "2024-08-13 20:35:29,311 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=80042\n",
            "2024-08-13 20:35:29,311 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 188.90it/s]\n",
            "2024-08-13 20:35:37,041 - INFO - joeynmt.prediction - Generation took 7.7292[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 54548.05 examples/s]\n",
            "2024-08-13 20:35:37,245 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:35:37,245 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   7.05, loss:   4.14, ppl:  63.02, acc:   0.32, 0.1067[sec]\n",
            "2024-08-13 20:35:37,246 - INFO - joeynmt.training - Hooray! New best validation result [bleu]!\n",
            "2024-08-13 20:35:37,483 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/80000.ckpt.\n",
            "2024-08-13 20:35:37,484 - INFO - joeynmt.helpers - delete /content/../saved_model/dyu_fr/76000.ckpt\n",
            "2024-08-13 20:35:37,515 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:35:37,561 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:35:37,562 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:35:37,562 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 20:35:37,654 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:35:37,699 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:35:37,699 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:35:37,700 - INFO - joeynmt.training - \tHypothesis: trois points d’avance\n",
            "2024-08-13 20:35:37,795 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:35:37,841 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:35:37,841 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:35:37,841 - INFO - joeynmt.training - \tHypothesis: les délers sont passé dans le monde\n",
            "2024-08-13 20:35:37,943 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:35:38,004 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:35:38,005 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:35:38,005 - INFO - joeynmt.training - \tHypothesis: un kilomètre de route\n",
            "2024-08-13 20:35:58,283 - INFO - joeynmt.training - Epoch 270, total training loss: 32.29, num. of seqs: 8065, num. of tokens: 90423, 31.5890[sec]\n",
            "2024-08-13 20:35:58,284 - INFO - joeynmt.training - EPOCH 271\n",
            "2024-08-13 20:36:28,567 - INFO - joeynmt.training - Epoch 271, total training loss: 32.02, num. of seqs: 8065, num. of tokens: 90423, 30.2827[sec]\n",
            "2024-08-13 20:36:28,568 - INFO - joeynmt.training - EPOCH 272\n",
            "2024-08-13 20:36:58,181 - INFO - joeynmt.training - Epoch 272, total training loss: 31.88, num. of seqs: 8065, num. of tokens: 90423, 29.6119[sec]\n",
            "2024-08-13 20:36:58,181 - INFO - joeynmt.training - EPOCH 273\n",
            "2024-08-13 20:37:28,777 - INFO - joeynmt.training - Epoch 273, total training loss: 32.16, num. of seqs: 8065, num. of tokens: 90423, 30.5955[sec]\n",
            "2024-08-13 20:37:28,778 - INFO - joeynmt.training - EPOCH 274\n",
            "2024-08-13 20:37:58,238 - INFO - joeynmt.training - Epoch 274, total training loss: 32.18, num. of seqs: 8065, num. of tokens: 90423, 29.4594[sec]\n",
            "2024-08-13 20:37:58,238 - INFO - joeynmt.training - EPOCH 275\n",
            "2024-08-13 20:38:27,829 - INFO - joeynmt.training - Epoch 275, total training loss: 31.97, num. of seqs: 8065, num. of tokens: 90423, 29.5904[sec]\n",
            "2024-08-13 20:38:27,830 - INFO - joeynmt.training - EPOCH 276\n",
            "2024-08-13 20:38:57,886 - INFO - joeynmt.training - Epoch 276, total training loss: 31.62, num. of seqs: 8065, num. of tokens: 90423, 30.0558[sec]\n",
            "2024-08-13 20:38:57,887 - INFO - joeynmt.training - EPOCH 277\n",
            "2024-08-13 20:39:01,477 - INFO - joeynmt.training - Epoch 277, Step:    82000, Batch Loss:     0.113917, Batch Acc: 0.997110, Tokens per Sec:     2989, Lr: 0.000150\n",
            "2024-08-13 20:39:01,478 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=82042\n",
            "2024-08-13 20:39:01,478 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 203.65it/s]\n",
            "2024-08-13 20:39:08,648 - INFO - joeynmt.prediction - Generation took 7.1696[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 33657.85 examples/s]\n",
            "2024-08-13 20:39:08,999 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:39:09,001 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.67, loss:   4.16, ppl:  64.33, acc:   0.32, 0.1950[sec]\n",
            "2024-08-13 20:39:09,003 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:39:09,079 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:39:09,079 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:39:09,079 - INFO - joeynmt.training - \tHypothesis: trois points d'avance\n",
            "2024-08-13 20:39:09,240 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:39:09,323 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:39:09,323 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:39:09,323 - INFO - joeynmt.training - \tHypothesis: des joueurs de soleil\n",
            "2024-08-13 20:39:09,498 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:39:09,579 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:39:09,580 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:39:09,580 - INFO - joeynmt.training - \tHypothesis: un autre animal\n",
            "2024-08-13 20:39:09,738 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:39:09,814 - INFO - joeynmt.training - \tSource:     n ma daraka dun ban\n",
            "2024-08-13 20:39:09,815 - INFO - joeynmt.training - \tReference:  je n’ai pas encore déjeuné\n",
            "2024-08-13 20:39:09,815 - INFO - joeynmt.training - \tHypothesis: je n’ai pas fini de manger\n",
            "2024-08-13 20:39:38,108 - INFO - joeynmt.training - Epoch 277, total training loss: 32.21, num. of seqs: 8065, num. of tokens: 90423, 31.7229[sec]\n",
            "2024-08-13 20:39:38,108 - INFO - joeynmt.training - EPOCH 278\n",
            "2024-08-13 20:40:07,867 - INFO - joeynmt.training - Epoch 278, total training loss: 31.89, num. of seqs: 8065, num. of tokens: 90423, 29.7573[sec]\n",
            "2024-08-13 20:40:07,867 - INFO - joeynmt.training - EPOCH 279\n",
            "2024-08-13 20:40:37,504 - INFO - joeynmt.training - Epoch 279, total training loss: 32.11, num. of seqs: 8065, num. of tokens: 90423, 29.6367[sec]\n",
            "2024-08-13 20:40:37,505 - INFO - joeynmt.training - EPOCH 280\n",
            "2024-08-13 20:41:07,694 - INFO - joeynmt.training - Epoch 280, total training loss: 31.81, num. of seqs: 8065, num. of tokens: 90423, 30.1883[sec]\n",
            "2024-08-13 20:41:07,694 - INFO - joeynmt.training - EPOCH 281\n",
            "2024-08-13 20:41:37,911 - INFO - joeynmt.training - Epoch 281, total training loss: 32.19, num. of seqs: 8065, num. of tokens: 90423, 30.2157[sec]\n",
            "2024-08-13 20:41:37,912 - INFO - joeynmt.training - EPOCH 282\n",
            "2024-08-13 20:42:07,694 - INFO - joeynmt.training - Epoch 282, total training loss: 31.88, num. of seqs: 8065, num. of tokens: 90423, 29.7816[sec]\n",
            "2024-08-13 20:42:07,695 - INFO - joeynmt.training - EPOCH 283\n",
            "2024-08-13 20:42:33,578 - INFO - joeynmt.training - Epoch 283, Step:    84000, Batch Loss:     0.111700, Batch Acc: 0.996549, Tokens per Sec:     2966, Lr: 0.000150\n",
            "2024-08-13 20:42:33,579 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=84042\n",
            "2024-08-13 20:42:33,579 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:08<00:00, 180.93it/s]\n",
            "2024-08-13 20:42:41,649 - INFO - joeynmt.prediction - Generation took 8.0698[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 54204.45 examples/s]\n",
            "2024-08-13 20:42:41,862 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:42:41,862 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.66, loss:   4.17, ppl:  64.99, acc:   0.32, 0.1183[sec]\n",
            "2024-08-13 20:42:41,863 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:42:41,909 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:42:41,909 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:42:41,909 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 20:42:42,002 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:42:42,046 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:42:42,046 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:42:42,047 - INFO - joeynmt.training - \tHypothesis: trois points d'avance\n",
            "2024-08-13 20:42:42,137 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:42:42,184 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:42:42,185 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:42:42,185 - INFO - joeynmt.training - \tHypothesis: des joueurs de pages pas\n",
            "2024-08-13 20:42:42,287 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:42:42,334 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:42:42,334 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:42:42,334 - INFO - joeynmt.training - \tHypothesis: l'un et l'autre\n",
            "2024-08-13 20:42:46,862 - INFO - joeynmt.training - Epoch 283, total training loss: 31.89, num. of seqs: 8065, num. of tokens: 90423, 30.3188[sec]\n",
            "2024-08-13 20:42:46,863 - INFO - joeynmt.training - EPOCH 284\n",
            "2024-08-13 20:43:18,113 - INFO - joeynmt.training - Epoch 284, total training loss: 31.43, num. of seqs: 8065, num. of tokens: 90423, 31.2497[sec]\n",
            "2024-08-13 20:43:18,115 - INFO - joeynmt.training - EPOCH 285\n",
            "2024-08-13 20:43:48,368 - INFO - joeynmt.training - Epoch 285, total training loss: 31.58, num. of seqs: 8065, num. of tokens: 90423, 30.2515[sec]\n",
            "2024-08-13 20:43:48,368 - INFO - joeynmt.training - EPOCH 286\n",
            "2024-08-13 20:44:18,375 - INFO - joeynmt.training - Epoch 286, total training loss: 31.88, num. of seqs: 8065, num. of tokens: 90423, 30.0064[sec]\n",
            "2024-08-13 20:44:18,376 - INFO - joeynmt.training - EPOCH 287\n",
            "2024-08-13 20:44:48,597 - INFO - joeynmt.training - Epoch 287, total training loss: 31.57, num. of seqs: 8065, num. of tokens: 90423, 30.2200[sec]\n",
            "2024-08-13 20:44:48,597 - INFO - joeynmt.training - EPOCH 288\n",
            "2024-08-13 20:45:18,995 - INFO - joeynmt.training - Epoch 288, total training loss: 31.44, num. of seqs: 8065, num. of tokens: 90423, 30.3970[sec]\n",
            "2024-08-13 20:45:18,996 - INFO - joeynmt.training - EPOCH 289\n",
            "2024-08-13 20:45:48,616 - INFO - joeynmt.training - Epoch 289, total training loss: 31.39, num. of seqs: 8065, num. of tokens: 90423, 29.6189[sec]\n",
            "2024-08-13 20:45:48,616 - INFO - joeynmt.training - EPOCH 290\n",
            "2024-08-13 20:46:06,416 - INFO - joeynmt.training - Epoch 290, Step:    86000, Batch Loss:     0.109308, Batch Acc: 0.997289, Tokens per Sec:     3005, Lr: 0.000150\n",
            "2024-08-13 20:46:06,417 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=86042\n",
            "2024-08-13 20:46:06,418 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:08<00:00, 180.01it/s]\n",
            "2024-08-13 20:46:14,529 - INFO - joeynmt.prediction - Generation took 8.1110[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 57588.68 examples/s]\n",
            "2024-08-13 20:46:14,731 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:46:14,731 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.67, loss:   4.17, ppl:  64.49, acc:   0.32, 0.1071[sec]\n",
            "2024-08-13 20:46:14,733 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:46:14,782 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:46:14,782 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:46:14,782 - INFO - joeynmt.training - \tHypothesis: comment s’appelle votre sœur\n",
            "2024-08-13 20:46:14,885 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:46:14,930 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:46:14,931 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:46:14,931 - INFO - joeynmt.training - \tHypothesis: trois point de l’avance\n",
            "2024-08-13 20:46:15,020 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:46:15,064 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:46:15,064 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:46:15,064 - INFO - joeynmt.training - \tHypothesis: des jours s’est passé\n",
            "2024-08-13 20:46:15,156 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:46:15,200 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:46:15,201 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:46:15,201 - INFO - joeynmt.training - \tHypothesis: l'un et l'autre\n",
            "2024-08-13 20:46:28,270 - INFO - joeynmt.training - Epoch 290, total training loss: 31.50, num. of seqs: 8065, num. of tokens: 90423, 30.7725[sec]\n",
            "2024-08-13 20:46:28,270 - INFO - joeynmt.training - EPOCH 291\n",
            "2024-08-13 20:46:59,155 - INFO - joeynmt.training - Epoch 291, total training loss: 31.59, num. of seqs: 8065, num. of tokens: 90423, 30.8835[sec]\n",
            "2024-08-13 20:46:59,155 - INFO - joeynmt.training - EPOCH 292\n",
            "2024-08-13 20:47:30,056 - INFO - joeynmt.training - Epoch 292, total training loss: 31.85, num. of seqs: 8065, num. of tokens: 90423, 30.8998[sec]\n",
            "2024-08-13 20:47:30,056 - INFO - joeynmt.training - EPOCH 293\n",
            "2024-08-13 20:47:59,400 - INFO - joeynmt.training - Epoch 293, total training loss: 31.27, num. of seqs: 8065, num. of tokens: 90423, 29.3436[sec]\n",
            "2024-08-13 20:47:59,401 - INFO - joeynmt.training - EPOCH 294\n",
            "2024-08-13 20:48:28,917 - INFO - joeynmt.training - Epoch 294, total training loss: 31.33, num. of seqs: 8065, num. of tokens: 90423, 29.5150[sec]\n",
            "2024-08-13 20:48:28,918 - INFO - joeynmt.training - EPOCH 295\n",
            "2024-08-13 20:48:59,224 - INFO - joeynmt.training - Epoch 295, total training loss: 30.94, num. of seqs: 8065, num. of tokens: 90423, 30.3048[sec]\n",
            "2024-08-13 20:48:59,225 - INFO - joeynmt.training - EPOCH 296\n",
            "2024-08-13 20:49:28,874 - INFO - joeynmt.training - Epoch 296, total training loss: 31.34, num. of seqs: 8065, num. of tokens: 90423, 29.6483[sec]\n",
            "2024-08-13 20:49:28,874 - INFO - joeynmt.training - EPOCH 297\n",
            "2024-08-13 20:49:38,609 - INFO - joeynmt.training - Epoch 297, Step:    88000, Batch Loss:     0.095142, Batch Acc: 0.997404, Tokens per Sec:     2968, Lr: 0.000150\n",
            "2024-08-13 20:49:38,610 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=88042\n",
            "2024-08-13 20:49:38,610 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 198.30it/s]\n",
            "2024-08-13 20:49:45,974 - INFO - joeynmt.prediction - Generation took 7.3630[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 61577.52 examples/s]\n",
            "2024-08-13 20:49:46,490 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:49:46,491 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.50, loss:   4.17, ppl:  64.62, acc:   0.32, 0.4243[sec]\n",
            "2024-08-13 20:49:46,492 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:49:46,538 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:49:46,538 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:49:46,538 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 20:49:46,627 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:49:46,699 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:49:46,700 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:49:46,700 - INFO - joeynmt.training - \tHypothesis: trois point d’avance\n",
            "2024-08-13 20:49:46,855 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:49:46,933 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:49:46,933 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:49:46,933 - INFO - joeynmt.training - \tHypothesis: il ne s’est pas d’un jeu\n",
            "2024-08-13 20:49:47,084 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:49:47,161 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:49:47,161 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:49:47,161 - INFO - joeynmt.training - \tHypothesis: un succès au régime\n",
            "2024-08-13 20:50:08,658 - INFO - joeynmt.training - Epoch 297, total training loss: 31.47, num. of seqs: 8065, num. of tokens: 90423, 31.0750[sec]\n",
            "2024-08-13 20:50:08,659 - INFO - joeynmt.training - EPOCH 298\n",
            "2024-08-13 20:50:38,183 - INFO - joeynmt.training - Epoch 298, total training loss: 31.09, num. of seqs: 8065, num. of tokens: 90423, 29.5239[sec]\n",
            "2024-08-13 20:50:38,184 - INFO - joeynmt.training - EPOCH 299\n",
            "2024-08-13 20:51:08,598 - INFO - joeynmt.training - Epoch 299, total training loss: 31.07, num. of seqs: 8065, num. of tokens: 90423, 30.4137[sec]\n",
            "2024-08-13 20:51:08,599 - INFO - joeynmt.training - EPOCH 300\n",
            "2024-08-13 20:51:38,312 - INFO - joeynmt.training - Epoch 300, total training loss: 31.43, num. of seqs: 8065, num. of tokens: 90423, 29.7126[sec]\n",
            "2024-08-13 20:51:38,313 - INFO - joeynmt.training - EPOCH 301\n",
            "2024-08-13 20:52:07,914 - INFO - joeynmt.training - Epoch 301, total training loss: 31.18, num. of seqs: 8065, num. of tokens: 90423, 29.6007[sec]\n",
            "2024-08-13 20:52:07,915 - INFO - joeynmt.training - EPOCH 302\n",
            "2024-08-13 20:52:38,078 - INFO - joeynmt.training - Epoch 302, total training loss: 30.94, num. of seqs: 8065, num. of tokens: 90423, 30.1623[sec]\n",
            "2024-08-13 20:52:38,078 - INFO - joeynmt.training - EPOCH 303\n",
            "2024-08-13 20:53:07,704 - INFO - joeynmt.training - Epoch 303, total training loss: 31.05, num. of seqs: 8065, num. of tokens: 90423, 29.6242[sec]\n",
            "2024-08-13 20:53:07,704 - INFO - joeynmt.training - EPOCH 304\n",
            "2024-08-13 20:53:09,377 - INFO - joeynmt.training - Epoch 304, Step:    90000, Batch Loss:     0.106609, Batch Acc: 0.998134, Tokens per Sec:     3207, Lr: 0.000150\n",
            "2024-08-13 20:53:09,378 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=90042\n",
            "2024-08-13 20:53:09,378 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 193.41it/s]\n",
            "2024-08-13 20:53:16,928 - INFO - joeynmt.prediction - Generation took 7.5492[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 35543.72 examples/s]\n",
            "2024-08-13 20:53:17,273 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:53:17,273 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.80, loss:   4.19, ppl:  65.98, acc:   0.32, 0.1852[sec]\n",
            "2024-08-13 20:53:17,276 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:53:17,362 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:53:17,362 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:53:17,362 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 20:53:17,480 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:53:17,530 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:53:17,531 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:53:17,531 - INFO - joeynmt.training - \tHypothesis: trois points d’avance\n",
            "2024-08-13 20:53:17,621 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:53:17,665 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:53:17,666 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:53:17,666 - INFO - joeynmt.training - \tHypothesis: il n’est pas d’un jeu\n",
            "2024-08-13 20:53:17,754 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:53:17,797 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:53:17,797 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:53:17,797 - INFO - joeynmt.training - \tHypothesis: un autre animal\n",
            "2024-08-13 20:53:46,438 - INFO - joeynmt.training - Epoch 304, total training loss: 31.23, num. of seqs: 8065, num. of tokens: 90423, 30.2190[sec]\n",
            "2024-08-13 20:53:46,439 - INFO - joeynmt.training - EPOCH 305\n",
            "2024-08-13 20:54:15,777 - INFO - joeynmt.training - Epoch 305, total training loss: 30.72, num. of seqs: 8065, num. of tokens: 90423, 29.3377[sec]\n",
            "2024-08-13 20:54:15,777 - INFO - joeynmt.training - EPOCH 306\n",
            "2024-08-13 20:54:45,579 - INFO - joeynmt.training - Epoch 306, total training loss: 31.37, num. of seqs: 8065, num. of tokens: 90423, 29.8009[sec]\n",
            "2024-08-13 20:54:45,580 - INFO - joeynmt.training - EPOCH 307\n",
            "2024-08-13 20:55:15,815 - INFO - joeynmt.training - Epoch 307, total training loss: 31.15, num. of seqs: 8065, num. of tokens: 90423, 30.2343[sec]\n",
            "2024-08-13 20:55:15,816 - INFO - joeynmt.training - EPOCH 308\n",
            "2024-08-13 20:55:45,395 - INFO - joeynmt.training - Epoch 308, total training loss: 31.17, num. of seqs: 8065, num. of tokens: 90423, 29.5781[sec]\n",
            "2024-08-13 20:55:45,395 - INFO - joeynmt.training - EPOCH 309\n",
            "2024-08-13 20:56:14,754 - INFO - joeynmt.training - Epoch 309, total training loss: 30.89, num. of seqs: 8065, num. of tokens: 90423, 29.3583[sec]\n",
            "2024-08-13 20:56:14,755 - INFO - joeynmt.training - EPOCH 310\n",
            "2024-08-13 20:56:38,599 - INFO - joeynmt.training - Epoch 310, Step:    92000, Batch Loss:     0.108177, Batch Acc: 0.996811, Tokens per Sec:     3025, Lr: 0.000150\n",
            "2024-08-13 20:56:38,600 - INFO - joeynmt.datasets - Sample random subset from validation data: n=1460, seed=92042\n",
            "2024-08-13 20:56:38,600 - INFO - joeynmt.prediction - Predicting 1460 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 1460/1460 [00:07<00:00, 185.44it/s]\n",
            "2024-08-13 20:56:46,474 - INFO - joeynmt.prediction - Generation took 7.8736[sec].\n",
            "Filter: 100% 1471/1471 [00:00<00:00, 60600.14 examples/s]\n",
            "2024-08-13 20:56:46,674 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2\n",
            "2024-08-13 20:56:46,674 - INFO - joeynmt.prediction - Evaluation result (greedy): bleu:   6.78, loss:   4.18, ppl:  65.37, acc:   0.32, 0.1076[sec]\n",
            "2024-08-13 20:56:46,675 - INFO - joeynmt.training - Example #0\n",
            "2024-08-13 20:56:46,733 - INFO - joeynmt.training - \tSource:     i tɔgɔ bi cogodɔ\n",
            "2024-08-13 20:56:46,733 - INFO - joeynmt.training - \tReference:  tu portes un nom de fantaisie\n",
            "2024-08-13 20:56:46,733 - INFO - joeynmt.training - \tHypothesis: comment t’appellestu\n",
            "2024-08-13 20:56:46,822 - INFO - joeynmt.training - Example #1\n",
            "2024-08-13 20:56:46,865 - INFO - joeynmt.training - \tSource:     puɛn saba fɔlɔ\n",
            "2024-08-13 20:56:46,865 - INFO - joeynmt.training - \tReference:  trois points d’avance\n",
            "2024-08-13 20:56:46,865 - INFO - joeynmt.training - \tHypothesis: trois points d’avance\n",
            "2024-08-13 20:56:46,953 - INFO - joeynmt.training - Example #2\n",
            "2024-08-13 20:56:46,997 - INFO - joeynmt.training - \tSource:     tile bena\n",
            "2024-08-13 20:56:46,997 - INFO - joeynmt.training - \tReference:  le soleil s’est couché\n",
            "2024-08-13 20:56:46,998 - INFO - joeynmt.training - \tHypothesis: des jours s'est passé\n",
            "2024-08-13 20:56:47,086 - INFO - joeynmt.training - Example #3\n",
            "2024-08-13 20:56:47,130 - INFO - joeynmt.training - \tSource:     cogoya kelen\n",
            "2024-08-13 20:56:47,131 - INFO - joeynmt.training - \tReference:  mêmes mouvements\n",
            "2024-08-13 20:56:47,131 - INFO - joeynmt.training - \tHypothesis: l'un et l'autre\n",
            "2024-08-13 20:56:53,088 - INFO - joeynmt.training - Epoch 310, total training loss: 30.81, num. of seqs: 8065, num. of tokens: 90423, 29.7086[sec]\n",
            "2024-08-13 20:56:53,088 - INFO - joeynmt.training - EPOCH 311\n",
            "2024-08-13 20:57:24,165 - INFO - joeynmt.training - Epoch 311, total training loss: 29.21, num. of seqs: 8065, num. of tokens: 90423, 31.0768[sec]\n",
            "2024-08-13 20:57:24,166 - INFO - joeynmt.training - EPOCH 312\n",
            "2024-08-13 20:57:53,673 - INFO - joeynmt.training - Epoch 312, total training loss: 28.58, num. of seqs: 8065, num. of tokens: 90423, 29.5062[sec]\n",
            "2024-08-13 20:57:53,673 - INFO - joeynmt.training - EPOCH 313\n",
            "2024-08-13 20:58:23,219 - INFO - joeynmt.training - Epoch 313, total training loss: 27.96, num. of seqs: 8065, num. of tokens: 90423, 29.5459[sec]\n",
            "2024-08-13 20:58:23,220 - INFO - joeynmt.training - EPOCH 314\n",
            "2024-08-13 20:58:53,274 - INFO - joeynmt.training - Epoch 314, total training loss: 27.49, num. of seqs: 8065, num. of tokens: 90423, 30.0532[sec]\n",
            "2024-08-13 20:58:53,274 - INFO - joeynmt.training - EPOCH 315\n",
            "2024-08-13 20:59:23,302 - INFO - joeynmt.training - Epoch 315, total training loss: 27.06, num. of seqs: 8065, num. of tokens: 90423, 30.0263[sec]\n",
            "2024-08-13 20:59:23,302 - INFO - joeynmt.training - EPOCH 316\n",
            "2024-08-13 20:59:52,940 - INFO - joeynmt.training - Epoch 316, total training loss: 26.83, num. of seqs: 8065, num. of tokens: 90423, 29.6370[sec]\n",
            "2024-08-13 20:59:52,941 - INFO - joeynmt.training - Training ended after 316 epochs.\n",
            "2024-08-13 20:59:52,941 - INFO - joeynmt.training - Best validation result (greedy) at step    80000:   7.05 bleu.\n",
            "2024-08-13 20:59:53,156 - INFO - joeynmt.training - Checkpoint saved in /content/../saved_model/dyu_fr/93844.ckpt.\n",
            "2024-08-13 20:59:53,158 - INFO - joeynmt.training - Skipping test after training.\n",
            "CPU times: user 56.2 s, sys: 7.63 s, total: 1min 3s\n",
            "Wall time: 2h 47min 21s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!python -m joeynmt train {data_dir}/config.yaml --skip-test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q7wLJZWqBJp"
      },
      "source": [
        "Invalid scheduler. Valid options: 'plateau', 'decaying', 'exponential', 'noam', 'warmupexponentialdecay', 'warmupinversesquareroot'.\n",
        "\n",
        "\n",
        "Plateau - 1.99\n",
        "warmupinversesquareroot - 1.00"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaNe3IenSDG9"
      },
      "outputs": [],
      "source": [
        "# Add the best model info on config file\n",
        "with (Path(model_dir) / \"config.yaml\").open('r') as f:\n",
        "    config = f.read()\n",
        "resume_config = config\\\n",
        "  .replace(f'#load_model: \"{model_dir}/best.ckpt\"',\n",
        "           f'load_model: \"{model_dir}/best.ckpt\"')\n",
        "\n",
        "resume_config = resume_config\\\n",
        "  .replace(f'model_file: \"{data_dir}/sp.model\"',\n",
        "           f'model_file: \"{model_dir}/sp.model\"')\n",
        "\n",
        "resume_config = resume_config\\\n",
        "  .replace(f'voc_file: \"{data_dir}/vocab.txt\"',\n",
        "           f'voc_file: \"{model_dir}/vocab.txt\"')\n",
        "\n",
        "with (Path(model_dir) / \"config.yaml\").open('w') as f:\n",
        "    f.write(resume_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nafMgzcSIta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e1cd80-cfbc-44b3-c9bb-4c947d8eb310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create directory '/content/drive/MyDrive/mt-dyu-fr': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cp {data_dir}/vocab.txt  {model_dir}\n",
        "!cp -R {model_dir} /content/drive/MyDrive/mt-dyu-fr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6O-ZtPASsV1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "os.makedirs('/content/lean_model', exist_ok=True)\n",
        "\n",
        "files_to_copy = [\n",
        "    (\"/content/../saved_model/dyu_fr/best.ckpt\", \"/content/lean_model/best.ckpt\"),\n",
        "    (\"/content/../saved_model/dyu_fr/config.yaml\", \"/content/lean_model/config.yaml\"),\n",
        "    (\"/content/../saved_model/dyu_fr/sp.model\", \"/content/lean_model/sp.model\"),\n",
        "    (\"/content/../saved_model/dyu_fr/vocab.txt\", \"/content/lean_model/vocab.txt\")\n",
        "]\n",
        "\n",
        "for src, dst in files_to_copy:\n",
        "    shutil.copy(src, dst)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz_39RC97-7v"
      },
      "source": [
        "### Upload Trained Model to HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPGHkXoaQghR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360,
          "referenced_widgets": [
            "d8e3a3f72e8943e3a4d62ff119e67625",
            "f8ff644d4bcf4d9aad6652df255461b1",
            "fe12e916304044e1948b26fc0c650a83",
            "2d6ed5077ec949cd95bdfe9ff5763f96",
            "0f644e3c45e1462dad8754f338f3e8bc",
            "6a55f0d2df344903aa4e783f3cb73463",
            "7d551f3a8c194018a3a1984414d67dd5",
            "685382331bbc4d5a8f04a26e905818f7",
            "65dbdb71d42748d4a3ebaac097c3118c",
            "9fed4bbdc5de44ebb6d4bc27c0001561",
            "47ed62a50f8140ef9f4f0052d78a1a71",
            "b6479a952cd44f84be0a1714aa5584b5",
            "54f9d641b6794f86ba37d28ff1c51445",
            "696aaf1f393449b5a9a5c1e039e76d33",
            "72fba3ad8ade45f9931cce9ceba91f2f",
            "4eb8cc5c969046eab4093ff15ee48714",
            "54ae13f47a234ab5bc4fed43aa377068"
          ]
        },
        "outputId": "f92c804c-242c-41d9-b947-be2db4f66c95"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8e3a3f72e8943e3a4d62ff119e67625"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtpQBLV68BS1"
      },
      "outputs": [],
      "source": [
        "# Remember to run `huggingface-cli login` before you run the code below\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import joeynmt\n",
        "import torch\n",
        "from huggingface_hub import HfApi\n",
        "\n",
        "api = HfApi()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xh7JIIT6nIqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78c9dc53-4c3b-400e-fe79-37d93a7bcdfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-08-13 21:36:32,694 - INFO - joeynmt.data - Building tokenizer...\n",
            "2024-08-13 21:36:32,703 - INFO - joeynmt.tokenizers - dyu tokenizer: SentencePieceTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, 100), pretokenizer=none, tokenizer=SentencePieceProcessor, nbest_size=5, alpha=0.0)\n",
            "2024-08-13 21:36:32,704 - INFO - joeynmt.tokenizers - fr tokenizer: SentencePieceTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, 100), pretokenizer=none, tokenizer=SentencePieceProcessor, nbest_size=5, alpha=0.0)\n",
            "2024-08-13 21:36:32,705 - INFO - joeynmt.data - Building vocabulary...\n",
            "2024-08-13 21:36:32,762 - INFO - joeynmt.data - Data loaded.\n",
            "2024-08-13 21:36:32,763 - INFO - joeynmt.data - Train dataset: None\n",
            "2024-08-13 21:36:32,765 - INFO - joeynmt.data - Valid dataset: None\n",
            "2024-08-13 21:36:32,767 - INFO - joeynmt.data -  Test dataset: StreamDataset(split=test, len=0, src_lang=\"dyu\", trg_lang=\"fr\", has_trg=False, random_subset=-1, has_src_prompt=False, has_trg_prompt=False)\n",
            "2024-08-13 21:36:32,769 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) s (5) ▁a (6) ▁ka (7) a (8) ' (9) ▁\n",
            "2024-08-13 21:36:32,771 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) s (5) ▁a (6) ▁ka (7) a (8) ' (9) ▁\n",
            "2024-08-13 21:36:32,772 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2000\n",
            "2024-08-13 21:36:32,773 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2000\n",
            "2024-08-13 21:36:32,774 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
            "2024-08-13 21:36:32,917 - INFO - joeynmt.model - Enc-dec model built.\n",
            "2024-08-13 21:36:32,920 - INFO - joeynmt.model - Total params: 9051648\n",
            "2024-08-13 21:36:32,923 - INFO - joeynmt.prediction - Loading model from /content/../saved_model/dyu_fr/best.ckpt\n",
            "2024-08-13 21:36:33,075 - INFO - joeynmt.prediction - Model(\n",
            "\tencoder=TransformerEncoder(num_layers=2, num_heads=8, alpha=1.0, layer_norm=\"pre\", activation=GELU(approximate='none')),\n",
            "\tdecoder=TransformerDecoder(num_layers=2, num_heads=8, alpha=1.0, layer_norm=\"pre\", activation=GELU(approximate='none')),\n",
            "\tsrc_embed=Embeddings(embedding_dim=384, vocab_size=2000),\n",
            "\ttrg_embed=Embeddings(embedding_dim=384, vocab_size=2000),\n",
            "\tloss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.1))\n"
          ]
        }
      ],
      "source": [
        "# load the model\n",
        "import torch\n",
        "from joeynmt.config import load_config, parse_global_args\n",
        "from joeynmt.prediction import predict, prepare\n",
        "\n",
        "\n",
        "class JoeyNMTModel:\n",
        "    \"\"\"\n",
        "    JoeyNMTModel which load JoeyNMT model for inference.\n",
        "\n",
        "    :param config_path: Path to YAML config file\n",
        "    :param n_best: return this many hypotheses, <= beam (currently only 1)\n",
        "    \"\"\"\n",
        "    def __init__(self, config_path: str, n_best: int = 1):\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "        cfg = load_config(config_path)\n",
        "        args = parse_global_args(cfg, rank=0, mode=\"translate\")\n",
        "        self.args = args._replace(test=args.test._replace(n_best=n_best))\n",
        "        # build model\n",
        "        self.model, _, _, self.test_data = prepare(self.args, rank=0, mode=\"translate\")\n",
        "\n",
        "    def _translate_data(self):\n",
        "        _, _, hypotheses, trg_tokens, trg_scores, _ = predict(\n",
        "            model=self.model,\n",
        "            data=self.test_data,\n",
        "            compute_loss=False,\n",
        "            device=self.args.device,\n",
        "            rank=0,\n",
        "            n_gpu=self.args.n_gpu,\n",
        "            normalization=\"none\",\n",
        "            num_workers=self.args.num_workers,\n",
        "            args=self.args.test,\n",
        "            autocast=self.args.autocast,\n",
        "        )\n",
        "        return hypotheses, trg_tokens, trg_scores\n",
        "\n",
        "    def translate(self, sentence) -> list:\n",
        "        \"\"\"\n",
        "        Translate the given sentence.\n",
        "\n",
        "        :param sentence: Sentence to be translated\n",
        "        :return:\n",
        "        - translations: (list of str) possible translations of the sentence.\n",
        "        \"\"\"\n",
        "        self.test_data.set_item(sentence.strip())\n",
        "        translations, _, _ = self._translate_data()\n",
        "        assert len(translations) == len(self.test_data) * self.args.test.n_best\n",
        "        self.test_data.reset_cache()\n",
        "        return translations\n",
        "config_path = \"/content/lean_model/config.yaml\" # Change this to the path to your model congig file\n",
        "model = JoeyNMTModel(config_path=config_path, n_best=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj-MdNt5nJev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b254e8aa-d1b4-4a51-af7d-b3931e1f24d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1471 [00:00<?, ?it/s]2024-08-13 21:36:33,386 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:33,437 - INFO - joeynmt.prediction - Generation took 0.0487[sec].\n",
            "2024-08-13 21:36:33,438 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:33,599 - INFO - joeynmt.prediction - Generation took 0.1577[sec].\n",
            "  0%|          | 2/1471 [00:00<02:38,  9.26it/s]2024-08-13 21:36:33,604 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:33,734 - INFO - joeynmt.prediction - Generation took 0.1289[sec].\n",
            "  0%|          | 3/1471 [00:00<02:54,  8.39it/s]2024-08-13 21:36:33,737 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:33,794 - INFO - joeynmt.prediction - Generation took 0.0539[sec].\n",
            "2024-08-13 21:36:33,795 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:33,866 - INFO - joeynmt.prediction - Generation took 0.0664[sec].\n",
            "  0%|          | 5/1471 [00:00<02:12, 11.09it/s]2024-08-13 21:36:33,871 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:33,942 - INFO - joeynmt.prediction - Generation took 0.0685[sec].\n",
            "2024-08-13 21:36:33,943 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:34,008 - INFO - joeynmt.prediction - Generation took 0.0616[sec].\n",
            "  0%|          | 7/1471 [00:00<01:59, 12.20it/s]2024-08-13 21:36:34,011 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:34,050 - INFO - joeynmt.prediction - Generation took 0.0351[sec].\n",
            "2024-08-13 21:36:34,052 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:34,122 - INFO - joeynmt.prediction - Generation took 0.0677[sec].\n",
            "  1%|          | 9/1471 [00:00<01:45, 13.85it/s]2024-08-13 21:36:34,126 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:34,246 - INFO - joeynmt.prediction - Generation took 0.1179[sec].\n",
            "2024-08-13 21:36:34,248 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:34,392 - INFO - joeynmt.prediction - Generation took 0.1408[sec].\n",
            "  1%|          | 11/1471 [00:01<02:18, 10.58it/s]2024-08-13 21:36:34,396 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:34,498 - INFO - joeynmt.prediction - Generation took 0.1004[sec].\n",
            "2024-08-13 21:36:34,501 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:34,574 - INFO - joeynmt.prediction - Generation took 0.0706[sec].\n",
            "  1%|          | 13/1471 [00:01<02:15, 10.72it/s]2024-08-13 21:36:34,577 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:34,636 - INFO - joeynmt.prediction - Generation took 0.0571[sec].\n",
            "2024-08-13 21:36:34,638 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:34,774 - INFO - joeynmt.prediction - Generation took 0.1330[sec].\n",
            "  1%|          | 15/1471 [00:01<02:19, 10.47it/s]2024-08-13 21:36:34,778 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:34,828 - INFO - joeynmt.prediction - Generation took 0.0482[sec].\n",
            "2024-08-13 21:36:34,830 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:34,882 - INFO - joeynmt.prediction - Generation took 0.0495[sec].\n",
            "  1%|          | 17/1471 [00:01<01:59, 12.13it/s]2024-08-13 21:36:34,888 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:34,974 - INFO - joeynmt.prediction - Generation took 0.0842[sec].\n",
            "2024-08-13 21:36:34,977 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:35,042 - INFO - joeynmt.prediction - Generation took 0.0631[sec].\n",
            "  1%|▏         | 19/1471 [00:01<01:58, 12.25it/s]2024-08-13 21:36:35,046 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:35,333 - INFO - joeynmt.prediction - Generation took 0.2839[sec].\n",
            "2024-08-13 21:36:35,336 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:35,412 - INFO - joeynmt.prediction - Generation took 0.0747[sec].\n",
            "  1%|▏         | 21/1471 [00:02<02:44,  8.81it/s]2024-08-13 21:36:35,417 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:35,558 - INFO - joeynmt.prediction - Generation took 0.1397[sec].\n",
            "2024-08-13 21:36:35,561 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:35,617 - INFO - joeynmt.prediction - Generation took 0.0537[sec].\n",
            "  2%|▏         | 23/1471 [00:02<02:39,  9.09it/s]2024-08-13 21:36:35,620 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:35,771 - INFO - joeynmt.prediction - Generation took 0.1468[sec].\n",
            "2024-08-13 21:36:35,773 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:35,932 - INFO - joeynmt.prediction - Generation took 0.1561[sec].\n",
            "  2%|▏         | 25/1471 [00:02<03:00,  8.03it/s]2024-08-13 21:36:35,936 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:35,999 - INFO - joeynmt.prediction - Generation took 0.0596[sec].\n",
            "2024-08-13 21:36:36,001 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:36,222 - INFO - joeynmt.prediction - Generation took 0.2188[sec].\n",
            "  2%|▏         | 27/1471 [00:02<03:08,  7.64it/s]2024-08-13 21:36:36,227 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:36,275 - INFO - joeynmt.prediction - Generation took 0.0450[sec].\n",
            "2024-08-13 21:36:36,276 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:36,424 - INFO - joeynmt.prediction - Generation took 0.1440[sec].\n",
            "  2%|▏         | 29/1471 [00:03<02:55,  8.22it/s]2024-08-13 21:36:36,428 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:36,498 - INFO - joeynmt.prediction - Generation took 0.0683[sec].\n",
            "2024-08-13 21:36:36,500 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:36,610 - INFO - joeynmt.prediction - Generation took 0.1077[sec].\n",
            "  2%|▏         | 31/1471 [00:03<02:43,  8.83it/s]2024-08-13 21:36:36,615 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:36,680 - INFO - joeynmt.prediction - Generation took 0.0627[sec].\n",
            "2024-08-13 21:36:36,683 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:36,731 - INFO - joeynmt.prediction - Generation took 0.0464[sec].\n",
            "  2%|▏         | 33/1471 [00:03<02:19, 10.30it/s]2024-08-13 21:36:36,734 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:36,791 - INFO - joeynmt.prediction - Generation took 0.0533[sec].\n",
            "2024-08-13 21:36:36,793 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:36,887 - INFO - joeynmt.prediction - Generation took 0.0905[sec].\n",
            "  2%|▏         | 35/1471 [00:03<02:11, 10.95it/s]2024-08-13 21:36:36,890 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:36,962 - INFO - joeynmt.prediction - Generation took 0.0663[sec].\n",
            "2024-08-13 21:36:36,963 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:37,376 - INFO - joeynmt.prediction - Generation took 0.4093[sec].\n",
            "  3%|▎         | 37/1471 [00:03<03:17,  7.27it/s]2024-08-13 21:36:37,380 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:37,450 - INFO - joeynmt.prediction - Generation took 0.0675[sec].\n",
            "2024-08-13 21:36:37,452 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:37,516 - INFO - joeynmt.prediction - Generation took 0.0616[sec].\n",
            "  3%|▎         | 39/1471 [00:04<02:47,  8.54it/s]2024-08-13 21:36:37,520 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:37,575 - INFO - joeynmt.prediction - Generation took 0.0489[sec].\n",
            "2024-08-13 21:36:37,577 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:37,626 - INFO - joeynmt.prediction - Generation took 0.0468[sec].\n",
            "  3%|▎         | 41/1471 [00:04<02:20, 10.15it/s]2024-08-13 21:36:37,631 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:37,717 - INFO - joeynmt.prediction - Generation took 0.0836[sec].\n",
            "2024-08-13 21:36:37,718 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:37,794 - INFO - joeynmt.prediction - Generation took 0.0716[sec].\n",
            "  3%|▎         | 43/1471 [00:04<02:14, 10.63it/s]2024-08-13 21:36:37,800 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:37,846 - INFO - joeynmt.prediction - Generation took 0.0430[sec].\n",
            "2024-08-13 21:36:37,847 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:37,910 - INFO - joeynmt.prediction - Generation took 0.0591[sec].\n",
            "  3%|▎         | 45/1471 [00:04<01:59, 11.92it/s]2024-08-13 21:36:37,917 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:37,957 - INFO - joeynmt.prediction - Generation took 0.0372[sec].\n",
            "2024-08-13 21:36:37,958 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:38,015 - INFO - joeynmt.prediction - Generation took 0.0538[sec].\n",
            "  3%|▎         | 47/1471 [00:04<01:45, 13.53it/s]2024-08-13 21:36:38,019 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:38,075 - INFO - joeynmt.prediction - Generation took 0.0541[sec].\n",
            "2024-08-13 21:36:38,077 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:38,132 - INFO - joeynmt.prediction - Generation took 0.0528[sec].\n",
            "  3%|▎         | 49/1471 [00:04<01:38, 14.44it/s]2024-08-13 21:36:38,136 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:38,450 - INFO - joeynmt.prediction - Generation took 0.3122[sec].\n",
            "2024-08-13 21:36:38,457 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:38,561 - INFO - joeynmt.prediction - Generation took 0.1002[sec].\n",
            "  3%|▎         | 51/1471 [00:05<02:41,  8.82it/s]2024-08-13 21:36:38,572 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:38,680 - INFO - joeynmt.prediction - Generation took 0.1052[sec].\n",
            "2024-08-13 21:36:38,682 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:38,838 - INFO - joeynmt.prediction - Generation took 0.1534[sec].\n",
            "  4%|▎         | 53/1471 [00:05<02:50,  8.30it/s]2024-08-13 21:36:38,842 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:38,945 - INFO - joeynmt.prediction - Generation took 0.1004[sec].\n",
            "2024-08-13 21:36:38,947 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:39,007 - INFO - joeynmt.prediction - Generation took 0.0575[sec].\n",
            "  4%|▎         | 55/1471 [00:05<02:35,  9.12it/s]2024-08-13 21:36:39,011 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:39,111 - INFO - joeynmt.prediction - Generation took 0.0983[sec].\n",
            "2024-08-13 21:36:39,114 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:39,190 - INFO - joeynmt.prediction - Generation took 0.0745[sec].\n",
            "  4%|▍         | 57/1471 [00:05<02:27,  9.59it/s]2024-08-13 21:36:39,195 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:39,335 - INFO - joeynmt.prediction - Generation took 0.1378[sec].\n",
            "2024-08-13 21:36:39,337 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:39,429 - INFO - joeynmt.prediction - Generation took 0.0890[sec].\n",
            "  4%|▍         | 59/1471 [00:06<02:33,  9.20it/s]2024-08-13 21:36:39,434 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:39,561 - INFO - joeynmt.prediction - Generation took 0.1238[sec].\n",
            "2024-08-13 21:36:39,567 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:39,780 - INFO - joeynmt.prediction - Generation took 0.2072[sec].\n",
            "  4%|▍         | 61/1471 [00:06<03:02,  7.74it/s]2024-08-13 21:36:39,788 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:39,909 - INFO - joeynmt.prediction - Generation took 0.1152[sec].\n",
            "  4%|▍         | 62/1471 [00:06<03:01,  7.77it/s]2024-08-13 21:36:39,913 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:40,018 - INFO - joeynmt.prediction - Generation took 0.1022[sec].\n",
            "  4%|▍         | 63/1471 [00:06<02:55,  8.01it/s]2024-08-13 21:36:40,023 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:40,101 - INFO - joeynmt.prediction - Generation took 0.0747[sec].\n",
            "2024-08-13 21:36:40,105 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:40,247 - INFO - joeynmt.prediction - Generation took 0.1391[sec].\n",
            "  4%|▍         | 65/1471 [00:06<02:50,  8.23it/s]2024-08-13 21:36:40,257 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:40,358 - INFO - joeynmt.prediction - Generation took 0.0993[sec].\n",
            "  4%|▍         | 66/1471 [00:06<02:47,  8.39it/s]2024-08-13 21:36:40,365 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:40,426 - INFO - joeynmt.prediction - Generation took 0.0558[sec].\n",
            "2024-08-13 21:36:40,429 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:40,719 - INFO - joeynmt.prediction - Generation took 0.2883[sec].\n",
            "  5%|▍         | 68/1471 [00:07<03:19,  7.04it/s]2024-08-13 21:36:40,728 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:40,862 - INFO - joeynmt.prediction - Generation took 0.1300[sec].\n",
            "  5%|▍         | 69/1471 [00:07<03:19,  7.03it/s]2024-08-13 21:36:40,870 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:41,097 - INFO - joeynmt.prediction - Generation took 0.2230[sec].\n",
            "  5%|▍         | 70/1471 [00:07<03:48,  6.14it/s]2024-08-13 21:36:41,101 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:41,152 - INFO - joeynmt.prediction - Generation took 0.0490[sec].\n",
            "2024-08-13 21:36:41,154 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:41,274 - INFO - joeynmt.prediction - Generation took 0.1164[sec].\n",
            "  5%|▍         | 72/1471 [00:07<03:06,  7.50it/s]2024-08-13 21:36:41,279 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:41,367 - INFO - joeynmt.prediction - Generation took 0.0829[sec].\n",
            "2024-08-13 21:36:41,369 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:41,449 - INFO - joeynmt.prediction - Generation took 0.0772[sec].\n",
            "  5%|▌         | 74/1471 [00:08<02:43,  8.56it/s]2024-08-13 21:36:41,453 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:41,523 - INFO - joeynmt.prediction - Generation took 0.0674[sec].\n",
            "2024-08-13 21:36:41,525 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:41,585 - INFO - joeynmt.prediction - Generation took 0.0578[sec].\n",
            "  5%|▌         | 76/1471 [00:08<02:19,  9.98it/s]2024-08-13 21:36:41,589 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:41,708 - INFO - joeynmt.prediction - Generation took 0.1169[sec].\n",
            "2024-08-13 21:36:41,710 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:41,770 - INFO - joeynmt.prediction - Generation took 0.0574[sec].\n",
            "  5%|▌         | 78/1471 [00:08<02:15, 10.24it/s]2024-08-13 21:36:41,773 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:41,874 - INFO - joeynmt.prediction - Generation took 0.0980[sec].\n",
            "2024-08-13 21:36:41,876 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:41,948 - INFO - joeynmt.prediction - Generation took 0.0690[sec].\n",
            "  5%|▌         | 80/1471 [00:08<02:11, 10.54it/s]2024-08-13 21:36:41,951 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:42,330 - INFO - joeynmt.prediction - Generation took 0.3763[sec].\n",
            "2024-08-13 21:36:42,334 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:42,412 - INFO - joeynmt.prediction - Generation took 0.0748[sec].\n",
            "  6%|▌         | 82/1471 [00:09<03:11,  7.25it/s]2024-08-13 21:36:42,416 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:42,486 - INFO - joeynmt.prediction - Generation took 0.0675[sec].\n",
            "2024-08-13 21:36:42,488 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:42,539 - INFO - joeynmt.prediction - Generation took 0.0484[sec].\n",
            "  6%|▌         | 84/1471 [00:09<02:39,  8.71it/s]2024-08-13 21:36:42,543 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:42,633 - INFO - joeynmt.prediction - Generation took 0.0849[sec].\n",
            "2024-08-13 21:36:42,634 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:42,825 - INFO - joeynmt.prediction - Generation took 0.1871[sec].\n",
            "  6%|▌         | 86/1471 [00:09<02:51,  8.09it/s]2024-08-13 21:36:42,829 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:43,008 - INFO - joeynmt.prediction - Generation took 0.1766[sec].\n",
            "  6%|▌         | 87/1471 [00:09<03:05,  7.45it/s]2024-08-13 21:36:43,013 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:43,126 - INFO - joeynmt.prediction - Generation took 0.1116[sec].\n",
            "  6%|▌         | 88/1471 [00:09<03:01,  7.63it/s]2024-08-13 21:36:43,131 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:43,184 - INFO - joeynmt.prediction - Generation took 0.0479[sec].\n",
            "2024-08-13 21:36:43,186 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:43,243 - INFO - joeynmt.prediction - Generation took 0.0549[sec].\n",
            "  6%|▌         | 90/1471 [00:09<02:23,  9.61it/s]2024-08-13 21:36:43,247 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:43,314 - INFO - joeynmt.prediction - Generation took 0.0649[sec].\n",
            "2024-08-13 21:36:43,317 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:43,376 - INFO - joeynmt.prediction - Generation took 0.0563[sec].\n",
            "  6%|▋         | 92/1471 [00:09<02:05, 10.97it/s]2024-08-13 21:36:43,380 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:43,574 - INFO - joeynmt.prediction - Generation took 0.1914[sec].\n",
            "2024-08-13 21:36:43,576 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:43,633 - INFO - joeynmt.prediction - Generation took 0.0549[sec].\n",
            "  6%|▋         | 94/1471 [00:10<02:22,  9.66it/s]2024-08-13 21:36:43,637 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:43,802 - INFO - joeynmt.prediction - Generation took 0.1623[sec].\n",
            "2024-08-13 21:36:43,804 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:43,849 - INFO - joeynmt.prediction - Generation took 0.0420[sec].\n",
            "  7%|▋         | 96/1471 [00:10<02:24,  9.54it/s]2024-08-13 21:36:43,853 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:44,280 - INFO - joeynmt.prediction - Generation took 0.4236[sec].\n",
            "2024-08-13 21:36:44,283 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:44,330 - INFO - joeynmt.prediction - Generation took 0.0433[sec].\n",
            "  7%|▋         | 98/1471 [00:10<03:22,  6.78it/s]2024-08-13 21:36:44,334 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:44,390 - INFO - joeynmt.prediction - Generation took 0.0540[sec].\n",
            "2024-08-13 21:36:44,395 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:44,469 - INFO - joeynmt.prediction - Generation took 0.0706[sec].\n",
            "  7%|▋         | 100/1471 [00:11<02:49,  8.11it/s]2024-08-13 21:36:44,473 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:44,664 - INFO - joeynmt.prediction - Generation took 0.1886[sec].\n",
            "2024-08-13 21:36:44,666 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:44,738 - INFO - joeynmt.prediction - Generation took 0.0674[sec].\n",
            "  7%|▋         | 102/1471 [00:11<02:53,  7.89it/s]2024-08-13 21:36:44,742 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:44,823 - INFO - joeynmt.prediction - Generation took 0.0786[sec].\n",
            "2024-08-13 21:36:44,825 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:44,915 - INFO - joeynmt.prediction - Generation took 0.0883[sec].\n",
            "  7%|▋         | 104/1471 [00:11<02:37,  8.69it/s]2024-08-13 21:36:44,920 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:45,014 - INFO - joeynmt.prediction - Generation took 0.0919[sec].\n",
            "2024-08-13 21:36:45,017 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:45,149 - INFO - joeynmt.prediction - Generation took 0.1297[sec].\n",
            "  7%|▋         | 106/1471 [00:11<02:38,  8.64it/s]2024-08-13 21:36:45,155 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:45,234 - INFO - joeynmt.prediction - Generation took 0.0770[sec].\n",
            "2024-08-13 21:36:45,237 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:45,291 - INFO - joeynmt.prediction - Generation took 0.0521[sec].\n",
            "  7%|▋         | 108/1471 [00:11<02:19,  9.79it/s]2024-08-13 21:36:45,295 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:45,351 - INFO - joeynmt.prediction - Generation took 0.0539[sec].\n",
            "2024-08-13 21:36:45,353 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:45,438 - INFO - joeynmt.prediction - Generation took 0.0830[sec].\n",
            "  7%|▋         | 110/1471 [00:12<02:07, 10.70it/s]2024-08-13 21:36:45,444 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:45,527 - INFO - joeynmt.prediction - Generation took 0.0807[sec].\n",
            "2024-08-13 21:36:45,529 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:45,609 - INFO - joeynmt.prediction - Generation took 0.0776[sec].\n",
            "  8%|▊         | 112/1471 [00:12<02:03, 10.97it/s]2024-08-13 21:36:45,612 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:45,731 - INFO - joeynmt.prediction - Generation took 0.1158[sec].\n",
            "2024-08-13 21:36:45,733 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:45,836 - INFO - joeynmt.prediction - Generation took 0.1000[sec].\n",
            "  8%|▊         | 114/1471 [00:12<02:12, 10.22it/s]2024-08-13 21:36:45,841 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:45,918 - INFO - joeynmt.prediction - Generation took 0.0740[sec].\n",
            "2024-08-13 21:36:45,920 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:45,987 - INFO - joeynmt.prediction - Generation took 0.0635[sec].\n",
            "  8%|▊         | 116/1471 [00:12<02:03, 10.96it/s]2024-08-13 21:36:45,993 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:46,070 - INFO - joeynmt.prediction - Generation took 0.0748[sec].\n",
            "2024-08-13 21:36:46,072 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:46,117 - INFO - joeynmt.prediction - Generation took 0.0429[sec].\n",
            "  8%|▊         | 118/1471 [00:12<01:52, 12.02it/s]2024-08-13 21:36:46,120 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:46,517 - INFO - joeynmt.prediction - Generation took 0.3943[sec].\n",
            "2024-08-13 21:36:46,524 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:46,604 - INFO - joeynmt.prediction - Generation took 0.0790[sec].\n",
            "  8%|▊         | 120/1471 [00:13<02:57,  7.60it/s]2024-08-13 21:36:46,608 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:46,796 - INFO - joeynmt.prediction - Generation took 0.1855[sec].\n",
            "2024-08-13 21:36:46,798 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:46,886 - INFO - joeynmt.prediction - Generation took 0.0850[sec].\n",
            "  8%|▊         | 122/1471 [00:13<03:01,  7.45it/s]2024-08-13 21:36:46,889 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:46,966 - INFO - joeynmt.prediction - Generation took 0.0736[sec].\n",
            "2024-08-13 21:36:46,968 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:47,115 - INFO - joeynmt.prediction - Generation took 0.1444[sec].\n",
            "  8%|▊         | 124/1471 [00:13<02:52,  7.80it/s]2024-08-13 21:36:47,119 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:47,159 - INFO - joeynmt.prediction - Generation took 0.0374[sec].\n",
            "2024-08-13 21:36:47,162 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:47,205 - INFO - joeynmt.prediction - Generation took 0.0414[sec].\n",
            "2024-08-13 21:36:47,207 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:47,277 - INFO - joeynmt.prediction - Generation took 0.0670[sec].\n",
            "  9%|▊         | 127/1471 [00:13<02:13, 10.07it/s]2024-08-13 21:36:47,282 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:47,330 - INFO - joeynmt.prediction - Generation took 0.0458[sec].\n",
            "2024-08-13 21:36:47,332 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:47,524 - INFO - joeynmt.prediction - Generation took 0.1893[sec].\n",
            "  9%|▉         | 129/1471 [00:14<02:21,  9.45it/s]2024-08-13 21:36:47,528 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:47,785 - INFO - joeynmt.prediction - Generation took 0.2547[sec].\n",
            "2024-08-13 21:36:47,787 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:47,852 - INFO - joeynmt.prediction - Generation took 0.0625[sec].\n",
            "  9%|▉         | 131/1471 [00:14<02:43,  8.19it/s]2024-08-13 21:36:47,856 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:47,929 - INFO - joeynmt.prediction - Generation took 0.0714[sec].\n",
            "2024-08-13 21:36:47,931 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:47,975 - INFO - joeynmt.prediction - Generation took 0.0417[sec].\n",
            "  9%|▉         | 133/1471 [00:14<02:20,  9.54it/s]2024-08-13 21:36:47,979 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:48,031 - INFO - joeynmt.prediction - Generation took 0.0494[sec].\n",
            "2024-08-13 21:36:48,034 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:48,103 - INFO - joeynmt.prediction - Generation took 0.0675[sec].\n",
            "  9%|▉         | 135/1471 [00:14<02:04, 10.77it/s]2024-08-13 21:36:48,106 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:48,301 - INFO - joeynmt.prediction - Generation took 0.1920[sec].\n",
            "2024-08-13 21:36:48,303 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:48,544 - INFO - joeynmt.prediction - Generation took 0.2388[sec].\n",
            "  9%|▉         | 137/1471 [00:15<02:53,  7.67it/s]2024-08-13 21:36:48,548 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:48,639 - INFO - joeynmt.prediction - Generation took 0.0878[sec].\n",
            "2024-08-13 21:36:48,641 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:48,725 - INFO - joeynmt.prediction - Generation took 0.0816[sec].\n",
            "  9%|▉         | 139/1471 [00:15<02:37,  8.43it/s]2024-08-13 21:36:48,729 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:48,891 - INFO - joeynmt.prediction - Generation took 0.1587[sec].\n",
            "2024-08-13 21:36:48,893 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:48,946 - INFO - joeynmt.prediction - Generation took 0.0501[sec].\n",
            " 10%|▉         | 141/1471 [00:15<02:34,  8.61it/s]2024-08-13 21:36:48,951 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:49,019 - INFO - joeynmt.prediction - Generation took 0.0646[sec].\n",
            "2024-08-13 21:36:49,022 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:49,079 - INFO - joeynmt.prediction - Generation took 0.0555[sec].\n",
            " 10%|▉         | 143/1471 [00:15<02:14,  9.86it/s]2024-08-13 21:36:49,082 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:49,151 - INFO - joeynmt.prediction - Generation took 0.0657[sec].\n",
            "2024-08-13 21:36:49,152 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:49,210 - INFO - joeynmt.prediction - Generation took 0.0551[sec].\n",
            " 10%|▉         | 145/1471 [00:15<02:00, 11.02it/s]2024-08-13 21:36:49,214 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:49,394 - INFO - joeynmt.prediction - Generation took 0.1783[sec].\n",
            "2024-08-13 21:36:49,396 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:49,463 - INFO - joeynmt.prediction - Generation took 0.0641[sec].\n",
            " 10%|▉         | 147/1471 [00:16<02:14,  9.87it/s]2024-08-13 21:36:49,467 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:49,535 - INFO - joeynmt.prediction - Generation took 0.0664[sec].\n",
            "2024-08-13 21:36:49,538 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:49,636 - INFO - joeynmt.prediction - Generation took 0.0959[sec].\n",
            " 10%|█         | 149/1471 [00:16<02:08, 10.32it/s]2024-08-13 21:36:49,641 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:49,704 - INFO - joeynmt.prediction - Generation took 0.0611[sec].\n",
            "2024-08-13 21:36:49,707 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:49,746 - INFO - joeynmt.prediction - Generation took 0.0373[sec].\n",
            " 10%|█         | 151/1471 [00:16<01:51, 11.86it/s]2024-08-13 21:36:49,751 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:49,820 - INFO - joeynmt.prediction - Generation took 0.0665[sec].\n",
            "2024-08-13 21:36:49,822 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:49,899 - INFO - joeynmt.prediction - Generation took 0.0756[sec].\n",
            " 10%|█         | 153/1471 [00:16<01:48, 12.20it/s]2024-08-13 21:36:49,902 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:49,973 - INFO - joeynmt.prediction - Generation took 0.0687[sec].\n",
            "2024-08-13 21:36:49,975 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:50,026 - INFO - joeynmt.prediction - Generation took 0.0486[sec].\n",
            " 11%|█         | 155/1471 [00:16<01:40, 13.07it/s]2024-08-13 21:36:50,029 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:50,177 - INFO - joeynmt.prediction - Generation took 0.1447[sec].\n",
            "2024-08-13 21:36:50,179 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:50,361 - INFO - joeynmt.prediction - Generation took 0.1785[sec].\n",
            " 11%|█         | 157/1471 [00:16<02:16,  9.65it/s]2024-08-13 21:36:50,365 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:50,500 - INFO - joeynmt.prediction - Generation took 0.1322[sec].\n",
            "2024-08-13 21:36:50,503 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:50,683 - INFO - joeynmt.prediction - Generation took 0.1775[sec].\n",
            " 11%|█         | 159/1471 [00:17<02:38,  8.26it/s]2024-08-13 21:36:50,687 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:50,767 - INFO - joeynmt.prediction - Generation took 0.0768[sec].\n",
            "2024-08-13 21:36:50,769 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:50,897 - INFO - joeynmt.prediction - Generation took 0.1247[sec].\n",
            " 11%|█         | 161/1471 [00:17<02:32,  8.57it/s]2024-08-13 21:36:50,901 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:50,987 - INFO - joeynmt.prediction - Generation took 0.0843[sec].\n",
            "2024-08-13 21:36:50,990 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:51,059 - INFO - joeynmt.prediction - Generation took 0.0672[sec].\n",
            " 11%|█         | 163/1471 [00:17<02:18,  9.42it/s]2024-08-13 21:36:51,064 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:51,292 - INFO - joeynmt.prediction - Generation took 0.2226[sec].\n",
            "2024-08-13 21:36:51,297 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:51,535 - INFO - joeynmt.prediction - Generation took 0.2348[sec].\n",
            " 11%|█         | 165/1471 [00:18<03:10,  6.86it/s]2024-08-13 21:36:51,540 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:51,606 - INFO - joeynmt.prediction - Generation took 0.0629[sec].\n",
            "2024-08-13 21:36:51,611 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:51,674 - INFO - joeynmt.prediction - Generation took 0.0614[sec].\n",
            " 11%|█▏        | 167/1471 [00:18<02:40,  8.14it/s]2024-08-13 21:36:51,679 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:51,815 - INFO - joeynmt.prediction - Generation took 0.1332[sec].\n",
            "2024-08-13 21:36:51,817 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:52,055 - INFO - joeynmt.prediction - Generation took 0.2346[sec].\n",
            " 11%|█▏        | 169/1471 [00:18<03:06,  6.98it/s]2024-08-13 21:36:52,060 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:52,144 - INFO - joeynmt.prediction - Generation took 0.0807[sec].\n",
            "2024-08-13 21:36:52,147 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:52,271 - INFO - joeynmt.prediction - Generation took 0.1211[sec].\n",
            " 12%|█▏        | 171/1471 [00:18<02:52,  7.55it/s]2024-08-13 21:36:52,275 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:52,365 - INFO - joeynmt.prediction - Generation took 0.0866[sec].\n",
            "2024-08-13 21:36:52,368 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:52,453 - INFO - joeynmt.prediction - Generation took 0.0829[sec].\n",
            " 12%|█▏        | 173/1471 [00:19<02:35,  8.32it/s]2024-08-13 21:36:52,458 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:52,525 - INFO - joeynmt.prediction - Generation took 0.0632[sec].\n",
            "2024-08-13 21:36:52,529 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:52,639 - INFO - joeynmt.prediction - Generation took 0.1059[sec].\n",
            " 12%|█▏        | 175/1471 [00:19<02:25,  8.92it/s]2024-08-13 21:36:52,645 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:52,763 - INFO - joeynmt.prediction - Generation took 0.1152[sec].\n",
            " 12%|█▏        | 176/1471 [00:19<02:27,  8.77it/s]2024-08-13 21:36:52,768 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:52,855 - INFO - joeynmt.prediction - Generation took 0.0848[sec].\n",
            "2024-08-13 21:36:52,858 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:52,930 - INFO - joeynmt.prediction - Generation took 0.0696[sec].\n",
            " 12%|█▏        | 178/1471 [00:19<02:14,  9.63it/s]2024-08-13 21:36:52,935 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:53,184 - INFO - joeynmt.prediction - Generation took 0.2457[sec].\n",
            "2024-08-13 21:36:53,187 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:53,254 - INFO - joeynmt.prediction - Generation took 0.0642[sec].\n",
            " 12%|█▏        | 180/1471 [00:19<02:38,  8.16it/s]2024-08-13 21:36:53,258 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:53,350 - INFO - joeynmt.prediction - Generation took 0.0886[sec].\n",
            "2024-08-13 21:36:53,352 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:53,463 - INFO - joeynmt.prediction - Generation took 0.1075[sec].\n",
            " 12%|█▏        | 182/1471 [00:20<02:30,  8.54it/s]2024-08-13 21:36:53,469 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:53,765 - INFO - joeynmt.prediction - Generation took 0.2917[sec].\n",
            " 12%|█▏        | 183/1471 [00:20<03:14,  6.63it/s]2024-08-13 21:36:53,770 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:53,897 - INFO - joeynmt.prediction - Generation took 0.1236[sec].\n",
            " 13%|█▎        | 184/1471 [00:20<03:09,  6.80it/s]2024-08-13 21:36:53,902 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:54,059 - INFO - joeynmt.prediction - Generation took 0.1547[sec].\n",
            " 13%|█▎        | 185/1471 [00:20<03:13,  6.65it/s]2024-08-13 21:36:54,063 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:54,210 - INFO - joeynmt.prediction - Generation took 0.1445[sec].\n",
            " 13%|█▎        | 186/1471 [00:20<03:13,  6.64it/s]2024-08-13 21:36:54,215 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:54,299 - INFO - joeynmt.prediction - Generation took 0.0812[sec].\n",
            "2024-08-13 21:36:54,301 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:54,371 - INFO - joeynmt.prediction - Generation took 0.0661[sec].\n",
            " 13%|█▎        | 188/1471 [00:20<02:35,  8.23it/s]2024-08-13 21:36:54,377 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:54,468 - INFO - joeynmt.prediction - Generation took 0.0884[sec].\n",
            "2024-08-13 21:36:54,470 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:54,551 - INFO - joeynmt.prediction - Generation took 0.0775[sec].\n",
            " 13%|█▎        | 190/1471 [00:21<02:20,  9.11it/s]2024-08-13 21:36:54,555 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:54,638 - INFO - joeynmt.prediction - Generation took 0.0800[sec].\n",
            "2024-08-13 21:36:54,640 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:54,727 - INFO - joeynmt.prediction - Generation took 0.0842[sec].\n",
            " 13%|█▎        | 192/1471 [00:21<02:10,  9.77it/s]2024-08-13 21:36:54,731 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:54,826 - INFO - joeynmt.prediction - Generation took 0.0922[sec].\n",
            "2024-08-13 21:36:54,828 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:55,004 - INFO - joeynmt.prediction - Generation took 0.1732[sec].\n",
            " 13%|█▎        | 194/1471 [00:21<02:26,  8.74it/s]2024-08-13 21:36:55,010 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:55,152 - INFO - joeynmt.prediction - Generation took 0.1390[sec].\n",
            " 13%|█▎        | 195/1471 [00:21<02:33,  8.29it/s]2024-08-13 21:36:55,157 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:55,327 - INFO - joeynmt.prediction - Generation took 0.1674[sec].\n",
            " 13%|█▎        | 196/1471 [00:21<02:48,  7.55it/s]2024-08-13 21:36:55,332 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:55,674 - INFO - joeynmt.prediction - Generation took 0.3388[sec].\n",
            " 13%|█▎        | 197/1471 [00:22<03:52,  5.48it/s]2024-08-13 21:36:55,678 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:55,857 - INFO - joeynmt.prediction - Generation took 0.1763[sec].\n",
            " 13%|█▎        | 198/1471 [00:22<03:52,  5.46it/s]2024-08-13 21:36:55,862 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:55,970 - INFO - joeynmt.prediction - Generation took 0.1056[sec].\n",
            " 14%|█▎        | 199/1471 [00:22<03:28,  6.09it/s]2024-08-13 21:36:55,974 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:56,107 - INFO - joeynmt.prediction - Generation took 0.1308[sec].\n",
            " 14%|█▎        | 200/1471 [00:22<03:19,  6.38it/s]2024-08-13 21:36:56,111 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:56,282 - INFO - joeynmt.prediction - Generation took 0.1688[sec].\n",
            " 14%|█▎        | 201/1471 [00:22<03:25,  6.18it/s]2024-08-13 21:36:56,287 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:56,344 - INFO - joeynmt.prediction - Generation took 0.0536[sec].\n",
            "2024-08-13 21:36:56,345 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:56,402 - INFO - joeynmt.prediction - Generation took 0.0538[sec].\n",
            " 14%|█▍        | 203/1471 [00:23<02:27,  8.58it/s]2024-08-13 21:36:56,406 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:56,509 - INFO - joeynmt.prediction - Generation took 0.1013[sec].\n",
            " 14%|█▍        | 204/1471 [00:23<02:25,  8.74it/s]2024-08-13 21:36:56,514 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:56,608 - INFO - joeynmt.prediction - Generation took 0.0919[sec].\n",
            "2024-08-13 21:36:56,611 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:56,668 - INFO - joeynmt.prediction - Generation took 0.0549[sec].\n",
            " 14%|█▍        | 206/1471 [00:23<02:06, 10.01it/s]2024-08-13 21:36:56,672 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:56,735 - INFO - joeynmt.prediction - Generation took 0.0604[sec].\n",
            "2024-08-13 21:36:56,737 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:56,793 - INFO - joeynmt.prediction - Generation took 0.0535[sec].\n",
            " 14%|█▍        | 208/1471 [00:23<01:48, 11.61it/s]2024-08-13 21:36:56,798 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:56,858 - INFO - joeynmt.prediction - Generation took 0.0571[sec].\n",
            "2024-08-13 21:36:56,860 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:56,918 - INFO - joeynmt.prediction - Generation took 0.0564[sec].\n",
            " 14%|█▍        | 210/1471 [00:23<01:38, 12.80it/s]2024-08-13 21:36:56,923 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:56,993 - INFO - joeynmt.prediction - Generation took 0.0666[sec].\n",
            "2024-08-13 21:36:56,995 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:57,262 - INFO - joeynmt.prediction - Generation took 0.2652[sec].\n",
            " 14%|█▍        | 212/1471 [00:23<02:17,  9.17it/s]2024-08-13 21:36:57,267 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:57,338 - INFO - joeynmt.prediction - Generation took 0.0679[sec].\n",
            "2024-08-13 21:36:57,340 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:57,394 - INFO - joeynmt.prediction - Generation took 0.0511[sec].\n",
            " 15%|█▍        | 214/1471 [00:24<01:59, 10.49it/s]2024-08-13 21:36:57,399 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:57,448 - INFO - joeynmt.prediction - Generation took 0.0468[sec].\n",
            "2024-08-13 21:36:57,450 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:57,615 - INFO - joeynmt.prediction - Generation took 0.1607[sec].\n",
            " 15%|█▍        | 216/1471 [00:24<02:05, 10.01it/s]2024-08-13 21:36:57,619 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:57,822 - INFO - joeynmt.prediction - Generation took 0.1993[sec].\n",
            "2024-08-13 21:36:57,824 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:57,940 - INFO - joeynmt.prediction - Generation took 0.1130[sec].\n",
            " 15%|█▍        | 218/1471 [00:24<02:29,  8.38it/s]2024-08-13 21:36:57,944 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:58,101 - INFO - joeynmt.prediction - Generation took 0.1548[sec].\n",
            " 15%|█▍        | 219/1471 [00:24<02:38,  7.87it/s]2024-08-13 21:36:58,105 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:58,249 - INFO - joeynmt.prediction - Generation took 0.1415[sec].\n",
            " 15%|█▍        | 220/1471 [00:24<02:44,  7.62it/s]2024-08-13 21:36:58,254 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:58,589 - INFO - joeynmt.prediction - Generation took 0.3324[sec].\n",
            " 15%|█▌        | 221/1471 [00:25<03:43,  5.60it/s]2024-08-13 21:36:58,595 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:58,682 - INFO - joeynmt.prediction - Generation took 0.0840[sec].\n",
            "2024-08-13 21:36:58,684 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:58,826 - INFO - joeynmt.prediction - Generation took 0.1394[sec].\n",
            " 15%|█▌        | 223/1471 [00:25<03:13,  6.44it/s]2024-08-13 21:36:58,833 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:59,201 - INFO - joeynmt.prediction - Generation took 0.3657[sec].\n",
            " 15%|█▌        | 224/1471 [00:25<04:13,  4.92it/s]2024-08-13 21:36:59,205 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:59,318 - INFO - joeynmt.prediction - Generation took 0.1110[sec].\n",
            " 15%|█▌        | 225/1471 [00:25<03:47,  5.47it/s]2024-08-13 21:36:59,323 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:59,421 - INFO - joeynmt.prediction - Generation took 0.0956[sec].\n",
            " 15%|█▌        | 226/1471 [00:26<03:22,  6.16it/s]2024-08-13 21:36:59,425 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:59,664 - INFO - joeynmt.prediction - Generation took 0.2362[sec].\n",
            " 15%|█▌        | 227/1471 [00:26<03:48,  5.44it/s]2024-08-13 21:36:59,668 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:59,819 - INFO - joeynmt.prediction - Generation took 0.1483[sec].\n",
            " 15%|█▌        | 228/1471 [00:26<03:38,  5.68it/s]2024-08-13 21:36:59,823 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:59,917 - INFO - joeynmt.prediction - Generation took 0.0917[sec].\n",
            "2024-08-13 21:36:59,920 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:36:59,972 - INFO - joeynmt.prediction - Generation took 0.0501[sec].\n",
            " 16%|█▌        | 230/1471 [00:26<02:43,  7.57it/s]2024-08-13 21:36:59,977 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:00,092 - INFO - joeynmt.prediction - Generation took 0.1125[sec].\n",
            " 16%|█▌        | 231/1471 [00:26<02:41,  7.68it/s]2024-08-13 21:37:00,100 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:00,178 - INFO - joeynmt.prediction - Generation took 0.0743[sec].\n",
            "2024-08-13 21:37:00,181 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:00,309 - INFO - joeynmt.prediction - Generation took 0.1257[sec].\n",
            " 16%|█▌        | 233/1471 [00:26<02:28,  8.31it/s]2024-08-13 21:37:00,311 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:00,469 - INFO - joeynmt.prediction - Generation took 0.1524[sec].\n",
            " 16%|█▌        | 234/1471 [00:27<02:40,  7.72it/s]2024-08-13 21:37:00,474 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:00,729 - INFO - joeynmt.prediction - Generation took 0.2527[sec].\n",
            " 16%|█▌        | 235/1471 [00:27<03:19,  6.20it/s]2024-08-13 21:37:00,733 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:00,861 - INFO - joeynmt.prediction - Generation took 0.1253[sec].\n",
            " 16%|█▌        | 236/1471 [00:27<03:10,  6.50it/s]2024-08-13 21:37:00,866 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:01,073 - INFO - joeynmt.prediction - Generation took 0.2055[sec].\n",
            " 16%|█▌        | 237/1471 [00:27<03:28,  5.91it/s]2024-08-13 21:37:01,077 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:01,213 - INFO - joeynmt.prediction - Generation took 0.1319[sec].\n",
            " 16%|█▌        | 238/1471 [00:27<03:18,  6.20it/s]2024-08-13 21:37:01,217 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:01,384 - INFO - joeynmt.prediction - Generation took 0.1636[sec].\n",
            " 16%|█▌        | 239/1471 [00:28<03:21,  6.11it/s]2024-08-13 21:37:01,388 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:01,474 - INFO - joeynmt.prediction - Generation took 0.0844[sec].\n",
            "2024-08-13 21:37:01,477 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:01,613 - INFO - joeynmt.prediction - Generation took 0.1338[sec].\n",
            " 16%|█▋        | 241/1471 [00:28<02:54,  7.05it/s]2024-08-13 21:37:01,617 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:01,750 - INFO - joeynmt.prediction - Generation took 0.1308[sec].\n",
            " 16%|█▋        | 242/1471 [00:28<02:52,  7.11it/s]2024-08-13 21:37:01,755 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:01,921 - INFO - joeynmt.prediction - Generation took 0.1636[sec].\n",
            " 17%|█▋        | 243/1471 [00:28<03:03,  6.70it/s]2024-08-13 21:37:01,929 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:02,148 - INFO - joeynmt.prediction - Generation took 0.2145[sec].\n",
            " 17%|█▋        | 244/1471 [00:28<03:27,  5.91it/s]2024-08-13 21:37:02,153 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:02,294 - INFO - joeynmt.prediction - Generation took 0.1384[sec].\n",
            " 17%|█▋        | 245/1471 [00:28<03:19,  6.14it/s]2024-08-13 21:37:02,298 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:02,458 - INFO - joeynmt.prediction - Generation took 0.1569[sec].\n",
            " 17%|█▋        | 246/1471 [00:29<03:19,  6.14it/s]2024-08-13 21:37:02,466 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:02,617 - INFO - joeynmt.prediction - Generation took 0.1473[sec].\n",
            " 17%|█▋        | 247/1471 [00:29<03:18,  6.16it/s]2024-08-13 21:37:02,621 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:02,796 - INFO - joeynmt.prediction - Generation took 0.1724[sec].\n",
            " 17%|█▋        | 248/1471 [00:29<03:24,  5.98it/s]2024-08-13 21:37:02,802 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:02,877 - INFO - joeynmt.prediction - Generation took 0.0718[sec].\n",
            "2024-08-13 21:37:02,879 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:02,940 - INFO - joeynmt.prediction - Generation took 0.0576[sec].\n",
            " 17%|█▋        | 250/1471 [00:29<02:31,  8.08it/s]2024-08-13 21:37:02,944 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:03,031 - INFO - joeynmt.prediction - Generation took 0.0843[sec].\n",
            "2024-08-13 21:37:03,033 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:03,348 - INFO - joeynmt.prediction - Generation took 0.3126[sec].\n",
            " 17%|█▋        | 252/1471 [00:29<03:09,  6.44it/s]2024-08-13 21:37:03,354 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:03,475 - INFO - joeynmt.prediction - Generation took 0.1174[sec].\n",
            " 17%|█▋        | 253/1471 [00:30<03:01,  6.70it/s]2024-08-13 21:37:03,481 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:03,706 - INFO - joeynmt.prediction - Generation took 0.2223[sec].\n",
            " 17%|█▋        | 254/1471 [00:30<03:25,  5.93it/s]2024-08-13 21:37:03,710 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:03,766 - INFO - joeynmt.prediction - Generation took 0.0534[sec].\n",
            "2024-08-13 21:37:03,767 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:03,864 - INFO - joeynmt.prediction - Generation took 0.0931[sec].\n",
            " 17%|█▋        | 256/1471 [00:30<02:40,  7.56it/s]2024-08-13 21:37:03,869 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:03,933 - INFO - joeynmt.prediction - Generation took 0.0623[sec].\n",
            "2024-08-13 21:37:03,934 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:04,172 - INFO - joeynmt.prediction - Generation took 0.2341[sec].\n",
            " 18%|█▊        | 258/1471 [00:30<02:50,  7.10it/s]2024-08-13 21:37:04,179 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:04,266 - INFO - joeynmt.prediction - Generation took 0.0836[sec].\n",
            "2024-08-13 21:37:04,269 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:04,356 - INFO - joeynmt.prediction - Generation took 0.0847[sec].\n",
            " 18%|█▊        | 260/1471 [00:30<02:29,  8.10it/s]2024-08-13 21:37:04,360 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:04,458 - INFO - joeynmt.prediction - Generation took 0.0962[sec].\n",
            " 18%|█▊        | 261/1471 [00:31<02:24,  8.38it/s]2024-08-13 21:37:04,462 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:04,660 - INFO - joeynmt.prediction - Generation took 0.1958[sec].\n",
            " 18%|█▊        | 262/1471 [00:31<02:46,  7.27it/s]2024-08-13 21:37:04,664 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:04,746 - INFO - joeynmt.prediction - Generation took 0.0796[sec].\n",
            "2024-08-13 21:37:04,749 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:04,933 - INFO - joeynmt.prediction - Generation took 0.1809[sec].\n",
            " 18%|█▊        | 264/1471 [00:31<02:45,  7.29it/s]2024-08-13 21:37:04,937 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:05,119 - INFO - joeynmt.prediction - Generation took 0.1793[sec].\n",
            " 18%|█▊        | 265/1471 [00:31<02:57,  6.78it/s]2024-08-13 21:37:05,124 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:05,228 - INFO - joeynmt.prediction - Generation took 0.1013[sec].\n",
            " 18%|█▊        | 266/1471 [00:31<02:46,  7.22it/s]2024-08-13 21:37:05,233 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:05,880 - INFO - joeynmt.prediction - Generation took 0.6439[sec].\n",
            " 18%|█▊        | 267/1471 [00:32<05:22,  3.73it/s]2024-08-13 21:37:05,886 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:06,031 - INFO - joeynmt.prediction - Generation took 0.1423[sec].\n",
            " 18%|█▊        | 268/1471 [00:32<04:45,  4.22it/s]2024-08-13 21:37:06,036 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:06,245 - INFO - joeynmt.prediction - Generation took 0.2060[sec].\n",
            " 18%|█▊        | 269/1471 [00:32<04:37,  4.33it/s]2024-08-13 21:37:06,250 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:06,327 - INFO - joeynmt.prediction - Generation took 0.0740[sec].\n",
            "2024-08-13 21:37:06,329 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:06,434 - INFO - joeynmt.prediction - Generation took 0.1021[sec].\n",
            " 18%|█▊        | 271/1471 [00:33<03:24,  5.86it/s]2024-08-13 21:37:06,438 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:06,522 - INFO - joeynmt.prediction - Generation took 0.0807[sec].\n",
            "2024-08-13 21:37:06,524 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:06,625 - INFO - joeynmt.prediction - Generation took 0.0984[sec].\n",
            " 19%|█▊        | 273/1471 [00:33<02:49,  7.06it/s]2024-08-13 21:37:06,629 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:06,707 - INFO - joeynmt.prediction - Generation took 0.0726[sec].\n",
            "2024-08-13 21:37:06,709 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:06,881 - INFO - joeynmt.prediction - Generation took 0.1696[sec].\n",
            " 19%|█▊        | 275/1471 [00:33<02:43,  7.30it/s]2024-08-13 21:37:06,885 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:06,995 - INFO - joeynmt.prediction - Generation took 0.1077[sec].\n",
            " 19%|█▉        | 276/1471 [00:33<02:38,  7.56it/s]2024-08-13 21:37:06,999 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:07,187 - INFO - joeynmt.prediction - Generation took 0.1843[sec].\n",
            " 19%|█▉        | 277/1471 [00:33<02:53,  6.87it/s]2024-08-13 21:37:07,191 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:07,492 - INFO - joeynmt.prediction - Generation took 0.2982[sec].\n",
            " 19%|█▉        | 278/1471 [00:34<03:40,  5.42it/s]2024-08-13 21:37:07,497 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:07,661 - INFO - joeynmt.prediction - Generation took 0.1603[sec].\n",
            " 19%|█▉        | 279/1471 [00:34<03:34,  5.55it/s]2024-08-13 21:37:07,665 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:07,800 - INFO - joeynmt.prediction - Generation took 0.1319[sec].\n",
            " 19%|█▉        | 280/1471 [00:34<03:21,  5.92it/s]2024-08-13 21:37:07,804 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:07,902 - INFO - joeynmt.prediction - Generation took 0.0941[sec].\n",
            " 19%|█▉        | 281/1471 [00:34<02:59,  6.63it/s]2024-08-13 21:37:07,906 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:07,969 - INFO - joeynmt.prediction - Generation took 0.0603[sec].\n",
            "2024-08-13 21:37:07,971 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:08,109 - INFO - joeynmt.prediction - Generation took 0.1350[sec].\n",
            " 19%|█▉        | 283/1471 [00:34<02:34,  7.71it/s]2024-08-13 21:37:08,114 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:08,181 - INFO - joeynmt.prediction - Generation took 0.0641[sec].\n",
            "2024-08-13 21:37:08,184 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:08,250 - INFO - joeynmt.prediction - Generation took 0.0635[sec].\n",
            " 19%|█▉        | 285/1471 [00:34<02:06,  9.35it/s]2024-08-13 21:37:08,254 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:08,326 - INFO - joeynmt.prediction - Generation took 0.0697[sec].\n",
            "2024-08-13 21:37:08,327 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:08,426 - INFO - joeynmt.prediction - Generation took 0.0941[sec].\n",
            " 20%|█▉        | 287/1471 [00:35<01:58, 10.00it/s]2024-08-13 21:37:08,430 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:08,626 - INFO - joeynmt.prediction - Generation took 0.1937[sec].\n",
            "2024-08-13 21:37:08,628 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:08,773 - INFO - joeynmt.prediction - Generation took 0.1424[sec].\n",
            " 20%|█▉        | 289/1471 [00:35<02:27,  8.02it/s]2024-08-13 21:37:08,777 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:08,857 - INFO - joeynmt.prediction - Generation took 0.0765[sec].\n",
            "2024-08-13 21:37:08,859 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:08,970 - INFO - joeynmt.prediction - Generation took 0.1094[sec].\n",
            " 20%|█▉        | 291/1471 [00:35<02:17,  8.60it/s]2024-08-13 21:37:08,977 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:09,321 - INFO - joeynmt.prediction - Generation took 0.3417[sec].\n",
            " 20%|█▉        | 292/1471 [00:35<03:09,  6.23it/s]2024-08-13 21:37:09,325 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:09,409 - INFO - joeynmt.prediction - Generation took 0.0816[sec].\n",
            "2024-08-13 21:37:09,413 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:09,470 - INFO - joeynmt.prediction - Generation took 0.0543[sec].\n",
            " 20%|█▉        | 294/1471 [00:36<02:33,  7.67it/s]2024-08-13 21:37:09,476 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:09,558 - INFO - joeynmt.prediction - Generation took 0.0789[sec].\n",
            "2024-08-13 21:37:09,560 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:09,721 - INFO - joeynmt.prediction - Generation took 0.1582[sec].\n",
            " 20%|██        | 296/1471 [00:36<02:31,  7.76it/s]2024-08-13 21:37:09,725 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:09,785 - INFO - joeynmt.prediction - Generation took 0.0573[sec].\n",
            "2024-08-13 21:37:09,787 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:09,844 - INFO - joeynmt.prediction - Generation took 0.0545[sec].\n",
            " 20%|██        | 298/1471 [00:36<02:05,  9.35it/s]2024-08-13 21:37:09,847 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:09,912 - INFO - joeynmt.prediction - Generation took 0.0622[sec].\n",
            "2024-08-13 21:37:09,913 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:09,975 - INFO - joeynmt.prediction - Generation took 0.0579[sec].\n",
            " 20%|██        | 300/1471 [00:36<01:49, 10.65it/s]2024-08-13 21:37:09,981 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:10,115 - INFO - joeynmt.prediction - Generation took 0.1298[sec].\n",
            "2024-08-13 21:37:10,118 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:10,178 - INFO - joeynmt.prediction - Generation took 0.0568[sec].\n",
            " 21%|██        | 302/1471 [00:36<01:52, 10.38it/s]2024-08-13 21:37:10,182 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:10,275 - INFO - joeynmt.prediction - Generation took 0.0909[sec].\n",
            "2024-08-13 21:37:10,277 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:10,463 - INFO - joeynmt.prediction - Generation took 0.1816[sec].\n",
            " 21%|██        | 304/1471 [00:37<02:08,  9.05it/s]2024-08-13 21:37:10,468 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:10,648 - INFO - joeynmt.prediction - Generation took 0.1763[sec].\n",
            "2024-08-13 21:37:10,650 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:10,706 - INFO - joeynmt.prediction - Generation took 0.0537[sec].\n",
            " 21%|██        | 306/1471 [00:37<02:12,  8.79it/s]2024-08-13 21:37:10,710 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:10,787 - INFO - joeynmt.prediction - Generation took 0.0741[sec].\n",
            "2024-08-13 21:37:10,788 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:10,851 - INFO - joeynmt.prediction - Generation took 0.0582[sec].\n",
            " 21%|██        | 308/1471 [00:37<01:58,  9.86it/s]2024-08-13 21:37:10,856 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:10,934 - INFO - joeynmt.prediction - Generation took 0.0748[sec].\n",
            "2024-08-13 21:37:10,936 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:11,096 - INFO - joeynmt.prediction - Generation took 0.1581[sec].\n",
            " 21%|██        | 310/1471 [00:37<02:05,  9.28it/s]2024-08-13 21:37:11,100 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:11,190 - INFO - joeynmt.prediction - Generation took 0.0875[sec].\n",
            "2024-08-13 21:37:11,193 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:11,436 - INFO - joeynmt.prediction - Generation took 0.2408[sec].\n",
            " 21%|██        | 312/1471 [00:38<02:26,  7.90it/s]2024-08-13 21:37:11,441 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:11,512 - INFO - joeynmt.prediction - Generation took 0.0687[sec].\n",
            "2024-08-13 21:37:11,514 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:11,713 - INFO - joeynmt.prediction - Generation took 0.1963[sec].\n",
            " 21%|██▏       | 314/1471 [00:38<02:30,  7.68it/s]2024-08-13 21:37:11,718 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:11,831 - INFO - joeynmt.prediction - Generation took 0.1098[sec].\n",
            " 21%|██▏       | 315/1471 [00:38<02:27,  7.82it/s]2024-08-13 21:37:11,836 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:11,908 - INFO - joeynmt.prediction - Generation took 0.0689[sec].\n",
            "2024-08-13 21:37:11,911 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:11,973 - INFO - joeynmt.prediction - Generation took 0.0594[sec].\n",
            " 22%|██▏       | 317/1471 [00:38<02:05,  9.19it/s]2024-08-13 21:37:11,979 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:12,087 - INFO - joeynmt.prediction - Generation took 0.1043[sec].\n",
            "2024-08-13 21:37:12,090 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:12,142 - INFO - joeynmt.prediction - Generation took 0.0495[sec].\n",
            " 22%|██▏       | 319/1471 [00:38<01:56,  9.91it/s]2024-08-13 21:37:12,146 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:12,214 - INFO - joeynmt.prediction - Generation took 0.0655[sec].\n",
            "2024-08-13 21:37:12,216 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:12,318 - INFO - joeynmt.prediction - Generation took 0.0984[sec].\n",
            " 22%|██▏       | 321/1471 [00:38<01:51, 10.34it/s]2024-08-13 21:37:12,322 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:12,462 - INFO - joeynmt.prediction - Generation took 0.1384[sec].\n",
            "2024-08-13 21:37:12,465 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:12,557 - INFO - joeynmt.prediction - Generation took 0.0899[sec].\n",
            " 22%|██▏       | 323/1471 [00:39<01:59,  9.62it/s]2024-08-13 21:37:12,561 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:12,786 - INFO - joeynmt.prediction - Generation took 0.2216[sec].\n",
            "2024-08-13 21:37:12,789 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:12,862 - INFO - joeynmt.prediction - Generation took 0.0706[sec].\n",
            " 22%|██▏       | 325/1471 [00:39<02:16,  8.41it/s]2024-08-13 21:37:12,867 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:13,039 - INFO - joeynmt.prediction - Generation took 0.1694[sec].\n",
            " 22%|██▏       | 326/1471 [00:39<02:28,  7.73it/s]2024-08-13 21:37:13,043 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:13,092 - INFO - joeynmt.prediction - Generation took 0.0468[sec].\n",
            "2024-08-13 21:37:13,095 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:13,206 - INFO - joeynmt.prediction - Generation took 0.1082[sec].\n",
            " 22%|██▏       | 328/1471 [00:39<02:09,  8.81it/s]2024-08-13 21:37:13,210 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:13,483 - INFO - joeynmt.prediction - Generation took 0.2702[sec].\n",
            " 22%|██▏       | 329/1471 [00:40<02:46,  6.86it/s]2024-08-13 21:37:13,488 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:13,594 - INFO - joeynmt.prediction - Generation took 0.1034[sec].\n",
            " 22%|██▏       | 330/1471 [00:40<02:37,  7.25it/s]2024-08-13 21:37:13,597 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:13,662 - INFO - joeynmt.prediction - Generation took 0.0625[sec].\n",
            "2024-08-13 21:37:13,664 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:13,754 - INFO - joeynmt.prediction - Generation took 0.0875[sec].\n",
            " 23%|██▎       | 332/1471 [00:40<02:11,  8.65it/s]2024-08-13 21:37:13,758 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:13,964 - INFO - joeynmt.prediction - Generation took 0.2040[sec].\n",
            " 23%|██▎       | 333/1471 [00:40<02:35,  7.34it/s]2024-08-13 21:37:13,968 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:14,288 - INFO - joeynmt.prediction - Generation took 0.3170[sec].\n",
            " 23%|██▎       | 334/1471 [00:40<03:24,  5.55it/s]2024-08-13 21:37:14,292 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:14,499 - INFO - joeynmt.prediction - Generation took 0.2028[sec].\n",
            " 23%|██▎       | 335/1471 [00:41<03:33,  5.32it/s]2024-08-13 21:37:14,503 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:14,697 - INFO - joeynmt.prediction - Generation took 0.1896[sec].\n",
            " 23%|██▎       | 336/1471 [00:41<03:36,  5.24it/s]2024-08-13 21:37:14,702 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:14,881 - INFO - joeynmt.prediction - Generation took 0.1768[sec].\n",
            " 23%|██▎       | 337/1471 [00:41<03:34,  5.29it/s]2024-08-13 21:37:14,887 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:15,027 - INFO - joeynmt.prediction - Generation took 0.1381[sec].\n",
            " 23%|██▎       | 338/1471 [00:41<03:20,  5.66it/s]2024-08-13 21:37:15,032 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:15,202 - INFO - joeynmt.prediction - Generation took 0.1664[sec].\n",
            " 23%|██▎       | 339/1471 [00:41<03:19,  5.68it/s]2024-08-13 21:37:15,208 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:15,279 - INFO - joeynmt.prediction - Generation took 0.0677[sec].\n",
            "2024-08-13 21:37:15,280 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:15,467 - INFO - joeynmt.prediction - Generation took 0.1841[sec].\n",
            " 23%|██▎       | 341/1471 [00:42<02:57,  6.38it/s]2024-08-13 21:37:15,473 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:15,652 - INFO - joeynmt.prediction - Generation took 0.1777[sec].\n",
            " 23%|██▎       | 342/1471 [00:42<03:04,  6.12it/s]2024-08-13 21:37:15,657 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:15,711 - INFO - joeynmt.prediction - Generation took 0.0517[sec].\n",
            "2024-08-13 21:37:15,713 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:15,865 - INFO - joeynmt.prediction - Generation took 0.1483[sec].\n",
            " 23%|██▎       | 344/1471 [00:42<02:37,  7.14it/s]2024-08-13 21:37:15,869 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:16,450 - INFO - joeynmt.prediction - Generation took 0.5787[sec].\n",
            " 23%|██▎       | 345/1471 [00:43<04:31,  4.15it/s]2024-08-13 21:37:16,456 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:16,537 - INFO - joeynmt.prediction - Generation took 0.0778[sec].\n",
            "2024-08-13 21:37:16,541 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:16,590 - INFO - joeynmt.prediction - Generation took 0.0473[sec].\n",
            " 24%|██▎       | 347/1471 [00:43<03:15,  5.76it/s]2024-08-13 21:37:16,595 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:16,718 - INFO - joeynmt.prediction - Generation took 0.1200[sec].\n",
            " 24%|██▎       | 348/1471 [00:43<03:03,  6.12it/s]2024-08-13 21:37:16,721 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:16,811 - INFO - joeynmt.prediction - Generation took 0.0871[sec].\n",
            "2024-08-13 21:37:16,813 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:16,964 - INFO - joeynmt.prediction - Generation took 0.1483[sec].\n",
            " 24%|██▍       | 350/1471 [00:43<02:45,  6.76it/s]2024-08-13 21:37:16,968 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:17,094 - INFO - joeynmt.prediction - Generation took 0.1239[sec].\n",
            " 24%|██▍       | 351/1471 [00:43<02:41,  6.94it/s]2024-08-13 21:37:17,099 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:17,287 - INFO - joeynmt.prediction - Generation took 0.1852[sec].\n",
            " 24%|██▍       | 352/1471 [00:43<02:54,  6.42it/s]2024-08-13 21:37:17,293 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:17,496 - INFO - joeynmt.prediction - Generation took 0.1988[sec].\n",
            " 24%|██▍       | 353/1471 [00:44<03:08,  5.92it/s]2024-08-13 21:37:17,501 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:17,687 - INFO - joeynmt.prediction - Generation took 0.1832[sec].\n",
            " 24%|██▍       | 354/1471 [00:44<03:15,  5.71it/s]2024-08-13 21:37:17,691 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:17,795 - INFO - joeynmt.prediction - Generation took 0.1007[sec].\n",
            " 24%|██▍       | 355/1471 [00:44<02:54,  6.39it/s]2024-08-13 21:37:17,799 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:18,295 - INFO - joeynmt.prediction - Generation took 0.4934[sec].\n",
            " 24%|██▍       | 356/1471 [00:44<04:43,  3.93it/s]2024-08-13 21:37:18,302 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:18,519 - INFO - joeynmt.prediction - Generation took 0.2152[sec].\n",
            " 24%|██▍       | 357/1471 [00:45<04:32,  4.09it/s]2024-08-13 21:37:18,524 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:18,604 - INFO - joeynmt.prediction - Generation took 0.0783[sec].\n",
            "2024-08-13 21:37:18,607 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:18,691 - INFO - joeynmt.prediction - Generation took 0.0825[sec].\n",
            " 24%|██▍       | 359/1471 [00:45<03:12,  5.78it/s]2024-08-13 21:37:18,695 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:18,874 - INFO - joeynmt.prediction - Generation took 0.1764[sec].\n",
            " 24%|██▍       | 360/1471 [00:45<03:15,  5.68it/s]2024-08-13 21:37:18,881 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:19,086 - INFO - joeynmt.prediction - Generation took 0.2032[sec].\n",
            " 25%|██▍       | 361/1471 [00:45<03:25,  5.41it/s]2024-08-13 21:37:19,092 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:19,222 - INFO - joeynmt.prediction - Generation took 0.1266[sec].\n",
            " 25%|██▍       | 362/1471 [00:45<03:10,  5.83it/s]2024-08-13 21:37:19,227 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:19,580 - INFO - joeynmt.prediction - Generation took 0.3508[sec].\n",
            " 25%|██▍       | 363/1471 [00:46<04:07,  4.47it/s]2024-08-13 21:37:19,586 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:19,819 - INFO - joeynmt.prediction - Generation took 0.2290[sec].\n",
            " 25%|██▍       | 364/1471 [00:46<04:12,  4.39it/s]2024-08-13 21:37:19,826 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:19,998 - INFO - joeynmt.prediction - Generation took 0.1697[sec].\n",
            " 25%|██▍       | 365/1471 [00:46<03:56,  4.67it/s]2024-08-13 21:37:20,005 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:20,202 - INFO - joeynmt.prediction - Generation took 0.1951[sec].\n",
            " 25%|██▍       | 366/1471 [00:46<03:52,  4.75it/s]2024-08-13 21:37:20,207 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:20,386 - INFO - joeynmt.prediction - Generation took 0.1769[sec].\n",
            " 25%|██▍       | 367/1471 [00:47<03:43,  4.93it/s]2024-08-13 21:37:20,390 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:20,741 - INFO - joeynmt.prediction - Generation took 0.3473[sec].\n",
            " 25%|██▌       | 368/1471 [00:47<04:33,  4.04it/s]2024-08-13 21:37:20,745 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:20,835 - INFO - joeynmt.prediction - Generation took 0.0866[sec].\n",
            "2024-08-13 21:37:20,837 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:20,969 - INFO - joeynmt.prediction - Generation took 0.1300[sec].\n",
            " 25%|██▌       | 370/1471 [00:47<03:25,  5.37it/s]2024-08-13 21:37:20,974 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:21,171 - INFO - joeynmt.prediction - Generation took 0.1947[sec].\n",
            " 25%|██▌       | 371/1471 [00:47<03:29,  5.25it/s]2024-08-13 21:37:21,175 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:21,241 - INFO - joeynmt.prediction - Generation took 0.0636[sec].\n",
            "2024-08-13 21:37:21,243 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:21,301 - INFO - joeynmt.prediction - Generation took 0.0551[sec].\n",
            " 25%|██▌       | 373/1471 [00:47<02:32,  7.21it/s]2024-08-13 21:37:21,307 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:21,366 - INFO - joeynmt.prediction - Generation took 0.0559[sec].\n",
            "2024-08-13 21:37:21,368 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:21,558 - INFO - joeynmt.prediction - Generation took 0.1872[sec].\n",
            " 25%|██▌       | 375/1471 [00:48<02:27,  7.42it/s]2024-08-13 21:37:21,562 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:21,717 - INFO - joeynmt.prediction - Generation took 0.1524[sec].\n",
            " 26%|██▌       | 376/1471 [00:48<02:33,  7.16it/s]2024-08-13 21:37:21,721 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:21,863 - INFO - joeynmt.prediction - Generation took 0.1397[sec].\n",
            " 26%|██▌       | 377/1471 [00:48<02:34,  7.07it/s]2024-08-13 21:37:21,869 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:21,944 - INFO - joeynmt.prediction - Generation took 0.0727[sec].\n",
            "2024-08-13 21:37:21,947 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:22,024 - INFO - joeynmt.prediction - Generation took 0.0744[sec].\n",
            " 26%|██▌       | 379/1471 [00:48<02:07,  8.54it/s]2024-08-13 21:37:22,029 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:22,095 - INFO - joeynmt.prediction - Generation took 0.0640[sec].\n",
            "2024-08-13 21:37:22,098 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:22,152 - INFO - joeynmt.prediction - Generation took 0.0527[sec].\n",
            " 26%|██▌       | 381/1471 [00:48<01:46, 10.20it/s]2024-08-13 21:37:22,157 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:22,209 - INFO - joeynmt.prediction - Generation took 0.0505[sec].\n",
            "2024-08-13 21:37:22,212 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:22,274 - INFO - joeynmt.prediction - Generation took 0.0590[sec].\n",
            " 26%|██▌       | 383/1471 [00:48<01:32, 11.71it/s]2024-08-13 21:37:22,279 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:22,445 - INFO - joeynmt.prediction - Generation took 0.1626[sec].\n",
            "2024-08-13 21:37:22,447 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:22,542 - INFO - joeynmt.prediction - Generation took 0.0900[sec].\n",
            " 26%|██▌       | 385/1471 [00:49<01:49,  9.88it/s]2024-08-13 21:37:22,546 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:22,612 - INFO - joeynmt.prediction - Generation took 0.0639[sec].\n",
            "2024-08-13 21:37:22,615 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:22,704 - INFO - joeynmt.prediction - Generation took 0.0867[sec].\n",
            " 26%|██▋       | 387/1471 [00:49<01:42, 10.56it/s]2024-08-13 21:37:22,708 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:22,784 - INFO - joeynmt.prediction - Generation took 0.0735[sec].\n",
            "2024-08-13 21:37:22,786 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:22,848 - INFO - joeynmt.prediction - Generation took 0.0585[sec].\n",
            " 26%|██▋       | 389/1471 [00:49<01:34, 11.43it/s]2024-08-13 21:37:22,851 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:23,029 - INFO - joeynmt.prediction - Generation took 0.1753[sec].\n",
            "2024-08-13 21:37:23,031 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:23,184 - INFO - joeynmt.prediction - Generation took 0.1504[sec].\n",
            " 27%|██▋       | 391/1471 [00:49<02:01,  8.89it/s]2024-08-13 21:37:23,188 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:23,289 - INFO - joeynmt.prediction - Generation took 0.0987[sec].\n",
            "2024-08-13 21:37:23,291 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:23,436 - INFO - joeynmt.prediction - Generation took 0.1427[sec].\n",
            " 27%|██▋       | 393/1471 [00:50<02:05,  8.58it/s]2024-08-13 21:37:23,440 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:23,509 - INFO - joeynmt.prediction - Generation took 0.0666[sec].\n",
            "2024-08-13 21:37:23,512 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:23,593 - INFO - joeynmt.prediction - Generation took 0.0776[sec].\n",
            " 27%|██▋       | 395/1471 [00:50<01:52,  9.53it/s]2024-08-13 21:37:23,597 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:23,748 - INFO - joeynmt.prediction - Generation took 0.1473[sec].\n",
            "2024-08-13 21:37:23,750 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:24,082 - INFO - joeynmt.prediction - Generation took 0.3295[sec].\n",
            " 27%|██▋       | 397/1471 [00:50<02:38,  6.79it/s]2024-08-13 21:37:24,089 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:24,180 - INFO - joeynmt.prediction - Generation took 0.0884[sec].\n",
            "2024-08-13 21:37:24,182 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:24,237 - INFO - joeynmt.prediction - Generation took 0.0518[sec].\n",
            " 27%|██▋       | 399/1471 [00:50<02:15,  7.92it/s]2024-08-13 21:37:24,241 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:24,297 - INFO - joeynmt.prediction - Generation took 0.0542[sec].\n",
            "2024-08-13 21:37:24,300 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:24,431 - INFO - joeynmt.prediction - Generation took 0.1295[sec].\n",
            " 27%|██▋       | 401/1471 [00:51<02:05,  8.51it/s]2024-08-13 21:37:24,435 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:24,567 - INFO - joeynmt.prediction - Generation took 0.1287[sec].\n",
            "2024-08-13 21:37:24,569 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:24,779 - INFO - joeynmt.prediction - Generation took 0.2079[sec].\n",
            " 27%|██▋       | 403/1471 [00:51<02:23,  7.44it/s]2024-08-13 21:37:24,783 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:24,835 - INFO - joeynmt.prediction - Generation took 0.0495[sec].\n",
            "2024-08-13 21:37:24,837 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:24,938 - INFO - joeynmt.prediction - Generation took 0.0971[sec].\n",
            " 28%|██▊       | 405/1471 [00:51<02:05,  8.49it/s]2024-08-13 21:37:24,942 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:25,095 - INFO - joeynmt.prediction - Generation took 0.1504[sec].\n",
            " 28%|██▊       | 406/1471 [00:51<02:12,  8.01it/s]2024-08-13 21:37:25,100 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:25,274 - INFO - joeynmt.prediction - Generation took 0.1710[sec].\n",
            " 28%|██▊       | 407/1471 [00:51<02:24,  7.34it/s]2024-08-13 21:37:25,280 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:25,449 - INFO - joeynmt.prediction - Generation took 0.1662[sec].\n",
            " 28%|██▊       | 408/1471 [00:52<02:33,  6.93it/s]2024-08-13 21:37:25,453 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:25,625 - INFO - joeynmt.prediction - Generation took 0.1697[sec].\n",
            " 28%|██▊       | 409/1471 [00:52<02:41,  6.58it/s]2024-08-13 21:37:25,629 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:25,748 - INFO - joeynmt.prediction - Generation took 0.1141[sec].\n",
            " 28%|██▊       | 410/1471 [00:52<02:33,  6.91it/s]2024-08-13 21:37:25,753 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:25,882 - INFO - joeynmt.prediction - Generation took 0.1266[sec].\n",
            " 28%|██▊       | 411/1471 [00:52<02:30,  7.05it/s]2024-08-13 21:37:25,886 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:26,146 - INFO - joeynmt.prediction - Generation took 0.2581[sec].\n",
            " 28%|██▊       | 412/1471 [00:52<03:05,  5.69it/s]2024-08-13 21:37:26,151 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:26,291 - INFO - joeynmt.prediction - Generation took 0.1371[sec].\n",
            " 28%|██▊       | 413/1471 [00:52<02:56,  5.99it/s]2024-08-13 21:37:26,295 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:26,382 - INFO - joeynmt.prediction - Generation took 0.0843[sec].\n",
            "2024-08-13 21:37:26,384 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:26,429 - INFO - joeynmt.prediction - Generation took 0.0421[sec].\n",
            " 28%|██▊       | 415/1471 [00:53<02:10,  8.12it/s]2024-08-13 21:37:26,433 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:26,509 - INFO - joeynmt.prediction - Generation took 0.0726[sec].\n",
            "2024-08-13 21:37:26,512 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:26,726 - INFO - joeynmt.prediction - Generation took 0.2092[sec].\n",
            " 28%|██▊       | 417/1471 [00:53<02:20,  7.52it/s]2024-08-13 21:37:26,730 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:26,897 - INFO - joeynmt.prediction - Generation took 0.1650[sec].\n",
            " 28%|██▊       | 418/1471 [00:53<02:28,  7.07it/s]2024-08-13 21:37:26,901 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:26,995 - INFO - joeynmt.prediction - Generation took 0.0917[sec].\n",
            "2024-08-13 21:37:26,998 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:27,064 - INFO - joeynmt.prediction - Generation took 0.0624[sec].\n",
            " 29%|██▊       | 420/1471 [00:53<02:05,  8.39it/s]2024-08-13 21:37:27,069 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:27,210 - INFO - joeynmt.prediction - Generation took 0.1384[sec].\n",
            " 29%|██▊       | 421/1471 [00:53<02:11,  8.00it/s]2024-08-13 21:37:27,215 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:27,294 - INFO - joeynmt.prediction - Generation took 0.0758[sec].\n",
            "2024-08-13 21:37:27,296 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:27,409 - INFO - joeynmt.prediction - Generation took 0.1103[sec].\n",
            " 29%|██▉       | 423/1471 [00:54<02:00,  8.70it/s]2024-08-13 21:37:27,414 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:27,517 - INFO - joeynmt.prediction - Generation took 0.0984[sec].\n",
            " 29%|██▉       | 424/1471 [00:54<01:59,  8.78it/s]2024-08-13 21:37:27,522 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:27,599 - INFO - joeynmt.prediction - Generation took 0.0748[sec].\n",
            "2024-08-13 21:37:27,601 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:27,757 - INFO - joeynmt.prediction - Generation took 0.1537[sec].\n",
            " 29%|██▉       | 426/1471 [00:54<02:01,  8.60it/s]2024-08-13 21:37:27,762 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:27,852 - INFO - joeynmt.prediction - Generation took 0.0874[sec].\n",
            "2024-08-13 21:37:27,854 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:28,040 - INFO - joeynmt.prediction - Generation took 0.1833[sec].\n",
            " 29%|██▉       | 428/1471 [00:54<02:10,  8.00it/s]2024-08-13 21:37:28,044 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:28,101 - INFO - joeynmt.prediction - Generation took 0.0551[sec].\n",
            "2024-08-13 21:37:28,104 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:28,161 - INFO - joeynmt.prediction - Generation took 0.0558[sec].\n",
            " 29%|██▉       | 430/1471 [00:54<01:47,  9.66it/s]2024-08-13 21:37:28,167 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:28,227 - INFO - joeynmt.prediction - Generation took 0.0581[sec].\n",
            "2024-08-13 21:37:28,229 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:28,362 - INFO - joeynmt.prediction - Generation took 0.1310[sec].\n",
            " 29%|██▉       | 432/1471 [00:54<01:46,  9.77it/s]2024-08-13 21:37:28,367 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:28,447 - INFO - joeynmt.prediction - Generation took 0.0769[sec].\n",
            "2024-08-13 21:37:28,449 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:28,597 - INFO - joeynmt.prediction - Generation took 0.1451[sec].\n",
            " 30%|██▉       | 434/1471 [00:55<01:51,  9.32it/s]2024-08-13 21:37:28,602 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:28,699 - INFO - joeynmt.prediction - Generation took 0.0940[sec].\n",
            " 30%|██▉       | 435/1471 [00:55<01:50,  9.41it/s]2024-08-13 21:37:28,704 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:28,757 - INFO - joeynmt.prediction - Generation took 0.0496[sec].\n",
            "2024-08-13 21:37:28,759 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:28,841 - INFO - joeynmt.prediction - Generation took 0.0794[sec].\n",
            " 30%|██▉       | 437/1471 [00:55<01:37, 10.63it/s]2024-08-13 21:37:28,846 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:28,897 - INFO - joeynmt.prediction - Generation took 0.0482[sec].\n",
            "2024-08-13 21:37:28,899 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:28,979 - INFO - joeynmt.prediction - Generation took 0.0774[sec].\n",
            " 30%|██▉       | 439/1471 [00:55<01:28, 11.67it/s]2024-08-13 21:37:28,983 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:29,037 - INFO - joeynmt.prediction - Generation took 0.0512[sec].\n",
            "2024-08-13 21:37:29,039 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:29,225 - INFO - joeynmt.prediction - Generation took 0.1831[sec].\n",
            " 30%|██▉       | 441/1471 [00:55<01:40, 10.23it/s]2024-08-13 21:37:29,229 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:29,311 - INFO - joeynmt.prediction - Generation took 0.0798[sec].\n",
            "2024-08-13 21:37:29,314 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:29,372 - INFO - joeynmt.prediction - Generation took 0.0562[sec].\n",
            " 30%|███       | 443/1471 [00:55<01:32, 11.09it/s]2024-08-13 21:37:29,376 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:29,525 - INFO - joeynmt.prediction - Generation took 0.1470[sec].\n",
            "2024-08-13 21:37:29,528 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:29,599 - INFO - joeynmt.prediction - Generation took 0.0687[sec].\n",
            " 30%|███       | 445/1471 [00:56<01:39, 10.27it/s]2024-08-13 21:37:29,603 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:29,736 - INFO - joeynmt.prediction - Generation took 0.1293[sec].\n",
            "2024-08-13 21:37:29,739 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:29,793 - INFO - joeynmt.prediction - Generation took 0.0513[sec].\n",
            " 30%|███       | 447/1471 [00:56<01:39, 10.29it/s]2024-08-13 21:37:29,797 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:29,939 - INFO - joeynmt.prediction - Generation took 0.1404[sec].\n",
            "2024-08-13 21:37:29,941 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:30,011 - INFO - joeynmt.prediction - Generation took 0.0656[sec].\n",
            " 31%|███       | 449/1471 [00:56<01:42,  9.93it/s]2024-08-13 21:37:30,016 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:30,077 - INFO - joeynmt.prediction - Generation took 0.0576[sec].\n",
            "2024-08-13 21:37:30,080 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:30,188 - INFO - joeynmt.prediction - Generation took 0.1052[sec].\n",
            " 31%|███       | 451/1471 [00:56<01:39, 10.29it/s]2024-08-13 21:37:30,193 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:30,256 - INFO - joeynmt.prediction - Generation took 0.0607[sec].\n",
            "2024-08-13 21:37:30,258 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:30,339 - INFO - joeynmt.prediction - Generation took 0.0785[sec].\n",
            " 31%|███       | 453/1471 [00:56<01:32, 11.04it/s]2024-08-13 21:37:30,343 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:30,497 - INFO - joeynmt.prediction - Generation took 0.1505[sec].\n",
            "2024-08-13 21:37:30,499 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:30,561 - INFO - joeynmt.prediction - Generation took 0.0573[sec].\n",
            " 31%|███       | 455/1471 [00:57<01:38, 10.34it/s]2024-08-13 21:37:30,566 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:30,694 - INFO - joeynmt.prediction - Generation took 0.1248[sec].\n",
            "2024-08-13 21:37:30,696 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:30,780 - INFO - joeynmt.prediction - Generation took 0.0812[sec].\n",
            " 31%|███       | 457/1471 [00:57<01:42,  9.94it/s]2024-08-13 21:37:30,785 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:30,893 - INFO - joeynmt.prediction - Generation took 0.1051[sec].\n",
            "2024-08-13 21:37:30,899 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:31,078 - INFO - joeynmt.prediction - Generation took 0.1760[sec].\n",
            " 31%|███       | 459/1471 [00:57<01:56,  8.68it/s]2024-08-13 21:37:31,082 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:31,265 - INFO - joeynmt.prediction - Generation took 0.1804[sec].\n",
            " 31%|███▏      | 460/1471 [00:57<02:09,  7.82it/s]2024-08-13 21:37:31,269 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:31,605 - INFO - joeynmt.prediction - Generation took 0.3332[sec].\n",
            " 31%|███▏      | 461/1471 [00:58<02:52,  5.86it/s]2024-08-13 21:37:31,609 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:31,685 - INFO - joeynmt.prediction - Generation took 0.0740[sec].\n",
            "2024-08-13 21:37:31,688 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:31,749 - INFO - joeynmt.prediction - Generation took 0.0585[sec].\n",
            " 31%|███▏      | 463/1471 [00:58<02:15,  7.43it/s]2024-08-13 21:37:31,753 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:31,794 - INFO - joeynmt.prediction - Generation took 0.0389[sec].\n",
            "2024-08-13 21:37:31,796 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:31,938 - INFO - joeynmt.prediction - Generation took 0.1386[sec].\n",
            " 32%|███▏      | 465/1471 [00:58<02:01,  8.28it/s]2024-08-13 21:37:31,942 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:32,003 - INFO - joeynmt.prediction - Generation took 0.0581[sec].\n",
            "2024-08-13 21:37:32,005 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:32,269 - INFO - joeynmt.prediction - Generation took 0.2620[sec].\n",
            " 32%|███▏      | 467/1471 [00:58<02:16,  7.38it/s]2024-08-13 21:37:32,273 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:32,463 - INFO - joeynmt.prediction - Generation took 0.1868[sec].\n",
            " 32%|███▏      | 468/1471 [00:59<02:27,  6.81it/s]2024-08-13 21:37:32,470 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:32,731 - INFO - joeynmt.prediction - Generation took 0.2579[sec].\n",
            " 32%|███▏      | 469/1471 [00:59<02:52,  5.80it/s]2024-08-13 21:37:32,736 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:32,862 - INFO - joeynmt.prediction - Generation took 0.1238[sec].\n",
            " 32%|███▏      | 470/1471 [00:59<02:42,  6.15it/s]2024-08-13 21:37:32,866 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:33,084 - INFO - joeynmt.prediction - Generation took 0.2162[sec].\n",
            " 32%|███▏      | 471/1471 [00:59<02:57,  5.62it/s]2024-08-13 21:37:33,089 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:33,329 - INFO - joeynmt.prediction - Generation took 0.2370[sec].\n",
            " 32%|███▏      | 472/1471 [00:59<03:15,  5.12it/s]2024-08-13 21:37:33,334 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:33,582 - INFO - joeynmt.prediction - Generation took 0.2464[sec].\n",
            " 32%|███▏      | 473/1471 [01:00<03:31,  4.72it/s]2024-08-13 21:37:33,590 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:33,748 - INFO - joeynmt.prediction - Generation took 0.1563[sec].\n",
            " 32%|███▏      | 474/1471 [01:00<03:17,  5.04it/s]2024-08-13 21:37:33,757 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:33,894 - INFO - joeynmt.prediction - Generation took 0.1347[sec].\n",
            " 32%|███▏      | 475/1471 [01:00<03:02,  5.46it/s]2024-08-13 21:37:33,898 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:34,169 - INFO - joeynmt.prediction - Generation took 0.2684[sec].\n",
            " 32%|███▏      | 476/1471 [01:00<03:28,  4.76it/s]2024-08-13 21:37:34,174 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:34,280 - INFO - joeynmt.prediction - Generation took 0.1038[sec].\n",
            " 32%|███▏      | 477/1471 [01:00<02:59,  5.53it/s]2024-08-13 21:37:34,285 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:34,416 - INFO - joeynmt.prediction - Generation took 0.1287[sec].\n",
            " 32%|███▏      | 478/1471 [01:01<02:46,  5.98it/s]2024-08-13 21:37:34,420 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:34,600 - INFO - joeynmt.prediction - Generation took 0.1779[sec].\n",
            " 33%|███▎      | 479/1471 [01:01<02:51,  5.79it/s]2024-08-13 21:37:34,605 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:34,825 - INFO - joeynmt.prediction - Generation took 0.2172[sec].\n",
            " 33%|███▎      | 480/1471 [01:01<03:06,  5.32it/s]2024-08-13 21:37:34,830 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:34,918 - INFO - joeynmt.prediction - Generation took 0.0849[sec].\n",
            "2024-08-13 21:37:34,921 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:35,158 - INFO - joeynmt.prediction - Generation took 0.2353[sec].\n",
            " 33%|███▎      | 482/1471 [01:01<02:56,  5.61it/s]2024-08-13 21:37:35,163 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:35,334 - INFO - joeynmt.prediction - Generation took 0.1693[sec].\n",
            " 33%|███▎      | 483/1471 [01:01<02:55,  5.63it/s]2024-08-13 21:37:35,339 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:35,955 - INFO - joeynmt.prediction - Generation took 0.6143[sec].\n",
            " 33%|███▎      | 484/1471 [01:02<04:49,  3.41it/s]2024-08-13 21:37:35,961 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:36,144 - INFO - joeynmt.prediction - Generation took 0.1799[sec].\n",
            " 33%|███▎      | 485/1471 [01:02<04:21,  3.78it/s]2024-08-13 21:37:36,149 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:36,356 - INFO - joeynmt.prediction - Generation took 0.2043[sec].\n",
            " 33%|███▎      | 486/1471 [01:02<04:06,  4.00it/s]2024-08-13 21:37:36,360 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:36,518 - INFO - joeynmt.prediction - Generation took 0.1550[sec].\n",
            " 33%|███▎      | 487/1471 [01:03<03:41,  4.44it/s]2024-08-13 21:37:36,522 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:36,712 - INFO - joeynmt.prediction - Generation took 0.1861[sec].\n",
            " 33%|███▎      | 488/1471 [01:03<03:32,  4.63it/s]2024-08-13 21:37:36,716 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:36,884 - INFO - joeynmt.prediction - Generation took 0.1651[sec].\n",
            " 33%|███▎      | 489/1471 [01:03<03:19,  4.92it/s]2024-08-13 21:37:36,888 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:37,118 - INFO - joeynmt.prediction - Generation took 0.2278[sec].\n",
            " 33%|███▎      | 490/1471 [01:03<03:28,  4.71it/s]2024-08-13 21:37:37,123 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:37,266 - INFO - joeynmt.prediction - Generation took 0.1406[sec].\n",
            " 33%|███▎      | 491/1471 [01:03<03:09,  5.18it/s]2024-08-13 21:37:37,271 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:37,423 - INFO - joeynmt.prediction - Generation took 0.1485[sec].\n",
            " 33%|███▎      | 492/1471 [01:04<02:58,  5.49it/s]2024-08-13 21:37:37,428 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:37,655 - INFO - joeynmt.prediction - Generation took 0.2246[sec].\n",
            " 34%|███▎      | 493/1471 [01:04<03:12,  5.07it/s]2024-08-13 21:37:37,660 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:37,827 - INFO - joeynmt.prediction - Generation took 0.1653[sec].\n",
            " 34%|███▎      | 494/1471 [01:04<03:05,  5.27it/s]2024-08-13 21:37:37,831 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:37,958 - INFO - joeynmt.prediction - Generation took 0.1239[sec].\n",
            " 34%|███▎      | 495/1471 [01:04<02:48,  5.81it/s]2024-08-13 21:37:37,963 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:38,085 - INFO - joeynmt.prediction - Generation took 0.1195[sec].\n",
            " 34%|███▎      | 496/1471 [01:04<02:34,  6.30it/s]2024-08-13 21:37:38,090 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:38,231 - INFO - joeynmt.prediction - Generation took 0.1377[sec].\n",
            " 34%|███▍      | 497/1471 [01:04<02:30,  6.46it/s]2024-08-13 21:37:38,235 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:38,438 - INFO - joeynmt.prediction - Generation took 0.2004[sec].\n",
            " 34%|███▍      | 498/1471 [01:05<02:45,  5.87it/s]2024-08-13 21:37:38,443 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:38,624 - INFO - joeynmt.prediction - Generation took 0.1779[sec].\n",
            " 34%|███▍      | 499/1471 [01:05<02:50,  5.70it/s]2024-08-13 21:37:38,629 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:38,807 - INFO - joeynmt.prediction - Generation took 0.1759[sec].\n",
            " 34%|███▍      | 500/1471 [01:05<02:52,  5.64it/s]2024-08-13 21:37:38,811 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:38,969 - INFO - joeynmt.prediction - Generation took 0.1543[sec].\n",
            " 34%|███▍      | 501/1471 [01:05<02:47,  5.78it/s]2024-08-13 21:37:38,974 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:39,148 - INFO - joeynmt.prediction - Generation took 0.1721[sec].\n",
            " 34%|███▍      | 502/1471 [01:05<02:49,  5.72it/s]2024-08-13 21:37:39,153 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:39,223 - INFO - joeynmt.prediction - Generation took 0.0665[sec].\n",
            "2024-08-13 21:37:39,225 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:39,415 - INFO - joeynmt.prediction - Generation took 0.1868[sec].\n",
            " 34%|███▍      | 504/1471 [01:06<02:30,  6.43it/s]2024-08-13 21:37:39,420 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:39,572 - INFO - joeynmt.prediction - Generation took 0.1468[sec].\n",
            " 34%|███▍      | 505/1471 [01:06<02:30,  6.41it/s]2024-08-13 21:37:39,576 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:39,787 - INFO - joeynmt.prediction - Generation took 0.2083[sec].\n",
            " 34%|███▍      | 506/1471 [01:06<02:45,  5.84it/s]2024-08-13 21:37:39,794 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:39,967 - INFO - joeynmt.prediction - Generation took 0.1702[sec].\n",
            " 34%|███▍      | 507/1471 [01:06<02:47,  5.75it/s]2024-08-13 21:37:39,971 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:40,042 - INFO - joeynmt.prediction - Generation took 0.0693[sec].\n",
            "2024-08-13 21:37:40,045 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:40,240 - INFO - joeynmt.prediction - Generation took 0.1926[sec].\n",
            " 35%|███▍      | 509/1471 [01:06<02:31,  6.35it/s]2024-08-13 21:37:40,244 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:40,342 - INFO - joeynmt.prediction - Generation took 0.0941[sec].\n",
            " 35%|███▍      | 510/1471 [01:06<02:19,  6.91it/s]2024-08-13 21:37:40,351 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:40,431 - INFO - joeynmt.prediction - Generation took 0.0746[sec].\n",
            "2024-08-13 21:37:40,433 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:40,672 - INFO - joeynmt.prediction - Generation took 0.2362[sec].\n",
            " 35%|███▍      | 512/1471 [01:07<02:26,  6.56it/s]2024-08-13 21:37:40,678 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:40,740 - INFO - joeynmt.prediction - Generation took 0.0597[sec].\n",
            "2024-08-13 21:37:40,743 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:40,882 - INFO - joeynmt.prediction - Generation took 0.1343[sec].\n",
            " 35%|███▍      | 514/1471 [01:07<02:09,  7.40it/s]2024-08-13 21:37:40,888 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:40,968 - INFO - joeynmt.prediction - Generation took 0.0766[sec].\n",
            "2024-08-13 21:37:40,970 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:41,034 - INFO - joeynmt.prediction - Generation took 0.0620[sec].\n",
            " 35%|███▌      | 516/1471 [01:07<01:49,  8.71it/s]2024-08-13 21:37:41,038 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:41,154 - INFO - joeynmt.prediction - Generation took 0.1136[sec].\n",
            " 35%|███▌      | 517/1471 [01:07<01:50,  8.62it/s]2024-08-13 21:37:41,161 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:41,290 - INFO - joeynmt.prediction - Generation took 0.1251[sec].\n",
            " 35%|███▌      | 518/1471 [01:07<01:54,  8.32it/s]2024-08-13 21:37:41,295 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:41,388 - INFO - joeynmt.prediction - Generation took 0.0911[sec].\n",
            "2024-08-13 21:37:41,390 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:41,485 - INFO - joeynmt.prediction - Generation took 0.0926[sec].\n",
            " 35%|███▌      | 520/1471 [01:08<01:46,  8.97it/s]2024-08-13 21:37:41,489 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:41,563 - INFO - joeynmt.prediction - Generation took 0.0718[sec].\n",
            "2024-08-13 21:37:41,566 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:41,685 - INFO - joeynmt.prediction - Generation took 0.1165[sec].\n",
            " 35%|███▌      | 522/1471 [01:08<01:41,  9.33it/s]2024-08-13 21:37:41,689 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:41,848 - INFO - joeynmt.prediction - Generation took 0.1556[sec].\n",
            " 36%|███▌      | 523/1471 [01:08<01:52,  8.43it/s]2024-08-13 21:37:41,853 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:42,012 - INFO - joeynmt.prediction - Generation took 0.1559[sec].\n",
            " 36%|███▌      | 524/1471 [01:08<02:02,  7.75it/s]2024-08-13 21:37:42,016 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:42,140 - INFO - joeynmt.prediction - Generation took 0.1210[sec].\n",
            " 36%|███▌      | 525/1471 [01:08<02:01,  7.78it/s]2024-08-13 21:37:42,144 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:42,294 - INFO - joeynmt.prediction - Generation took 0.1475[sec].\n",
            " 36%|███▌      | 526/1471 [01:08<02:07,  7.40it/s]2024-08-13 21:37:42,298 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:42,524 - INFO - joeynmt.prediction - Generation took 0.2234[sec].\n",
            " 36%|███▌      | 527/1471 [01:09<02:32,  6.21it/s]2024-08-13 21:37:42,530 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:42,659 - INFO - joeynmt.prediction - Generation took 0.1265[sec].\n",
            " 36%|███▌      | 528/1471 [01:09<02:24,  6.52it/s]2024-08-13 21:37:42,663 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:42,800 - INFO - joeynmt.prediction - Generation took 0.1331[sec].\n",
            " 36%|███▌      | 529/1471 [01:09<02:21,  6.66it/s]2024-08-13 21:37:42,804 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:42,885 - INFO - joeynmt.prediction - Generation took 0.0793[sec].\n",
            "2024-08-13 21:37:42,888 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:42,949 - INFO - joeynmt.prediction - Generation took 0.0584[sec].\n",
            " 36%|███▌      | 531/1471 [01:09<01:49,  8.60it/s]2024-08-13 21:37:42,954 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:43,072 - INFO - joeynmt.prediction - Generation took 0.1158[sec].\n",
            " 36%|███▌      | 532/1471 [01:09<01:50,  8.47it/s]2024-08-13 21:37:43,079 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:43,218 - INFO - joeynmt.prediction - Generation took 0.1365[sec].\n",
            " 36%|███▌      | 533/1471 [01:09<01:57,  7.99it/s]2024-08-13 21:37:43,223 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:43,501 - INFO - joeynmt.prediction - Generation took 0.2757[sec].\n",
            " 36%|███▋      | 534/1471 [01:10<02:36,  5.97it/s]2024-08-13 21:37:43,505 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:43,601 - INFO - joeynmt.prediction - Generation took 0.0936[sec].\n",
            "2024-08-13 21:37:43,603 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:43,789 - INFO - joeynmt.prediction - Generation took 0.1826[sec].\n",
            " 36%|███▋      | 536/1471 [01:10<02:26,  6.37it/s]2024-08-13 21:37:43,793 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:43,989 - INFO - joeynmt.prediction - Generation took 0.1940[sec].\n",
            " 37%|███▋      | 537/1471 [01:10<02:36,  5.98it/s]2024-08-13 21:37:43,994 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:44,074 - INFO - joeynmt.prediction - Generation took 0.0777[sec].\n",
            "2024-08-13 21:37:44,076 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:44,158 - INFO - joeynmt.prediction - Generation took 0.0793[sec].\n",
            " 37%|███▋      | 539/1471 [01:10<02:04,  7.46it/s]2024-08-13 21:37:44,163 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:44,259 - INFO - joeynmt.prediction - Generation took 0.0928[sec].\n",
            " 37%|███▋      | 540/1471 [01:10<01:57,  7.89it/s]2024-08-13 21:37:44,266 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:44,394 - INFO - joeynmt.prediction - Generation took 0.1248[sec].\n",
            " 37%|███▋      | 541/1471 [01:11<01:59,  7.77it/s]2024-08-13 21:37:44,399 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:44,560 - INFO - joeynmt.prediction - Generation took 0.1577[sec].\n",
            " 37%|███▋      | 542/1471 [01:11<02:08,  7.23it/s]2024-08-13 21:37:44,566 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:44,697 - INFO - joeynmt.prediction - Generation took 0.1283[sec].\n",
            " 37%|███▋      | 543/1471 [01:11<02:08,  7.24it/s]2024-08-13 21:37:44,705 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:44,832 - INFO - joeynmt.prediction - Generation took 0.1246[sec].\n",
            " 37%|███▋      | 544/1471 [01:11<02:06,  7.30it/s]2024-08-13 21:37:44,840 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:45,049 - INFO - joeynmt.prediction - Generation took 0.2074[sec].\n",
            " 37%|███▋      | 545/1471 [01:11<02:28,  6.26it/s]2024-08-13 21:37:45,054 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:45,433 - INFO - joeynmt.prediction - Generation took 0.3768[sec].\n",
            " 37%|███▋      | 546/1471 [01:12<03:28,  4.44it/s]2024-08-13 21:37:45,441 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:45,580 - INFO - joeynmt.prediction - Generation took 0.1364[sec].\n",
            " 37%|███▋      | 547/1471 [01:12<03:06,  4.96it/s]2024-08-13 21:37:45,584 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:45,680 - INFO - joeynmt.prediction - Generation took 0.0949[sec].\n",
            " 37%|███▋      | 548/1471 [01:12<02:38,  5.81it/s]2024-08-13 21:37:45,688 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:45,791 - INFO - joeynmt.prediction - Generation took 0.1014[sec].\n",
            " 37%|███▋      | 549/1471 [01:12<02:22,  6.46it/s]2024-08-13 21:37:45,799 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:46,177 - INFO - joeynmt.prediction - Generation took 0.3730[sec].\n",
            " 37%|███▋      | 550/1471 [01:12<03:24,  4.50it/s]2024-08-13 21:37:46,184 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:46,309 - INFO - joeynmt.prediction - Generation took 0.1228[sec].\n",
            " 37%|███▋      | 551/1471 [01:12<02:59,  5.12it/s]2024-08-13 21:37:46,314 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:46,423 - INFO - joeynmt.prediction - Generation took 0.1069[sec].\n",
            " 38%|███▊      | 552/1471 [01:13<02:38,  5.81it/s]2024-08-13 21:37:46,431 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:46,556 - INFO - joeynmt.prediction - Generation took 0.1223[sec].\n",
            " 38%|███▊      | 553/1471 [01:13<02:27,  6.23it/s]2024-08-13 21:37:46,564 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:46,960 - INFO - joeynmt.prediction - Generation took 0.3936[sec].\n",
            " 38%|███▊      | 554/1471 [01:13<03:33,  4.30it/s]2024-08-13 21:37:46,967 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:47,288 - INFO - joeynmt.prediction - Generation took 0.3178[sec].\n",
            " 38%|███▊      | 555/1471 [01:13<03:58,  3.83it/s]2024-08-13 21:37:47,292 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:47,537 - INFO - joeynmt.prediction - Generation took 0.2426[sec].\n",
            " 38%|███▊      | 556/1471 [01:14<03:55,  3.89it/s]2024-08-13 21:37:47,542 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:48,131 - INFO - joeynmt.prediction - Generation took 0.5854[sec].\n",
            " 38%|███▊      | 557/1471 [01:14<05:27,  2.79it/s]2024-08-13 21:37:48,137 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:48,219 - INFO - joeynmt.prediction - Generation took 0.0796[sec].\n",
            "2024-08-13 21:37:48,222 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:48,324 - INFO - joeynmt.prediction - Generation took 0.0996[sec].\n",
            " 38%|███▊      | 559/1471 [01:14<03:36,  4.21it/s]2024-08-13 21:37:48,329 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:48,482 - INFO - joeynmt.prediction - Generation took 0.1505[sec].\n",
            " 38%|███▊      | 560/1471 [01:15<03:18,  4.59it/s]2024-08-13 21:37:48,488 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:48,559 - INFO - joeynmt.prediction - Generation took 0.0665[sec].\n",
            "2024-08-13 21:37:48,561 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:48,630 - INFO - joeynmt.prediction - Generation took 0.0659[sec].\n",
            " 38%|███▊      | 562/1471 [01:15<02:23,  6.32it/s]2024-08-13 21:37:48,634 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:48,789 - INFO - joeynmt.prediction - Generation took 0.1513[sec].\n",
            " 38%|███▊      | 563/1471 [01:15<02:23,  6.31it/s]2024-08-13 21:37:48,796 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:48,909 - INFO - joeynmt.prediction - Generation took 0.1090[sec].\n",
            " 38%|███▊      | 564/1471 [01:15<02:15,  6.71it/s]2024-08-13 21:37:48,913 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:49,015 - INFO - joeynmt.prediction - Generation took 0.0979[sec].\n",
            " 38%|███▊      | 565/1471 [01:15<02:05,  7.23it/s]2024-08-13 21:37:49,021 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:49,094 - INFO - joeynmt.prediction - Generation took 0.0706[sec].\n",
            "2024-08-13 21:37:49,096 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:49,264 - INFO - joeynmt.prediction - Generation took 0.1652[sec].\n",
            " 39%|███▊      | 567/1471 [01:15<01:59,  7.57it/s]2024-08-13 21:37:49,268 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:49,324 - INFO - joeynmt.prediction - Generation took 0.0538[sec].\n",
            "2024-08-13 21:37:49,326 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:49,500 - INFO - joeynmt.prediction - Generation took 0.1700[sec].\n",
            " 39%|███▊      | 569/1471 [01:16<01:54,  7.89it/s]2024-08-13 21:37:49,505 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:49,613 - INFO - joeynmt.prediction - Generation took 0.1060[sec].\n",
            " 39%|███▊      | 570/1471 [01:16<01:51,  8.07it/s]2024-08-13 21:37:49,618 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:49,692 - INFO - joeynmt.prediction - Generation took 0.0722[sec].\n",
            "2024-08-13 21:37:49,694 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:49,883 - INFO - joeynmt.prediction - Generation took 0.1856[sec].\n",
            " 39%|███▉      | 572/1471 [01:16<01:55,  7.81it/s]2024-08-13 21:37:49,887 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:49,967 - INFO - joeynmt.prediction - Generation took 0.0771[sec].\n",
            "2024-08-13 21:37:49,969 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:50,054 - INFO - joeynmt.prediction - Generation took 0.0825[sec].\n",
            " 39%|███▉      | 574/1471 [01:16<01:41,  8.84it/s]2024-08-13 21:37:50,059 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:50,172 - INFO - joeynmt.prediction - Generation took 0.1112[sec].\n",
            " 39%|███▉      | 575/1471 [01:16<01:42,  8.76it/s]2024-08-13 21:37:50,177 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:50,245 - INFO - joeynmt.prediction - Generation took 0.0657[sec].\n",
            "2024-08-13 21:37:50,247 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:50,320 - INFO - joeynmt.prediction - Generation took 0.0711[sec].\n",
            " 39%|███▉      | 577/1471 [01:16<01:28, 10.05it/s]2024-08-13 21:37:50,325 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:50,391 - INFO - joeynmt.prediction - Generation took 0.0639[sec].\n",
            "2024-08-13 21:37:50,393 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:50,618 - INFO - joeynmt.prediction - Generation took 0.2220[sec].\n",
            " 39%|███▉      | 579/1471 [01:17<01:43,  8.58it/s]2024-08-13 21:37:50,623 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:50,683 - INFO - joeynmt.prediction - Generation took 0.0582[sec].\n",
            "2024-08-13 21:37:50,685 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:50,861 - INFO - joeynmt.prediction - Generation took 0.1727[sec].\n",
            " 39%|███▉      | 581/1471 [01:17<01:45,  8.47it/s]2024-08-13 21:37:50,865 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:50,924 - INFO - joeynmt.prediction - Generation took 0.0561[sec].\n",
            "2024-08-13 21:37:50,926 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:51,013 - INFO - joeynmt.prediction - Generation took 0.0843[sec].\n",
            " 40%|███▉      | 583/1471 [01:17<01:32,  9.55it/s]2024-08-13 21:37:51,018 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:51,073 - INFO - joeynmt.prediction - Generation took 0.0524[sec].\n",
            "2024-08-13 21:37:51,076 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:51,155 - INFO - joeynmt.prediction - Generation took 0.0741[sec].\n",
            " 40%|███▉      | 585/1471 [01:17<01:23, 10.63it/s]2024-08-13 21:37:51,159 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:51,329 - INFO - joeynmt.prediction - Generation took 0.1684[sec].\n",
            "2024-08-13 21:37:51,332 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:51,396 - INFO - joeynmt.prediction - Generation took 0.0602[sec].\n",
            " 40%|███▉      | 587/1471 [01:18<01:30,  9.79it/s]2024-08-13 21:37:51,400 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:51,508 - INFO - joeynmt.prediction - Generation took 0.1067[sec].\n",
            "2024-08-13 21:37:51,512 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:51,599 - INFO - joeynmt.prediction - Generation took 0.0844[sec].\n",
            " 40%|████      | 589/1471 [01:18<01:29,  9.81it/s]2024-08-13 21:37:51,604 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:51,829 - INFO - joeynmt.prediction - Generation took 0.2221[sec].\n",
            "2024-08-13 21:37:51,831 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:52,065 - INFO - joeynmt.prediction - Generation took 0.2306[sec].\n",
            " 40%|████      | 591/1471 [01:18<02:04,  7.04it/s]2024-08-13 21:37:52,070 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:52,131 - INFO - joeynmt.prediction - Generation took 0.0591[sec].\n",
            "2024-08-13 21:37:52,133 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:52,505 - INFO - joeynmt.prediction - Generation took 0.3670[sec].\n",
            " 40%|████      | 593/1471 [01:19<02:25,  6.04it/s]2024-08-13 21:37:52,509 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:52,598 - INFO - joeynmt.prediction - Generation took 0.0864[sec].\n",
            "2024-08-13 21:37:52,600 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:52,774 - INFO - joeynmt.prediction - Generation took 0.1719[sec].\n",
            " 40%|████      | 595/1471 [01:19<02:16,  6.40it/s]2024-08-13 21:37:52,778 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:52,904 - INFO - joeynmt.prediction - Generation took 0.1234[sec].\n",
            " 41%|████      | 596/1471 [01:19<02:12,  6.60it/s]2024-08-13 21:37:52,909 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:53,045 - INFO - joeynmt.prediction - Generation took 0.1337[sec].\n",
            " 41%|████      | 597/1471 [01:19<02:10,  6.70it/s]2024-08-13 21:37:53,049 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:53,127 - INFO - joeynmt.prediction - Generation took 0.0753[sec].\n",
            "2024-08-13 21:37:53,129 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:53,299 - INFO - joeynmt.prediction - Generation took 0.1682[sec].\n",
            " 41%|████      | 599/1471 [01:19<02:03,  7.08it/s]2024-08-13 21:37:53,304 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:53,467 - INFO - joeynmt.prediction - Generation took 0.1605[sec].\n",
            " 41%|████      | 600/1471 [01:20<02:07,  6.81it/s]2024-08-13 21:37:53,471 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:53,563 - INFO - joeynmt.prediction - Generation took 0.0894[sec].\n",
            "2024-08-13 21:37:53,564 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:53,864 - INFO - joeynmt.prediction - Generation took 0.2958[sec].\n",
            " 41%|████      | 602/1471 [01:20<02:24,  6.02it/s]2024-08-13 21:37:53,868 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:53,944 - INFO - joeynmt.prediction - Generation took 0.0732[sec].\n",
            "2024-08-13 21:37:53,946 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:54,012 - INFO - joeynmt.prediction - Generation took 0.0623[sec].\n",
            " 41%|████      | 604/1471 [01:20<01:56,  7.47it/s]2024-08-13 21:37:54,016 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:54,074 - INFO - joeynmt.prediction - Generation took 0.0552[sec].\n",
            "2024-08-13 21:37:54,075 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:54,421 - INFO - joeynmt.prediction - Generation took 0.3429[sec].\n",
            " 41%|████      | 606/1471 [01:21<02:16,  6.36it/s]2024-08-13 21:37:54,425 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:54,525 - INFO - joeynmt.prediction - Generation took 0.0972[sec].\n",
            " 41%|████▏     | 607/1471 [01:21<02:07,  6.80it/s]2024-08-13 21:37:54,530 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:54,667 - INFO - joeynmt.prediction - Generation took 0.1337[sec].\n",
            " 41%|████▏     | 608/1471 [01:21<02:06,  6.85it/s]2024-08-13 21:37:54,672 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:54,754 - INFO - joeynmt.prediction - Generation took 0.0790[sec].\n",
            "2024-08-13 21:37:54,757 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:55,020 - INFO - joeynmt.prediction - Generation took 0.2611[sec].\n",
            " 41%|████▏     | 610/1471 [01:21<02:15,  6.33it/s]2024-08-13 21:37:55,026 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:55,092 - INFO - joeynmt.prediction - Generation took 0.0628[sec].\n",
            "2024-08-13 21:37:55,093 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:55,164 - INFO - joeynmt.prediction - Generation took 0.0681[sec].\n",
            " 42%|████▏     | 612/1471 [01:21<01:49,  7.84it/s]2024-08-13 21:37:55,170 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:55,283 - INFO - joeynmt.prediction - Generation took 0.1100[sec].\n",
            " 42%|████▏     | 613/1471 [01:21<01:48,  7.94it/s]2024-08-13 21:37:55,288 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:55,360 - INFO - joeynmt.prediction - Generation took 0.0703[sec].\n",
            "2024-08-13 21:37:55,362 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:55,421 - INFO - joeynmt.prediction - Generation took 0.0550[sec].\n",
            " 42%|████▏     | 615/1471 [01:22<01:29,  9.53it/s]2024-08-13 21:37:55,425 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:55,542 - INFO - joeynmt.prediction - Generation took 0.1145[sec].\n",
            "2024-08-13 21:37:55,544 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:55,618 - INFO - joeynmt.prediction - Generation took 0.0716[sec].\n",
            " 42%|████▏     | 617/1471 [01:22<01:27,  9.72it/s]2024-08-13 21:37:55,623 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:55,701 - INFO - joeynmt.prediction - Generation took 0.0762[sec].\n",
            "2024-08-13 21:37:55,703 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:55,904 - INFO - joeynmt.prediction - Generation took 0.1976[sec].\n",
            " 42%|████▏     | 619/1471 [01:22<01:38,  8.62it/s]2024-08-13 21:37:55,908 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:55,971 - INFO - joeynmt.prediction - Generation took 0.0603[sec].\n",
            "2024-08-13 21:37:55,973 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:56,162 - INFO - joeynmt.prediction - Generation took 0.1859[sec].\n",
            " 42%|████▏     | 621/1471 [01:22<01:42,  8.33it/s]2024-08-13 21:37:56,166 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:56,392 - INFO - joeynmt.prediction - Generation took 0.2237[sec].\n",
            " 42%|████▏     | 622/1471 [01:23<01:59,  7.11it/s]2024-08-13 21:37:56,397 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:56,521 - INFO - joeynmt.prediction - Generation took 0.1223[sec].\n",
            " 42%|████▏     | 623/1471 [01:23<01:57,  7.23it/s]2024-08-13 21:37:56,525 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:56,602 - INFO - joeynmt.prediction - Generation took 0.0742[sec].\n",
            "2024-08-13 21:37:56,603 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:56,686 - INFO - joeynmt.prediction - Generation took 0.0788[sec].\n",
            " 42%|████▏     | 625/1471 [01:23<01:39,  8.53it/s]2024-08-13 21:37:56,691 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:56,765 - INFO - joeynmt.prediction - Generation took 0.0716[sec].\n",
            "2024-08-13 21:37:56,768 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:56,957 - INFO - joeynmt.prediction - Generation took 0.1866[sec].\n",
            " 43%|████▎     | 627/1471 [01:23<01:44,  8.09it/s]2024-08-13 21:37:56,962 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:57,447 - INFO - joeynmt.prediction - Generation took 0.4809[sec].\n",
            " 43%|████▎     | 628/1471 [01:24<02:45,  5.08it/s]2024-08-13 21:37:57,452 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:57,650 - INFO - joeynmt.prediction - Generation took 0.1933[sec].\n",
            " 43%|████▎     | 629/1471 [01:24<02:46,  5.04it/s]2024-08-13 21:37:57,656 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:57,759 - INFO - joeynmt.prediction - Generation took 0.0993[sec].\n",
            " 43%|████▎     | 630/1471 [01:24<02:28,  5.66it/s]2024-08-13 21:37:57,763 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:57,866 - INFO - joeynmt.prediction - Generation took 0.1007[sec].\n",
            " 43%|████▎     | 631/1471 [01:24<02:13,  6.30it/s]2024-08-13 21:37:57,870 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:57,955 - INFO - joeynmt.prediction - Generation took 0.0829[sec].\n",
            "2024-08-13 21:37:57,958 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:58,054 - INFO - joeynmt.prediction - Generation took 0.0941[sec].\n",
            " 43%|████▎     | 633/1471 [01:24<01:50,  7.61it/s]2024-08-13 21:37:58,058 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:58,108 - INFO - joeynmt.prediction - Generation took 0.0476[sec].\n",
            "2024-08-13 21:37:58,110 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:58,268 - INFO - joeynmt.prediction - Generation took 0.1553[sec].\n",
            " 43%|████▎     | 635/1471 [01:24<01:42,  8.17it/s]2024-08-13 21:37:58,273 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:58,531 - INFO - joeynmt.prediction - Generation took 0.2552[sec].\n",
            " 43%|████▎     | 636/1471 [01:25<02:06,  6.58it/s]2024-08-13 21:37:58,535 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:58,602 - INFO - joeynmt.prediction - Generation took 0.0636[sec].\n",
            "2024-08-13 21:37:58,604 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:58,669 - INFO - joeynmt.prediction - Generation took 0.0618[sec].\n",
            " 43%|████▎     | 638/1471 [01:25<01:40,  8.29it/s]2024-08-13 21:37:58,673 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:58,740 - INFO - joeynmt.prediction - Generation took 0.0649[sec].\n",
            "2024-08-13 21:37:58,742 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:58,861 - INFO - joeynmt.prediction - Generation took 0.1160[sec].\n",
            " 44%|████▎     | 640/1471 [01:25<01:33,  8.92it/s]2024-08-13 21:37:58,865 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:58,971 - INFO - joeynmt.prediction - Generation took 0.1038[sec].\n",
            " 44%|████▎     | 641/1471 [01:25<01:32,  8.94it/s]2024-08-13 21:37:58,976 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:59,140 - INFO - joeynmt.prediction - Generation took 0.1584[sec].\n",
            " 44%|████▎     | 642/1471 [01:25<01:43,  8.02it/s]2024-08-13 21:37:59,145 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:59,276 - INFO - joeynmt.prediction - Generation took 0.1260[sec].\n",
            " 44%|████▎     | 643/1471 [01:25<01:45,  7.86it/s]2024-08-13 21:37:59,280 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:59,463 - INFO - joeynmt.prediction - Generation took 0.1803[sec].\n",
            " 44%|████▍     | 644/1471 [01:26<01:58,  7.00it/s]2024-08-13 21:37:59,471 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:59,716 - INFO - joeynmt.prediction - Generation took 0.2402[sec].\n",
            " 44%|████▍     | 645/1471 [01:26<02:21,  5.82it/s]2024-08-13 21:37:59,720 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:59,807 - INFO - joeynmt.prediction - Generation took 0.0838[sec].\n",
            "2024-08-13 21:37:59,809 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:37:59,895 - INFO - joeynmt.prediction - Generation took 0.0825[sec].\n",
            " 44%|████▍     | 647/1471 [01:26<01:52,  7.35it/s]2024-08-13 21:37:59,899 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:00,073 - INFO - joeynmt.prediction - Generation took 0.1710[sec].\n",
            " 44%|████▍     | 648/1471 [01:26<02:00,  6.85it/s]2024-08-13 21:38:00,077 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:00,165 - INFO - joeynmt.prediction - Generation took 0.0856[sec].\n",
            "2024-08-13 21:38:00,168 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:00,278 - INFO - joeynmt.prediction - Generation took 0.1087[sec].\n",
            " 44%|████▍     | 650/1471 [01:26<01:45,  7.77it/s]2024-08-13 21:38:00,283 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:00,376 - INFO - joeynmt.prediction - Generation took 0.0902[sec].\n",
            "2024-08-13 21:38:00,378 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:00,779 - INFO - joeynmt.prediction - Generation took 0.3982[sec].\n",
            " 44%|████▍     | 652/1471 [01:27<02:21,  5.78it/s]2024-08-13 21:38:00,787 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:00,899 - INFO - joeynmt.prediction - Generation took 0.1099[sec].\n",
            " 44%|████▍     | 653/1471 [01:27<02:12,  6.17it/s]2024-08-13 21:38:00,904 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:01,023 - INFO - joeynmt.prediction - Generation took 0.1164[sec].\n",
            " 44%|████▍     | 654/1471 [01:27<02:05,  6.50it/s]2024-08-13 21:38:01,029 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:01,111 - INFO - joeynmt.prediction - Generation took 0.0793[sec].\n",
            "2024-08-13 21:38:01,113 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:01,207 - INFO - joeynmt.prediction - Generation took 0.0913[sec].\n",
            " 45%|████▍     | 656/1471 [01:27<01:45,  7.75it/s]2024-08-13 21:38:01,211 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:01,336 - INFO - joeynmt.prediction - Generation took 0.1224[sec].\n",
            " 45%|████▍     | 657/1471 [01:27<01:45,  7.75it/s]2024-08-13 21:38:01,340 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:01,568 - INFO - joeynmt.prediction - Generation took 0.2251[sec].\n",
            " 45%|████▍     | 658/1471 [01:28<02:05,  6.50it/s]2024-08-13 21:38:01,574 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:01,675 - INFO - joeynmt.prediction - Generation took 0.0988[sec].\n",
            " 45%|████▍     | 659/1471 [01:28<01:55,  7.05it/s]2024-08-13 21:38:01,679 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:01,743 - INFO - joeynmt.prediction - Generation took 0.0618[sec].\n",
            "2024-08-13 21:38:01,746 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:01,815 - INFO - joeynmt.prediction - Generation took 0.0670[sec].\n",
            " 45%|████▍     | 661/1471 [01:28<01:30,  8.96it/s]2024-08-13 21:38:01,820 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:01,891 - INFO - joeynmt.prediction - Generation took 0.0673[sec].\n",
            "2024-08-13 21:38:01,893 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:01,957 - INFO - joeynmt.prediction - Generation took 0.0614[sec].\n",
            " 45%|████▌     | 663/1471 [01:28<01:17, 10.39it/s]2024-08-13 21:38:01,962 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:02,022 - INFO - joeynmt.prediction - Generation took 0.0558[sec].\n",
            "2024-08-13 21:38:02,024 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:02,223 - INFO - joeynmt.prediction - Generation took 0.1975[sec].\n",
            " 45%|████▌     | 665/1471 [01:28<01:27,  9.17it/s]2024-08-13 21:38:02,227 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:02,298 - INFO - joeynmt.prediction - Generation took 0.0681[sec].\n",
            "2024-08-13 21:38:02,300 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:02,357 - INFO - joeynmt.prediction - Generation took 0.0535[sec].\n",
            " 45%|████▌     | 667/1471 [01:28<01:16, 10.54it/s]2024-08-13 21:38:02,361 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:02,421 - INFO - joeynmt.prediction - Generation took 0.0581[sec].\n",
            "2024-08-13 21:38:02,424 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:02,489 - INFO - joeynmt.prediction - Generation took 0.0624[sec].\n",
            " 45%|████▌     | 669/1471 [01:29<01:08, 11.66it/s]2024-08-13 21:38:02,493 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:02,740 - INFO - joeynmt.prediction - Generation took 0.2452[sec].\n",
            "2024-08-13 21:38:02,743 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:02,808 - INFO - joeynmt.prediction - Generation took 0.0618[sec].\n",
            " 46%|████▌     | 671/1471 [01:29<01:27,  9.17it/s]2024-08-13 21:38:02,812 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:02,881 - INFO - joeynmt.prediction - Generation took 0.0667[sec].\n",
            "2024-08-13 21:38:02,883 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:02,947 - INFO - joeynmt.prediction - Generation took 0.0603[sec].\n",
            " 46%|████▌     | 673/1471 [01:29<01:17, 10.34it/s]2024-08-13 21:38:02,951 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:03,095 - INFO - joeynmt.prediction - Generation took 0.1411[sec].\n",
            "2024-08-13 21:38:03,098 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:03,283 - INFO - joeynmt.prediction - Generation took 0.1808[sec].\n",
            " 46%|████▌     | 675/1471 [01:29<01:34,  8.43it/s]2024-08-13 21:38:03,287 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:03,420 - INFO - joeynmt.prediction - Generation took 0.1302[sec].\n",
            "2024-08-13 21:38:03,422 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:03,527 - INFO - joeynmt.prediction - Generation took 0.1032[sec].\n",
            " 46%|████▌     | 677/1471 [01:30<01:35,  8.35it/s]2024-08-13 21:38:03,532 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:03,595 - INFO - joeynmt.prediction - Generation took 0.0591[sec].\n",
            "2024-08-13 21:38:03,597 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:03,660 - INFO - joeynmt.prediction - Generation took 0.0615[sec].\n",
            " 46%|████▌     | 679/1471 [01:30<01:22,  9.65it/s]2024-08-13 21:38:03,665 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:03,719 - INFO - joeynmt.prediction - Generation took 0.0515[sec].\n",
            "2024-08-13 21:38:03,722 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:03,796 - INFO - joeynmt.prediction - Generation took 0.0719[sec].\n",
            " 46%|████▋     | 681/1471 [01:30<01:13, 10.77it/s]2024-08-13 21:38:03,802 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:03,878 - INFO - joeynmt.prediction - Generation took 0.0738[sec].\n",
            "2024-08-13 21:38:03,880 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:03,942 - INFO - joeynmt.prediction - Generation took 0.0595[sec].\n",
            " 46%|████▋     | 683/1471 [01:30<01:08, 11.54it/s]2024-08-13 21:38:03,947 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:04,051 - INFO - joeynmt.prediction - Generation took 0.1017[sec].\n",
            "2024-08-13 21:38:04,054 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:04,105 - INFO - joeynmt.prediction - Generation took 0.0465[sec].\n",
            " 47%|████▋     | 685/1471 [01:30<01:06, 11.74it/s]2024-08-13 21:38:04,109 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:04,202 - INFO - joeynmt.prediction - Generation took 0.0900[sec].\n",
            "2024-08-13 21:38:04,205 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:04,264 - INFO - joeynmt.prediction - Generation took 0.0568[sec].\n",
            " 47%|████▋     | 687/1471 [01:30<01:05, 11.98it/s]2024-08-13 21:38:04,268 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:04,357 - INFO - joeynmt.prediction - Generation took 0.0869[sec].\n",
            "2024-08-13 21:38:04,358 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:04,600 - INFO - joeynmt.prediction - Generation took 0.2373[sec].\n",
            " 47%|████▋     | 689/1471 [01:31<01:25,  9.18it/s]2024-08-13 21:38:04,605 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:04,676 - INFO - joeynmt.prediction - Generation took 0.0683[sec].\n",
            "2024-08-13 21:38:04,678 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:04,730 - INFO - joeynmt.prediction - Generation took 0.0495[sec].\n",
            " 47%|████▋     | 691/1471 [01:31<01:14, 10.44it/s]2024-08-13 21:38:04,734 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:04,790 - INFO - joeynmt.prediction - Generation took 0.0535[sec].\n",
            "2024-08-13 21:38:04,792 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:04,938 - INFO - joeynmt.prediction - Generation took 0.1419[sec].\n",
            " 47%|████▋     | 693/1471 [01:31<01:16, 10.19it/s]2024-08-13 21:38:04,942 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:05,018 - INFO - joeynmt.prediction - Generation took 0.0741[sec].\n",
            "2024-08-13 21:38:05,021 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:05,088 - INFO - joeynmt.prediction - Generation took 0.0654[sec].\n",
            " 47%|████▋     | 695/1471 [01:31<01:10, 10.95it/s]2024-08-13 21:38:05,093 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:05,231 - INFO - joeynmt.prediction - Generation took 0.1350[sec].\n",
            "2024-08-13 21:38:05,233 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:05,285 - INFO - joeynmt.prediction - Generation took 0.0497[sec].\n",
            " 47%|████▋     | 697/1471 [01:31<01:12, 10.69it/s]2024-08-13 21:38:05,291 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:05,358 - INFO - joeynmt.prediction - Generation took 0.0648[sec].\n",
            "2024-08-13 21:38:05,360 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:05,440 - INFO - joeynmt.prediction - Generation took 0.0769[sec].\n",
            " 48%|████▊     | 699/1471 [01:32<01:08, 11.30it/s]2024-08-13 21:38:05,444 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:05,527 - INFO - joeynmt.prediction - Generation took 0.0810[sec].\n",
            "2024-08-13 21:38:05,530 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:05,836 - INFO - joeynmt.prediction - Generation took 0.3036[sec].\n",
            " 48%|████▊     | 701/1471 [01:32<01:33,  8.23it/s]2024-08-13 21:38:05,841 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:05,911 - INFO - joeynmt.prediction - Generation took 0.0669[sec].\n",
            "2024-08-13 21:38:05,913 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:05,987 - INFO - joeynmt.prediction - Generation took 0.0709[sec].\n",
            " 48%|████▊     | 703/1471 [01:32<01:22,  9.28it/s]2024-08-13 21:38:05,991 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:06,111 - INFO - joeynmt.prediction - Generation took 0.1176[sec].\n",
            "2024-08-13 21:38:06,113 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:06,179 - INFO - joeynmt.prediction - Generation took 0.0621[sec].\n",
            " 48%|████▊     | 705/1471 [01:32<01:19,  9.60it/s]2024-08-13 21:38:06,183 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:06,373 - INFO - joeynmt.prediction - Generation took 0.1880[sec].\n",
            "2024-08-13 21:38:06,376 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:06,438 - INFO - joeynmt.prediction - Generation took 0.0586[sec].\n",
            " 48%|████▊     | 707/1471 [01:33<01:25,  8.95it/s]2024-08-13 21:38:06,442 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:06,657 - INFO - joeynmt.prediction - Generation took 0.2127[sec].\n",
            " 48%|████▊     | 708/1471 [01:33<01:39,  7.65it/s]2024-08-13 21:38:06,661 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:06,767 - INFO - joeynmt.prediction - Generation took 0.1025[sec].\n",
            " 48%|████▊     | 709/1471 [01:33<01:36,  7.90it/s]2024-08-13 21:38:06,771 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:06,827 - INFO - joeynmt.prediction - Generation took 0.0540[sec].\n",
            "2024-08-13 21:38:06,829 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:06,884 - INFO - joeynmt.prediction - Generation took 0.0518[sec].\n",
            " 48%|████▊     | 711/1471 [01:33<01:17,  9.82it/s]2024-08-13 21:38:06,890 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:07,082 - INFO - joeynmt.prediction - Generation took 0.1884[sec].\n",
            "2024-08-13 21:38:07,084 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:07,168 - INFO - joeynmt.prediction - Generation took 0.0813[sec].\n",
            " 48%|████▊     | 713/1471 [01:33<01:27,  8.67it/s]2024-08-13 21:38:07,172 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:07,239 - INFO - joeynmt.prediction - Generation took 0.0652[sec].\n",
            "2024-08-13 21:38:07,241 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:07,407 - INFO - joeynmt.prediction - Generation took 0.1634[sec].\n",
            " 49%|████▊     | 715/1471 [01:34<01:28,  8.56it/s]2024-08-13 21:38:07,411 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:07,545 - INFO - joeynmt.prediction - Generation took 0.1310[sec].\n",
            " 49%|████▊     | 716/1471 [01:34<01:31,  8.27it/s]2024-08-13 21:38:07,549 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:07,873 - INFO - joeynmt.prediction - Generation took 0.3208[sec].\n",
            " 49%|████▊     | 717/1471 [01:34<02:04,  6.06it/s]2024-08-13 21:38:07,877 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:08,076 - INFO - joeynmt.prediction - Generation took 0.1959[sec].\n",
            " 49%|████▉     | 718/1471 [01:34<02:10,  5.75it/s]2024-08-13 21:38:08,080 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:08,165 - INFO - joeynmt.prediction - Generation took 0.0825[sec].\n",
            "2024-08-13 21:38:08,168 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:08,244 - INFO - joeynmt.prediction - Generation took 0.0739[sec].\n",
            " 49%|████▉     | 720/1471 [01:34<01:43,  7.25it/s]2024-08-13 21:38:08,248 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:08,353 - INFO - joeynmt.prediction - Generation took 0.1032[sec].\n",
            " 49%|████▉     | 721/1471 [01:34<01:38,  7.61it/s]2024-08-13 21:38:08,357 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:08,636 - INFO - joeynmt.prediction - Generation took 0.2773[sec].\n",
            " 49%|████▉     | 722/1471 [01:35<02:06,  5.93it/s]2024-08-13 21:38:08,643 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:08,703 - INFO - joeynmt.prediction - Generation took 0.0576[sec].\n",
            "2024-08-13 21:38:08,705 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:08,866 - INFO - joeynmt.prediction - Generation took 0.1587[sec].\n",
            " 49%|████▉     | 724/1471 [01:35<01:49,  6.84it/s]2024-08-13 21:38:08,870 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:09,045 - INFO - joeynmt.prediction - Generation took 0.1721[sec].\n",
            " 49%|████▉     | 725/1471 [01:35<01:54,  6.50it/s]2024-08-13 21:38:09,050 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:09,114 - INFO - joeynmt.prediction - Generation took 0.0612[sec].\n",
            "2024-08-13 21:38:09,116 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:09,189 - INFO - joeynmt.prediction - Generation took 0.0692[sec].\n",
            " 49%|████▉     | 727/1471 [01:35<01:30,  8.22it/s]2024-08-13 21:38:09,193 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:09,311 - INFO - joeynmt.prediction - Generation took 0.1158[sec].\n",
            " 49%|████▉     | 728/1471 [01:35<01:30,  8.22it/s]2024-08-13 21:38:09,316 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:09,532 - INFO - joeynmt.prediction - Generation took 0.2139[sec].\n",
            " 50%|████▉     | 729/1471 [01:36<01:47,  6.88it/s]2024-08-13 21:38:09,538 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:09,624 - INFO - joeynmt.prediction - Generation took 0.0836[sec].\n",
            "2024-08-13 21:38:09,626 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:09,719 - INFO - joeynmt.prediction - Generation took 0.0904[sec].\n",
            " 50%|████▉     | 731/1471 [01:36<01:31,  8.04it/s]2024-08-13 21:38:09,723 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:09,793 - INFO - joeynmt.prediction - Generation took 0.0662[sec].\n",
            "2024-08-13 21:38:09,796 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:09,852 - INFO - joeynmt.prediction - Generation took 0.0542[sec].\n",
            " 50%|████▉     | 733/1471 [01:36<01:16,  9.69it/s]2024-08-13 21:38:09,856 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:09,923 - INFO - joeynmt.prediction - Generation took 0.0635[sec].\n",
            "2024-08-13 21:38:09,924 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:10,005 - INFO - joeynmt.prediction - Generation took 0.0763[sec].\n",
            " 50%|████▉     | 735/1471 [01:36<01:09, 10.64it/s]2024-08-13 21:38:10,009 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:10,076 - INFO - joeynmt.prediction - Generation took 0.0647[sec].\n",
            "2024-08-13 21:38:10,078 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:10,172 - INFO - joeynmt.prediction - Generation took 0.0909[sec].\n",
            " 50%|█████     | 737/1471 [01:36<01:06, 11.04it/s]2024-08-13 21:38:10,176 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:10,269 - INFO - joeynmt.prediction - Generation took 0.0896[sec].\n",
            "2024-08-13 21:38:10,272 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:10,409 - INFO - joeynmt.prediction - Generation took 0.1338[sec].\n",
            " 50%|█████     | 739/1471 [01:37<01:12, 10.04it/s]2024-08-13 21:38:10,414 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:10,641 - INFO - joeynmt.prediction - Generation took 0.2236[sec].\n",
            "2024-08-13 21:38:10,643 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:10,747 - INFO - joeynmt.prediction - Generation took 0.1007[sec].\n",
            " 50%|█████     | 741/1471 [01:37<01:28,  8.24it/s]2024-08-13 21:38:10,752 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:10,831 - INFO - joeynmt.prediction - Generation took 0.0775[sec].\n",
            "2024-08-13 21:38:10,834 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:11,442 - INFO - joeynmt.prediction - Generation took 0.6059[sec].\n",
            " 51%|█████     | 743/1471 [01:38<02:19,  5.23it/s]2024-08-13 21:38:11,446 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:11,509 - INFO - joeynmt.prediction - Generation took 0.0594[sec].\n",
            "2024-08-13 21:38:11,511 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:11,640 - INFO - joeynmt.prediction - Generation took 0.1270[sec].\n",
            " 51%|█████     | 745/1471 [01:38<01:58,  6.13it/s]2024-08-13 21:38:11,644 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:11,725 - INFO - joeynmt.prediction - Generation took 0.0780[sec].\n",
            "2024-08-13 21:38:11,727 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:11,999 - INFO - joeynmt.prediction - Generation took 0.2689[sec].\n",
            " 51%|█████     | 747/1471 [01:38<02:01,  5.94it/s]2024-08-13 21:38:12,005 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:12,128 - INFO - joeynmt.prediction - Generation took 0.1212[sec].\n",
            " 51%|█████     | 748/1471 [01:38<01:56,  6.21it/s]2024-08-13 21:38:12,132 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:12,197 - INFO - joeynmt.prediction - Generation took 0.0632[sec].\n",
            "2024-08-13 21:38:12,200 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:12,979 - INFO - joeynmt.prediction - Generation took 0.7767[sec].\n",
            " 51%|█████     | 750/1471 [01:39<03:00,  3.99it/s]2024-08-13 21:38:12,983 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:13,108 - INFO - joeynmt.prediction - Generation took 0.1224[sec].\n",
            " 51%|█████     | 751/1471 [01:39<02:43,  4.41it/s]2024-08-13 21:38:13,116 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:13,202 - INFO - joeynmt.prediction - Generation took 0.0832[sec].\n",
            "2024-08-13 21:38:13,207 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:13,428 - INFO - joeynmt.prediction - Generation took 0.2178[sec].\n",
            " 51%|█████     | 753/1471 [01:40<02:25,  4.93it/s]2024-08-13 21:38:13,433 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:13,604 - INFO - joeynmt.prediction - Generation took 0.1680[sec].\n",
            " 51%|█████▏    | 754/1471 [01:40<02:21,  5.06it/s]2024-08-13 21:38:13,611 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:13,782 - INFO - joeynmt.prediction - Generation took 0.1686[sec].\n",
            " 51%|█████▏    | 755/1471 [01:40<02:18,  5.17it/s]2024-08-13 21:38:13,789 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:13,944 - INFO - joeynmt.prediction - Generation took 0.1515[sec].\n",
            " 51%|█████▏    | 756/1471 [01:40<02:12,  5.39it/s]2024-08-13 21:38:13,950 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:14,128 - INFO - joeynmt.prediction - Generation took 0.1754[sec].\n",
            " 51%|█████▏    | 757/1471 [01:40<02:12,  5.40it/s]2024-08-13 21:38:14,133 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:14,209 - INFO - joeynmt.prediction - Generation took 0.0734[sec].\n",
            "2024-08-13 21:38:14,211 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:14,295 - INFO - joeynmt.prediction - Generation took 0.0813[sec].\n",
            " 52%|█████▏    | 759/1471 [01:40<01:41,  7.04it/s]2024-08-13 21:38:14,300 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:14,387 - INFO - joeynmt.prediction - Generation took 0.0840[sec].\n",
            "2024-08-13 21:38:14,389 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:14,459 - INFO - joeynmt.prediction - Generation took 0.0674[sec].\n",
            " 52%|█████▏    | 761/1471 [01:41<01:24,  8.38it/s]2024-08-13 21:38:14,464 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:14,657 - INFO - joeynmt.prediction - Generation took 0.1897[sec].\n",
            " 52%|█████▏    | 762/1471 [01:41<01:36,  7.36it/s]2024-08-13 21:38:14,661 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:14,738 - INFO - joeynmt.prediction - Generation took 0.0746[sec].\n",
            "2024-08-13 21:38:14,745 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:14,868 - INFO - joeynmt.prediction - Generation took 0.1217[sec].\n",
            " 52%|█████▏    | 764/1471 [01:41<01:28,  8.03it/s]2024-08-13 21:38:14,873 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:14,939 - INFO - joeynmt.prediction - Generation took 0.0633[sec].\n",
            "2024-08-13 21:38:14,942 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:15,034 - INFO - joeynmt.prediction - Generation took 0.0901[sec].\n",
            " 52%|█████▏    | 766/1471 [01:41<01:17,  9.07it/s]2024-08-13 21:38:15,041 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:15,270 - INFO - joeynmt.prediction - Generation took 0.2274[sec].\n",
            " 52%|█████▏    | 767/1471 [01:41<01:35,  7.39it/s]2024-08-13 21:38:15,276 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:15,668 - INFO - joeynmt.prediction - Generation took 0.3899[sec].\n",
            " 52%|█████▏    | 768/1471 [01:42<02:16,  5.17it/s]2024-08-13 21:38:15,675 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:15,867 - INFO - joeynmt.prediction - Generation took 0.1901[sec].\n",
            " 52%|█████▏    | 769/1471 [01:42<02:16,  5.14it/s]2024-08-13 21:38:15,871 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:15,927 - INFO - joeynmt.prediction - Generation took 0.0543[sec].\n",
            "2024-08-13 21:38:15,929 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:15,982 - INFO - joeynmt.prediction - Generation took 0.0489[sec].\n",
            " 52%|█████▏    | 771/1471 [01:42<01:37,  7.21it/s]2024-08-13 21:38:15,986 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:16,090 - INFO - joeynmt.prediction - Generation took 0.1013[sec].\n",
            " 52%|█████▏    | 772/1471 [01:42<01:32,  7.59it/s]2024-08-13 21:38:16,095 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:16,163 - INFO - joeynmt.prediction - Generation took 0.0656[sec].\n",
            "2024-08-13 21:38:16,165 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:16,330 - INFO - joeynmt.prediction - Generation took 0.1626[sec].\n",
            " 53%|█████▎    | 774/1471 [01:42<01:28,  7.86it/s]2024-08-13 21:38:16,334 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:16,423 - INFO - joeynmt.prediction - Generation took 0.0867[sec].\n",
            "2024-08-13 21:38:16,425 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:16,547 - INFO - joeynmt.prediction - Generation took 0.1186[sec].\n",
            " 53%|█████▎    | 776/1471 [01:43<01:23,  8.30it/s]2024-08-13 21:38:16,552 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:16,623 - INFO - joeynmt.prediction - Generation took 0.0676[sec].\n",
            "2024-08-13 21:38:16,626 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:16,706 - INFO - joeynmt.prediction - Generation took 0.0784[sec].\n",
            " 53%|█████▎    | 778/1471 [01:43<01:13,  9.38it/s]2024-08-13 21:38:16,710 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:16,883 - INFO - joeynmt.prediction - Generation took 0.1708[sec].\n",
            "2024-08-13 21:38:16,886 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:16,934 - INFO - joeynmt.prediction - Generation took 0.0457[sec].\n",
            " 53%|█████▎    | 780/1471 [01:43<01:15,  9.18it/s]2024-08-13 21:38:16,938 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:17,015 - INFO - joeynmt.prediction - Generation took 0.0756[sec].\n",
            "2024-08-13 21:38:17,018 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:17,625 - INFO - joeynmt.prediction - Generation took 0.6047[sec].\n",
            " 53%|█████▎    | 782/1471 [01:44<02:06,  5.43it/s]2024-08-13 21:38:17,630 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:17,711 - INFO - joeynmt.prediction - Generation took 0.0758[sec].\n",
            "2024-08-13 21:38:17,714 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:17,927 - INFO - joeynmt.prediction - Generation took 0.2114[sec].\n",
            " 53%|█████▎    | 784/1471 [01:44<01:59,  5.75it/s]2024-08-13 21:38:17,933 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:18,009 - INFO - joeynmt.prediction - Generation took 0.0733[sec].\n",
            "2024-08-13 21:38:18,011 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:18,140 - INFO - joeynmt.prediction - Generation took 0.1259[sec].\n",
            " 53%|█████▎    | 786/1471 [01:44<01:44,  6.53it/s]2024-08-13 21:38:18,144 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:18,216 - INFO - joeynmt.prediction - Generation took 0.0691[sec].\n",
            "2024-08-13 21:38:18,218 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:18,268 - INFO - joeynmt.prediction - Generation took 0.0488[sec].\n",
            " 54%|█████▎    | 788/1471 [01:44<01:25,  7.95it/s]2024-08-13 21:38:18,274 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:18,392 - INFO - joeynmt.prediction - Generation took 0.1162[sec].\n",
            "2024-08-13 21:38:18,394 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:18,460 - INFO - joeynmt.prediction - Generation took 0.0637[sec].\n",
            " 54%|█████▎    | 790/1471 [01:45<01:19,  8.57it/s]2024-08-13 21:38:18,467 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:18,622 - INFO - joeynmt.prediction - Generation took 0.1502[sec].\n",
            "2024-08-13 21:38:18,624 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:18,741 - INFO - joeynmt.prediction - Generation took 0.1151[sec].\n",
            " 54%|█████▍    | 792/1471 [01:45<01:24,  8.07it/s]2024-08-13 21:38:18,747 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:18,850 - INFO - joeynmt.prediction - Generation took 0.0993[sec].\n",
            " 54%|█████▍    | 793/1471 [01:45<01:22,  8.25it/s]2024-08-13 21:38:18,854 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:18,951 - INFO - joeynmt.prediction - Generation took 0.0946[sec].\n",
            " 54%|█████▍    | 794/1471 [01:45<01:19,  8.55it/s]2024-08-13 21:38:18,955 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:19,064 - INFO - joeynmt.prediction - Generation took 0.1065[sec].\n",
            " 54%|█████▍    | 795/1471 [01:45<01:18,  8.61it/s]2024-08-13 21:38:19,068 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:19,139 - INFO - joeynmt.prediction - Generation took 0.0689[sec].\n",
            "2024-08-13 21:38:19,142 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:19,225 - INFO - joeynmt.prediction - Generation took 0.0803[sec].\n",
            " 54%|█████▍    | 797/1471 [01:45<01:08,  9.79it/s]2024-08-13 21:38:19,231 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:19,342 - INFO - joeynmt.prediction - Generation took 0.1067[sec].\n",
            "2024-08-13 21:38:19,345 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:19,535 - INFO - joeynmt.prediction - Generation took 0.1879[sec].\n",
            " 54%|█████▍    | 799/1471 [01:46<01:21,  8.25it/s]2024-08-13 21:38:19,539 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:19,719 - INFO - joeynmt.prediction - Generation took 0.1778[sec].\n",
            " 54%|█████▍    | 800/1471 [01:46<01:29,  7.46it/s]2024-08-13 21:38:19,724 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:19,879 - INFO - joeynmt.prediction - Generation took 0.1538[sec].\n",
            " 54%|█████▍    | 801/1471 [01:46<01:33,  7.14it/s]2024-08-13 21:38:19,884 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:19,983 - INFO - joeynmt.prediction - Generation took 0.0971[sec].\n",
            " 55%|█████▍    | 802/1471 [01:46<01:27,  7.64it/s]2024-08-13 21:38:19,988 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:20,152 - INFO - joeynmt.prediction - Generation took 0.1613[sec].\n",
            " 55%|█████▍    | 803/1471 [01:46<01:34,  7.10it/s]2024-08-13 21:38:20,156 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:20,319 - INFO - joeynmt.prediction - Generation took 0.1601[sec].\n",
            " 55%|█████▍    | 804/1471 [01:46<01:38,  6.76it/s]2024-08-13 21:38:20,323 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:20,477 - INFO - joeynmt.prediction - Generation took 0.1526[sec].\n",
            " 55%|█████▍    | 805/1471 [01:47<01:40,  6.61it/s]2024-08-13 21:38:20,484 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:20,691 - INFO - joeynmt.prediction - Generation took 0.2039[sec].\n",
            " 55%|█████▍    | 806/1471 [01:47<01:52,  5.92it/s]2024-08-13 21:38:20,697 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:20,836 - INFO - joeynmt.prediction - Generation took 0.1373[sec].\n",
            " 55%|█████▍    | 807/1471 [01:47<01:47,  6.18it/s]2024-08-13 21:38:20,841 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:21,008 - INFO - joeynmt.prediction - Generation took 0.1652[sec].\n",
            " 55%|█████▍    | 808/1471 [01:47<01:49,  6.08it/s]2024-08-13 21:38:21,013 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:21,187 - INFO - joeynmt.prediction - Generation took 0.1723[sec].\n",
            " 55%|█████▍    | 809/1471 [01:47<01:51,  5.91it/s]2024-08-13 21:38:21,194 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:21,362 - INFO - joeynmt.prediction - Generation took 0.1646[sec].\n",
            " 55%|█████▌    | 810/1471 [01:47<01:52,  5.86it/s]2024-08-13 21:38:21,366 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:21,466 - INFO - joeynmt.prediction - Generation took 0.0974[sec].\n",
            " 55%|█████▌    | 811/1471 [01:48<01:39,  6.62it/s]2024-08-13 21:38:21,472 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:21,723 - INFO - joeynmt.prediction - Generation took 0.2492[sec].\n",
            " 55%|█████▌    | 812/1471 [01:48<02:00,  5.48it/s]2024-08-13 21:38:21,727 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:21,804 - INFO - joeynmt.prediction - Generation took 0.0738[sec].\n",
            "2024-08-13 21:38:21,807 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:21,947 - INFO - joeynmt.prediction - Generation took 0.1375[sec].\n",
            " 55%|█████▌    | 814/1471 [01:48<01:38,  6.68it/s]2024-08-13 21:38:21,951 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:22,164 - INFO - joeynmt.prediction - Generation took 0.2100[sec].\n",
            " 55%|█████▌    | 815/1471 [01:48<01:49,  6.01it/s]2024-08-13 21:38:22,168 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:22,343 - INFO - joeynmt.prediction - Generation took 0.1731[sec].\n",
            " 55%|█████▌    | 816/1471 [01:48<01:51,  5.89it/s]2024-08-13 21:38:22,347 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:22,501 - INFO - joeynmt.prediction - Generation took 0.1508[sec].\n",
            " 56%|█████▌    | 817/1471 [01:49<01:49,  5.99it/s]2024-08-13 21:38:22,506 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:22,590 - INFO - joeynmt.prediction - Generation took 0.0811[sec].\n",
            "2024-08-13 21:38:22,592 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:22,819 - INFO - joeynmt.prediction - Generation took 0.2235[sec].\n",
            " 56%|█████▌    | 819/1471 [01:49<01:46,  6.12it/s]2024-08-13 21:38:22,823 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:22,935 - INFO - joeynmt.prediction - Generation took 0.1095[sec].\n",
            " 56%|█████▌    | 820/1471 [01:49<01:38,  6.58it/s]2024-08-13 21:38:22,940 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:23,153 - INFO - joeynmt.prediction - Generation took 0.2106[sec].\n",
            " 56%|█████▌    | 821/1471 [01:49<01:49,  5.93it/s]2024-08-13 21:38:23,158 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:23,323 - INFO - joeynmt.prediction - Generation took 0.1625[sec].\n",
            " 56%|█████▌    | 822/1471 [01:49<01:49,  5.91it/s]2024-08-13 21:38:23,329 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:23,837 - INFO - joeynmt.prediction - Generation took 0.5054[sec].\n",
            " 56%|█████▌    | 823/1471 [01:50<02:51,  3.79it/s]2024-08-13 21:38:23,841 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:23,929 - INFO - joeynmt.prediction - Generation took 0.0851[sec].\n",
            "2024-08-13 21:38:23,931 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:24,049 - INFO - joeynmt.prediction - Generation took 0.1153[sec].\n",
            " 56%|█████▌    | 825/1471 [01:50<02:05,  5.15it/s]2024-08-13 21:38:24,054 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:24,120 - INFO - joeynmt.prediction - Generation took 0.0628[sec].\n",
            "2024-08-13 21:38:24,122 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:24,248 - INFO - joeynmt.prediction - Generation took 0.1239[sec].\n",
            " 56%|█████▌    | 827/1471 [01:50<01:41,  6.33it/s]2024-08-13 21:38:24,252 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:24,463 - INFO - joeynmt.prediction - Generation took 0.2085[sec].\n",
            " 56%|█████▋    | 828/1471 [01:51<01:49,  5.87it/s]2024-08-13 21:38:24,468 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:24,542 - INFO - joeynmt.prediction - Generation took 0.0702[sec].\n",
            "2024-08-13 21:38:24,544 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:24,702 - INFO - joeynmt.prediction - Generation took 0.1549[sec].\n",
            " 56%|█████▋    | 830/1471 [01:51<01:36,  6.63it/s]2024-08-13 21:38:24,707 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:24,775 - INFO - joeynmt.prediction - Generation took 0.0651[sec].\n",
            "2024-08-13 21:38:24,777 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:24,889 - INFO - joeynmt.prediction - Generation took 0.1094[sec].\n",
            " 57%|█████▋    | 832/1471 [01:51<01:23,  7.65it/s]2024-08-13 21:38:24,894 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:24,995 - INFO - joeynmt.prediction - Generation took 0.0992[sec].\n",
            " 57%|█████▋    | 833/1471 [01:51<01:20,  7.95it/s]2024-08-13 21:38:25,000 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:25,092 - INFO - joeynmt.prediction - Generation took 0.0895[sec].\n",
            "2024-08-13 21:38:25,094 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:25,148 - INFO - joeynmt.prediction - Generation took 0.0510[sec].\n",
            " 57%|█████▋    | 835/1471 [01:51<01:08,  9.29it/s]2024-08-13 21:38:25,153 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:25,252 - INFO - joeynmt.prediction - Generation took 0.0961[sec].\n",
            " 57%|█████▋    | 836/1471 [01:51<01:07,  9.37it/s]2024-08-13 21:38:25,257 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:25,328 - INFO - joeynmt.prediction - Generation took 0.0681[sec].\n",
            "2024-08-13 21:38:25,330 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:25,439 - INFO - joeynmt.prediction - Generation took 0.1048[sec].\n",
            " 57%|█████▋    | 838/1471 [01:52<01:04,  9.80it/s]2024-08-13 21:38:25,445 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:25,682 - INFO - joeynmt.prediction - Generation took 0.2344[sec].\n",
            "2024-08-13 21:38:25,688 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:25,793 - INFO - joeynmt.prediction - Generation took 0.1022[sec].\n",
            " 57%|█████▋    | 840/1471 [01:52<01:20,  7.81it/s]2024-08-13 21:38:25,797 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:26,072 - INFO - joeynmt.prediction - Generation took 0.2729[sec].\n",
            " 57%|█████▋    | 841/1471 [01:52<01:39,  6.31it/s]2024-08-13 21:38:26,082 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:26,225 - INFO - joeynmt.prediction - Generation took 0.1409[sec].\n",
            " 57%|█████▋    | 842/1471 [01:52<01:39,  6.34it/s]2024-08-13 21:38:26,234 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:26,308 - INFO - joeynmt.prediction - Generation took 0.0724[sec].\n",
            "2024-08-13 21:38:26,312 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:26,435 - INFO - joeynmt.prediction - Generation took 0.1217[sec].\n",
            " 57%|█████▋    | 844/1471 [01:53<01:25,  7.33it/s]2024-08-13 21:38:26,441 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:26,539 - INFO - joeynmt.prediction - Generation took 0.0936[sec].\n",
            " 57%|█████▋    | 845/1471 [01:53<01:21,  7.72it/s]2024-08-13 21:38:26,544 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:26,641 - INFO - joeynmt.prediction - Generation took 0.0946[sec].\n",
            " 58%|█████▊    | 846/1471 [01:53<01:17,  8.10it/s]2024-08-13 21:38:26,650 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:26,957 - INFO - joeynmt.prediction - Generation took 0.3050[sec].\n",
            " 58%|█████▊    | 847/1471 [01:53<01:47,  5.80it/s]2024-08-13 21:38:26,966 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:27,094 - INFO - joeynmt.prediction - Generation took 0.1256[sec].\n",
            " 58%|█████▊    | 848/1471 [01:53<01:41,  6.16it/s]2024-08-13 21:38:27,099 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:27,193 - INFO - joeynmt.prediction - Generation took 0.0923[sec].\n",
            "2024-08-13 21:38:27,196 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:27,328 - INFO - joeynmt.prediction - Generation took 0.1299[sec].\n",
            " 58%|█████▊    | 850/1471 [01:53<01:28,  7.01it/s]2024-08-13 21:38:27,334 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:27,407 - INFO - joeynmt.prediction - Generation took 0.0699[sec].\n",
            "2024-08-13 21:38:27,410 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:27,558 - INFO - joeynmt.prediction - Generation took 0.1442[sec].\n",
            " 58%|█████▊    | 852/1471 [01:54<01:22,  7.53it/s]2024-08-13 21:38:27,567 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:27,659 - INFO - joeynmt.prediction - Generation took 0.0900[sec].\n",
            "2024-08-13 21:38:27,662 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:27,743 - INFO - joeynmt.prediction - Generation took 0.0778[sec].\n",
            " 58%|█████▊    | 854/1471 [01:54<01:12,  8.47it/s]2024-08-13 21:38:27,748 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:27,880 - INFO - joeynmt.prediction - Generation took 0.1292[sec].\n",
            " 58%|█████▊    | 855/1471 [01:54<01:14,  8.21it/s]2024-08-13 21:38:27,884 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:28,001 - INFO - joeynmt.prediction - Generation took 0.1150[sec].\n",
            " 58%|█████▊    | 856/1471 [01:54<01:15,  8.16it/s]2024-08-13 21:38:28,010 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:28,599 - INFO - joeynmt.prediction - Generation took 0.5860[sec].\n",
            " 58%|█████▊    | 857/1471 [01:55<02:25,  4.23it/s]2024-08-13 21:38:28,605 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:29,403 - INFO - joeynmt.prediction - Generation took 0.7962[sec].\n",
            " 58%|█████▊    | 858/1471 [01:56<03:54,  2.62it/s]2024-08-13 21:38:29,409 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:29,511 - INFO - joeynmt.prediction - Generation took 0.0963[sec].\n",
            " 58%|█████▊    | 859/1471 [01:56<03:08,  3.24it/s]2024-08-13 21:38:29,515 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:29,651 - INFO - joeynmt.prediction - Generation took 0.1338[sec].\n",
            " 58%|█████▊    | 860/1471 [01:56<02:39,  3.82it/s]2024-08-13 21:38:29,655 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:29,851 - INFO - joeynmt.prediction - Generation took 0.1932[sec].\n",
            " 59%|█████▊    | 861/1471 [01:56<02:28,  4.10it/s]2024-08-13 21:38:29,855 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:30,067 - INFO - joeynmt.prediction - Generation took 0.2096[sec].\n",
            " 59%|█████▊    | 862/1471 [01:56<02:23,  4.23it/s]2024-08-13 21:38:30,072 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:30,169 - INFO - joeynmt.prediction - Generation took 0.0945[sec].\n",
            " 59%|█████▊    | 863/1471 [01:56<01:59,  5.08it/s]2024-08-13 21:38:30,174 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:30,359 - INFO - joeynmt.prediction - Generation took 0.1798[sec].\n",
            " 59%|█████▊    | 864/1471 [01:56<01:58,  5.13it/s]2024-08-13 21:38:30,366 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:30,937 - INFO - joeynmt.prediction - Generation took 0.5692[sec].\n",
            " 59%|█████▉    | 865/1471 [01:57<03:06,  3.24it/s]2024-08-13 21:38:30,942 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:31,113 - INFO - joeynmt.prediction - Generation took 0.1689[sec].\n",
            " 59%|█████▉    | 866/1471 [01:57<02:42,  3.72it/s]2024-08-13 21:38:31,119 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:31,359 - INFO - joeynmt.prediction - Generation took 0.2354[sec].\n",
            " 59%|█████▉    | 867/1471 [01:57<02:38,  3.82it/s]2024-08-13 21:38:31,364 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:31,483 - INFO - joeynmt.prediction - Generation took 0.1158[sec].\n",
            " 59%|█████▉    | 868/1471 [01:58<02:13,  4.52it/s]2024-08-13 21:38:31,489 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:31,594 - INFO - joeynmt.prediction - Generation took 0.1026[sec].\n",
            " 59%|█████▉    | 869/1471 [01:58<01:52,  5.33it/s]2024-08-13 21:38:31,598 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:31,815 - INFO - joeynmt.prediction - Generation took 0.2155[sec].\n",
            " 59%|█████▉    | 870/1471 [01:58<01:59,  5.05it/s]2024-08-13 21:38:31,820 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:31,952 - INFO - joeynmt.prediction - Generation took 0.1309[sec].\n",
            " 59%|█████▉    | 871/1471 [01:58<01:47,  5.57it/s]2024-08-13 21:38:31,959 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:32,109 - INFO - joeynmt.prediction - Generation took 0.1459[sec].\n",
            " 59%|█████▉    | 872/1471 [01:58<01:43,  5.79it/s]2024-08-13 21:38:32,113 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:32,200 - INFO - joeynmt.prediction - Generation took 0.0850[sec].\n",
            "2024-08-13 21:38:32,203 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:32,458 - INFO - joeynmt.prediction - Generation took 0.2512[sec].\n",
            " 59%|█████▉    | 874/1471 [01:59<01:43,  5.76it/s]2024-08-13 21:38:32,464 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:32,696 - INFO - joeynmt.prediction - Generation took 0.2299[sec].\n",
            " 59%|█████▉    | 875/1471 [01:59<01:53,  5.27it/s]2024-08-13 21:38:32,701 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:32,899 - INFO - joeynmt.prediction - Generation took 0.1953[sec].\n",
            " 60%|█████▉    | 876/1471 [01:59<01:54,  5.19it/s]2024-08-13 21:38:32,903 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:32,969 - INFO - joeynmt.prediction - Generation took 0.0640[sec].\n",
            "2024-08-13 21:38:32,971 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:33,083 - INFO - joeynmt.prediction - Generation took 0.1099[sec].\n",
            " 60%|█████▉    | 878/1471 [01:59<01:29,  6.65it/s]2024-08-13 21:38:33,090 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:33,311 - INFO - joeynmt.prediction - Generation took 0.2181[sec].\n",
            " 60%|█████▉    | 879/1471 [01:59<01:39,  5.95it/s]2024-08-13 21:38:33,315 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:33,409 - INFO - joeynmt.prediction - Generation took 0.0914[sec].\n",
            "2024-08-13 21:38:33,411 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:33,501 - INFO - joeynmt.prediction - Generation took 0.0874[sec].\n",
            " 60%|█████▉    | 881/1471 [02:00<01:21,  7.21it/s]2024-08-13 21:38:33,508 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:33,618 - INFO - joeynmt.prediction - Generation took 0.1058[sec].\n",
            " 60%|█████▉    | 882/1471 [02:00<01:18,  7.47it/s]2024-08-13 21:38:33,622 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:33,703 - INFO - joeynmt.prediction - Generation took 0.0792[sec].\n",
            "2024-08-13 21:38:33,706 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:33,779 - INFO - joeynmt.prediction - Generation took 0.0706[sec].\n",
            " 60%|██████    | 884/1471 [02:00<01:06,  8.83it/s]2024-08-13 21:38:33,783 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:33,956 - INFO - joeynmt.prediction - Generation took 0.1694[sec].\n",
            " 60%|██████    | 885/1471 [02:00<01:14,  7.87it/s]2024-08-13 21:38:33,960 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:34,124 - INFO - joeynmt.prediction - Generation took 0.1613[sec].\n",
            " 60%|██████    | 886/1471 [02:00<01:20,  7.31it/s]2024-08-13 21:38:34,128 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:34,250 - INFO - joeynmt.prediction - Generation took 0.1198[sec].\n",
            " 60%|██████    | 887/1471 [02:00<01:18,  7.46it/s]2024-08-13 21:38:34,254 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:34,589 - INFO - joeynmt.prediction - Generation took 0.3327[sec].\n",
            " 60%|██████    | 888/1471 [02:01<01:49,  5.30it/s]2024-08-13 21:38:34,594 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:34,742 - INFO - joeynmt.prediction - Generation took 0.1461[sec].\n",
            " 60%|██████    | 889/1471 [02:01<01:44,  5.60it/s]2024-08-13 21:38:34,748 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:34,906 - INFO - joeynmt.prediction - Generation took 0.1543[sec].\n",
            " 61%|██████    | 890/1471 [02:01<01:41,  5.74it/s]2024-08-13 21:38:34,912 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:34,993 - INFO - joeynmt.prediction - Generation took 0.0771[sec].\n",
            "2024-08-13 21:38:34,994 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:35,183 - INFO - joeynmt.prediction - Generation took 0.1855[sec].\n",
            " 61%|██████    | 892/1471 [02:01<01:31,  6.31it/s]2024-08-13 21:38:35,189 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:35,281 - INFO - joeynmt.prediction - Generation took 0.0891[sec].\n",
            "2024-08-13 21:38:35,283 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:35,378 - INFO - joeynmt.prediction - Generation took 0.0913[sec].\n",
            " 61%|██████    | 894/1471 [02:01<01:17,  7.43it/s]2024-08-13 21:38:35,382 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:35,559 - INFO - joeynmt.prediction - Generation took 0.1753[sec].\n",
            " 61%|██████    | 895/1471 [02:02<01:23,  6.89it/s]2024-08-13 21:38:35,565 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:35,639 - INFO - joeynmt.prediction - Generation took 0.0712[sec].\n",
            "2024-08-13 21:38:35,641 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:35,710 - INFO - joeynmt.prediction - Generation took 0.0666[sec].\n",
            " 61%|██████    | 897/1471 [02:02<01:07,  8.46it/s]2024-08-13 21:38:35,715 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:35,792 - INFO - joeynmt.prediction - Generation took 0.0756[sec].\n",
            "2024-08-13 21:38:35,794 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:35,935 - INFO - joeynmt.prediction - Generation took 0.1392[sec].\n",
            " 61%|██████    | 899/1471 [02:02<01:06,  8.60it/s]2024-08-13 21:38:35,941 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:36,084 - INFO - joeynmt.prediction - Generation took 0.1399[sec].\n",
            " 61%|██████    | 900/1471 [02:02<01:10,  8.14it/s]2024-08-13 21:38:36,088 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:36,176 - INFO - joeynmt.prediction - Generation took 0.0856[sec].\n",
            "2024-08-13 21:38:36,178 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:36,306 - INFO - joeynmt.prediction - Generation took 0.1254[sec].\n",
            " 61%|██████▏   | 902/1471 [02:02<01:07,  8.45it/s]2024-08-13 21:38:36,310 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:36,415 - INFO - joeynmt.prediction - Generation took 0.1023[sec].\n",
            " 61%|██████▏   | 903/1471 [02:03<01:06,  8.59it/s]2024-08-13 21:38:36,419 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:36,514 - INFO - joeynmt.prediction - Generation took 0.0925[sec].\n",
            "2024-08-13 21:38:36,516 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:36,662 - INFO - joeynmt.prediction - Generation took 0.1427[sec].\n",
            " 62%|██████▏   | 905/1471 [02:03<01:07,  8.40it/s]2024-08-13 21:38:36,667 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:36,796 - INFO - joeynmt.prediction - Generation took 0.1265[sec].\n",
            " 62%|██████▏   | 906/1471 [02:03<01:09,  8.18it/s]2024-08-13 21:38:36,800 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:36,953 - INFO - joeynmt.prediction - Generation took 0.1510[sec].\n",
            " 62%|██████▏   | 907/1471 [02:03<01:13,  7.68it/s]2024-08-13 21:38:36,958 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:37,162 - INFO - joeynmt.prediction - Generation took 0.2018[sec].\n",
            " 62%|██████▏   | 908/1471 [02:03<01:24,  6.68it/s]2024-08-13 21:38:37,167 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:37,354 - INFO - joeynmt.prediction - Generation took 0.1847[sec].\n",
            " 62%|██████▏   | 909/1471 [02:03<01:30,  6.22it/s]2024-08-13 21:38:37,358 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:37,429 - INFO - joeynmt.prediction - Generation took 0.0680[sec].\n",
            "2024-08-13 21:38:37,431 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:37,584 - INFO - joeynmt.prediction - Generation took 0.1504[sec].\n",
            " 62%|██████▏   | 911/1471 [02:04<01:19,  7.07it/s]2024-08-13 21:38:37,589 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:37,800 - INFO - joeynmt.prediction - Generation took 0.2088[sec].\n",
            " 62%|██████▏   | 912/1471 [02:04<01:28,  6.30it/s]2024-08-13 21:38:37,805 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:38,004 - INFO - joeynmt.prediction - Generation took 0.1956[sec].\n",
            " 62%|██████▏   | 913/1471 [02:04<01:35,  5.87it/s]2024-08-13 21:38:38,009 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:38,142 - INFO - joeynmt.prediction - Generation took 0.1309[sec].\n",
            " 62%|██████▏   | 914/1471 [02:04<01:29,  6.19it/s]2024-08-13 21:38:38,147 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:38,224 - INFO - joeynmt.prediction - Generation took 0.0732[sec].\n",
            "2024-08-13 21:38:38,226 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:38,302 - INFO - joeynmt.prediction - Generation took 0.0739[sec].\n",
            " 62%|██████▏   | 916/1471 [02:04<01:10,  7.90it/s]2024-08-13 21:38:38,306 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:38,432 - INFO - joeynmt.prediction - Generation took 0.1243[sec].\n",
            " 62%|██████▏   | 917/1471 [02:05<01:10,  7.85it/s]2024-08-13 21:38:38,438 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:38,595 - INFO - joeynmt.prediction - Generation took 0.1546[sec].\n",
            " 62%|██████▏   | 918/1471 [02:05<01:15,  7.33it/s]2024-08-13 21:38:38,600 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:38,699 - INFO - joeynmt.prediction - Generation took 0.0972[sec].\n",
            " 62%|██████▏   | 919/1471 [02:05<01:10,  7.82it/s]2024-08-13 21:38:38,704 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:38,804 - INFO - joeynmt.prediction - Generation took 0.0976[sec].\n",
            " 63%|██████▎   | 920/1471 [02:05<01:07,  8.22it/s]2024-08-13 21:38:38,810 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:38,898 - INFO - joeynmt.prediction - Generation took 0.0852[sec].\n",
            "2024-08-13 21:38:38,900 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:38,959 - INFO - joeynmt.prediction - Generation took 0.0561[sec].\n",
            " 63%|██████▎   | 922/1471 [02:05<00:56,  9.80it/s]2024-08-13 21:38:38,963 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:39,158 - INFO - joeynmt.prediction - Generation took 0.1935[sec].\n",
            " 63%|██████▎   | 923/1471 [02:05<01:09,  7.93it/s]2024-08-13 21:38:39,166 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:39,296 - INFO - joeynmt.prediction - Generation took 0.1271[sec].\n",
            " 63%|██████▎   | 924/1471 [02:05<01:10,  7.79it/s]2024-08-13 21:38:39,304 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:39,376 - INFO - joeynmt.prediction - Generation took 0.0693[sec].\n",
            "2024-08-13 21:38:39,378 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:39,646 - INFO - joeynmt.prediction - Generation took 0.2664[sec].\n",
            " 63%|██████▎   | 926/1471 [02:06<01:20,  6.76it/s]2024-08-13 21:38:39,652 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:39,991 - INFO - joeynmt.prediction - Generation took 0.3368[sec].\n",
            " 63%|██████▎   | 927/1471 [02:06<01:45,  5.17it/s]2024-08-13 21:38:39,996 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:40,095 - INFO - joeynmt.prediction - Generation took 0.0962[sec].\n",
            " 63%|██████▎   | 928/1471 [02:06<01:33,  5.83it/s]2024-08-13 21:38:40,101 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:40,238 - INFO - joeynmt.prediction - Generation took 0.1338[sec].\n",
            " 63%|██████▎   | 929/1471 [02:06<01:28,  6.11it/s]2024-08-13 21:38:40,242 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:40,472 - INFO - joeynmt.prediction - Generation took 0.2270[sec].\n",
            " 63%|██████▎   | 930/1471 [02:07<01:38,  5.47it/s]2024-08-13 21:38:40,476 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:40,648 - INFO - joeynmt.prediction - Generation took 0.1688[sec].\n",
            " 63%|██████▎   | 931/1471 [02:07<01:37,  5.53it/s]2024-08-13 21:38:40,656 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:40,769 - INFO - joeynmt.prediction - Generation took 0.1115[sec].\n",
            " 63%|██████▎   | 932/1471 [02:07<01:28,  6.10it/s]2024-08-13 21:38:40,774 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:40,868 - INFO - joeynmt.prediction - Generation took 0.0895[sec].\n",
            "2024-08-13 21:38:40,871 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:40,964 - INFO - joeynmt.prediction - Generation took 0.0904[sec].\n",
            " 63%|██████▎   | 934/1471 [02:07<01:12,  7.45it/s]2024-08-13 21:38:40,969 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:41,106 - INFO - joeynmt.prediction - Generation took 0.1357[sec].\n",
            " 64%|██████▎   | 935/1471 [02:07<01:12,  7.36it/s]2024-08-13 21:38:41,110 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:41,297 - INFO - joeynmt.prediction - Generation took 0.1850[sec].\n",
            " 64%|██████▎   | 936/1471 [02:07<01:20,  6.66it/s]2024-08-13 21:38:41,303 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:41,634 - INFO - joeynmt.prediction - Generation took 0.3284[sec].\n",
            " 64%|██████▎   | 937/1471 [02:08<01:47,  4.98it/s]2024-08-13 21:38:41,643 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:41,742 - INFO - joeynmt.prediction - Generation took 0.0937[sec].\n",
            " 64%|██████▍   | 938/1471 [02:08<01:33,  5.71it/s]2024-08-13 21:38:41,749 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:41,939 - INFO - joeynmt.prediction - Generation took 0.1872[sec].\n",
            " 64%|██████▍   | 939/1471 [02:08<01:36,  5.53it/s]2024-08-13 21:38:41,943 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:42,016 - INFO - joeynmt.prediction - Generation took 0.0708[sec].\n",
            "2024-08-13 21:38:42,018 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:42,088 - INFO - joeynmt.prediction - Generation took 0.0675[sec].\n",
            " 64%|██████▍   | 941/1471 [02:08<01:10,  7.51it/s]2024-08-13 21:38:42,092 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:42,478 - INFO - joeynmt.prediction - Generation took 0.3835[sec].\n",
            " 64%|██████▍   | 942/1471 [02:09<01:43,  5.12it/s]2024-08-13 21:38:42,482 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:42,559 - INFO - joeynmt.prediction - Generation took 0.0739[sec].\n",
            "2024-08-13 21:38:42,561 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:42,638 - INFO - joeynmt.prediction - Generation took 0.0750[sec].\n",
            " 64%|██████▍   | 944/1471 [02:09<01:18,  6.75it/s]2024-08-13 21:38:42,642 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:42,714 - INFO - joeynmt.prediction - Generation took 0.0694[sec].\n",
            "2024-08-13 21:38:42,716 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:43,071 - INFO - joeynmt.prediction - Generation took 0.3531[sec].\n",
            " 64%|██████▍   | 946/1471 [02:09<01:31,  5.76it/s]2024-08-13 21:38:43,076 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:43,172 - INFO - joeynmt.prediction - Generation took 0.0939[sec].\n",
            " 64%|██████▍   | 947/1471 [02:09<01:23,  6.27it/s]2024-08-13 21:38:43,181 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:43,263 - INFO - joeynmt.prediction - Generation took 0.0806[sec].\n",
            "2024-08-13 21:38:43,265 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:43,563 - INFO - joeynmt.prediction - Generation took 0.2955[sec].\n",
            " 65%|██████▍   | 949/1471 [02:10<01:29,  5.82it/s]2024-08-13 21:38:43,568 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:44,027 - INFO - joeynmt.prediction - Generation took 0.4567[sec].\n",
            " 65%|██████▍   | 950/1471 [02:10<02:01,  4.28it/s]2024-08-13 21:38:44,034 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:44,097 - INFO - joeynmt.prediction - Generation took 0.0602[sec].\n",
            "2024-08-13 21:38:44,100 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:44,226 - INFO - joeynmt.prediction - Generation took 0.1239[sec].\n",
            " 65%|██████▍   | 952/1471 [02:10<01:34,  5.46it/s]2024-08-13 21:38:44,230 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:44,339 - INFO - joeynmt.prediction - Generation took 0.1063[sec].\n",
            " 65%|██████▍   | 953/1471 [02:10<01:27,  5.95it/s]2024-08-13 21:38:44,343 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:44,634 - INFO - joeynmt.prediction - Generation took 0.2869[sec].\n",
            " 65%|██████▍   | 954/1471 [02:11<01:42,  5.06it/s]2024-08-13 21:38:44,638 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:44,787 - INFO - joeynmt.prediction - Generation took 0.1466[sec].\n",
            " 65%|██████▍   | 955/1471 [02:11<01:36,  5.36it/s]2024-08-13 21:38:44,792 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:44,985 - INFO - joeynmt.prediction - Generation took 0.1890[sec].\n",
            " 65%|██████▍   | 956/1471 [02:11<01:37,  5.27it/s]2024-08-13 21:38:44,989 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:45,073 - INFO - joeynmt.prediction - Generation took 0.0819[sec].\n",
            "2024-08-13 21:38:45,076 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:45,131 - INFO - joeynmt.prediction - Generation took 0.0535[sec].\n",
            " 65%|██████▌   | 958/1471 [02:11<01:11,  7.15it/s]2024-08-13 21:38:45,135 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:45,192 - INFO - joeynmt.prediction - Generation took 0.0543[sec].\n",
            "2024-08-13 21:38:45,194 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:45,271 - INFO - joeynmt.prediction - Generation took 0.0745[sec].\n",
            " 65%|██████▌   | 960/1471 [02:11<00:57,  8.83it/s]2024-08-13 21:38:45,276 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:45,367 - INFO - joeynmt.prediction - Generation took 0.0892[sec].\n",
            "2024-08-13 21:38:45,370 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:45,500 - INFO - joeynmt.prediction - Generation took 0.1275[sec].\n",
            " 65%|██████▌   | 962/1471 [02:12<00:58,  8.75it/s]2024-08-13 21:38:45,512 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:45,621 - INFO - joeynmt.prediction - Generation took 0.1071[sec].\n",
            " 65%|██████▌   | 963/1471 [02:12<00:58,  8.71it/s]2024-08-13 21:38:45,626 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:45,771 - INFO - joeynmt.prediction - Generation took 0.1432[sec].\n",
            " 66%|██████▌   | 964/1471 [02:12<01:02,  8.15it/s]2024-08-13 21:38:45,776 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:45,844 - INFO - joeynmt.prediction - Generation took 0.0660[sec].\n",
            "2024-08-13 21:38:45,846 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:46,065 - INFO - joeynmt.prediction - Generation took 0.2166[sec].\n",
            " 66%|██████▌   | 966/1471 [02:12<01:06,  7.57it/s]2024-08-13 21:38:46,070 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:46,144 - INFO - joeynmt.prediction - Generation took 0.0722[sec].\n",
            "2024-08-13 21:38:46,147 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:46,331 - INFO - joeynmt.prediction - Generation took 0.1815[sec].\n",
            " 66%|██████▌   | 968/1471 [02:12<01:06,  7.55it/s]2024-08-13 21:38:46,336 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:46,484 - INFO - joeynmt.prediction - Generation took 0.1460[sec].\n",
            " 66%|██████▌   | 969/1471 [02:13<01:08,  7.32it/s]2024-08-13 21:38:46,488 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:46,713 - INFO - joeynmt.prediction - Generation took 0.2223[sec].\n",
            " 66%|██████▌   | 970/1471 [02:13<01:18,  6.35it/s]2024-08-13 21:38:46,718 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:46,860 - INFO - joeynmt.prediction - Generation took 0.1388[sec].\n",
            " 66%|██████▌   | 971/1471 [02:13<01:17,  6.46it/s]2024-08-13 21:38:46,864 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:46,946 - INFO - joeynmt.prediction - Generation took 0.0803[sec].\n",
            "2024-08-13 21:38:46,949 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:47,002 - INFO - joeynmt.prediction - Generation took 0.0513[sec].\n",
            " 66%|██████▌   | 973/1471 [02:13<01:00,  8.29it/s]2024-08-13 21:38:47,006 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:47,087 - INFO - joeynmt.prediction - Generation took 0.0790[sec].\n",
            "2024-08-13 21:38:47,089 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:47,171 - INFO - joeynmt.prediction - Generation took 0.0789[sec].\n",
            " 66%|██████▋   | 975/1471 [02:13<00:53,  9.35it/s]2024-08-13 21:38:47,175 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:47,364 - INFO - joeynmt.prediction - Generation took 0.1867[sec].\n",
            " 66%|██████▋   | 976/1471 [02:13<01:01,  7.99it/s]2024-08-13 21:38:47,368 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:47,449 - INFO - joeynmt.prediction - Generation took 0.0790[sec].\n",
            "2024-08-13 21:38:47,451 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:47,538 - INFO - joeynmt.prediction - Generation took 0.0846[sec].\n",
            " 66%|██████▋   | 978/1471 [02:14<00:54,  9.01it/s]2024-08-13 21:38:47,543 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:47,612 - INFO - joeynmt.prediction - Generation took 0.0672[sec].\n",
            "2024-08-13 21:38:47,614 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:47,835 - INFO - joeynmt.prediction - Generation took 0.2183[sec].\n",
            " 67%|██████▋   | 980/1471 [02:14<01:00,  8.08it/s]2024-08-13 21:38:47,839 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:48,120 - INFO - joeynmt.prediction - Generation took 0.2784[sec].\n",
            " 67%|██████▋   | 981/1471 [02:14<01:16,  6.40it/s]2024-08-13 21:38:48,126 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:48,215 - INFO - joeynmt.prediction - Generation took 0.0862[sec].\n",
            "2024-08-13 21:38:48,217 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:48,390 - INFO - joeynmt.prediction - Generation took 0.1711[sec].\n",
            " 67%|██████▋   | 983/1471 [02:15<01:12,  6.74it/s]2024-08-13 21:38:48,396 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:48,686 - INFO - joeynmt.prediction - Generation took 0.2860[sec].\n",
            " 67%|██████▋   | 984/1471 [02:15<01:27,  5.59it/s]2024-08-13 21:38:48,691 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:48,841 - INFO - joeynmt.prediction - Generation took 0.1464[sec].\n",
            " 67%|██████▋   | 985/1471 [02:15<01:24,  5.77it/s]2024-08-13 21:38:48,845 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:49,002 - INFO - joeynmt.prediction - Generation took 0.1546[sec].\n",
            " 67%|██████▋   | 986/1471 [02:15<01:22,  5.87it/s]2024-08-13 21:38:49,007 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:49,144 - INFO - joeynmt.prediction - Generation took 0.1351[sec].\n",
            " 67%|██████▋   | 987/1471 [02:15<01:18,  6.13it/s]2024-08-13 21:38:49,149 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:49,232 - INFO - joeynmt.prediction - Generation took 0.0811[sec].\n",
            "2024-08-13 21:38:49,235 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:49,331 - INFO - joeynmt.prediction - Generation took 0.0944[sec].\n",
            " 67%|██████▋   | 989/1471 [02:15<01:04,  7.49it/s]2024-08-13 21:38:49,336 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:49,516 - INFO - joeynmt.prediction - Generation took 0.1777[sec].\n",
            " 67%|██████▋   | 990/1471 [02:16<01:09,  6.88it/s]2024-08-13 21:38:49,520 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:49,584 - INFO - joeynmt.prediction - Generation took 0.0613[sec].\n",
            "2024-08-13 21:38:49,587 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:49,770 - INFO - joeynmt.prediction - Generation took 0.1807[sec].\n",
            " 67%|██████▋   | 992/1471 [02:16<01:06,  7.25it/s]2024-08-13 21:38:49,774 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:49,915 - INFO - joeynmt.prediction - Generation took 0.1389[sec].\n",
            " 68%|██████▊   | 993/1471 [02:16<01:06,  7.16it/s]2024-08-13 21:38:49,919 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:50,139 - INFO - joeynmt.prediction - Generation took 0.2175[sec].\n",
            " 68%|██████▊   | 994/1471 [02:16<01:16,  6.24it/s]2024-08-13 21:38:50,146 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:50,242 - INFO - joeynmt.prediction - Generation took 0.0923[sec].\n",
            " 68%|██████▊   | 995/1471 [02:16<01:09,  6.89it/s]2024-08-13 21:38:50,248 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:50,336 - INFO - joeynmt.prediction - Generation took 0.0851[sec].\n",
            "2024-08-13 21:38:50,339 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:50,417 - INFO - joeynmt.prediction - Generation took 0.0749[sec].\n",
            " 68%|██████▊   | 997/1471 [02:17<00:57,  8.26it/s]2024-08-13 21:38:50,422 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:50,496 - INFO - joeynmt.prediction - Generation took 0.0720[sec].\n",
            "2024-08-13 21:38:50,499 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:50,699 - INFO - joeynmt.prediction - Generation took 0.1979[sec].\n",
            " 68%|██████▊   | 999/1471 [02:17<01:00,  7.79it/s]2024-08-13 21:38:50,704 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:50,868 - INFO - joeynmt.prediction - Generation took 0.1604[sec].\n",
            " 68%|██████▊   | 1000/1471 [02:17<01:04,  7.30it/s]2024-08-13 21:38:50,872 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:50,957 - INFO - joeynmt.prediction - Generation took 0.0817[sec].\n",
            "2024-08-13 21:38:50,959 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:51,248 - INFO - joeynmt.prediction - Generation took 0.2864[sec].\n",
            " 68%|██████▊   | 1002/1471 [02:17<01:13,  6.37it/s]2024-08-13 21:38:51,252 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:51,419 - INFO - joeynmt.prediction - Generation took 0.1650[sec].\n",
            " 68%|██████▊   | 1003/1471 [02:18<01:14,  6.24it/s]2024-08-13 21:38:51,426 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:51,550 - INFO - joeynmt.prediction - Generation took 0.1206[sec].\n",
            " 68%|██████▊   | 1004/1471 [02:18<01:11,  6.53it/s]2024-08-13 21:38:51,554 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:51,705 - INFO - joeynmt.prediction - Generation took 0.1493[sec].\n",
            " 68%|██████▊   | 1005/1471 [02:18<01:11,  6.50it/s]2024-08-13 21:38:51,710 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:51,806 - INFO - joeynmt.prediction - Generation took 0.0938[sec].\n",
            " 68%|██████▊   | 1006/1471 [02:18<01:05,  7.14it/s]2024-08-13 21:38:51,812 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:51,976 - INFO - joeynmt.prediction - Generation took 0.1625[sec].\n",
            " 68%|██████▊   | 1007/1471 [02:18<01:08,  6.75it/s]2024-08-13 21:38:51,980 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:52,144 - INFO - joeynmt.prediction - Generation took 0.1609[sec].\n",
            " 69%|██████▊   | 1008/1471 [02:18<01:11,  6.51it/s]2024-08-13 21:38:52,148 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:52,226 - INFO - joeynmt.prediction - Generation took 0.0758[sec].\n",
            "2024-08-13 21:38:52,229 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:52,293 - INFO - joeynmt.prediction - Generation took 0.0625[sec].\n",
            " 69%|██████▊   | 1010/1471 [02:18<00:54,  8.45it/s]2024-08-13 21:38:52,297 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:52,518 - INFO - joeynmt.prediction - Generation took 0.2186[sec].\n",
            " 69%|██████▊   | 1011/1471 [02:19<01:06,  6.93it/s]2024-08-13 21:38:52,523 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:52,611 - INFO - joeynmt.prediction - Generation took 0.0859[sec].\n",
            "2024-08-13 21:38:52,613 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:52,711 - INFO - joeynmt.prediction - Generation took 0.0956[sec].\n",
            " 69%|██████▉   | 1013/1471 [02:19<00:57,  8.02it/s]2024-08-13 21:38:52,717 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:52,812 - INFO - joeynmt.prediction - Generation took 0.0908[sec].\n",
            " 69%|██████▉   | 1014/1471 [02:19<00:54,  8.38it/s]2024-08-13 21:38:52,816 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:52,883 - INFO - joeynmt.prediction - Generation took 0.0635[sec].\n",
            "2024-08-13 21:38:52,886 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:53,033 - INFO - joeynmt.prediction - Generation took 0.1447[sec].\n",
            " 69%|██████▉   | 1016/1471 [02:19<00:52,  8.64it/s]2024-08-13 21:38:53,037 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:53,128 - INFO - joeynmt.prediction - Generation took 0.0887[sec].\n",
            "2024-08-13 21:38:53,130 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:53,214 - INFO - joeynmt.prediction - Generation took 0.0803[sec].\n",
            " 69%|██████▉   | 1018/1471 [02:19<00:48,  9.35it/s]2024-08-13 21:38:53,219 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:53,340 - INFO - joeynmt.prediction - Generation took 0.1192[sec].\n",
            " 69%|██████▉   | 1019/1471 [02:19<00:50,  9.03it/s]2024-08-13 21:38:53,346 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:53,425 - INFO - joeynmt.prediction - Generation took 0.0772[sec].\n",
            "2024-08-13 21:38:53,431 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:53,561 - INFO - joeynmt.prediction - Generation took 0.1239[sec].\n",
            " 69%|██████▉   | 1021/1471 [02:20<00:49,  9.04it/s]2024-08-13 21:38:53,567 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:53,683 - INFO - joeynmt.prediction - Generation took 0.1144[sec].\n",
            " 69%|██████▉   | 1022/1471 [02:20<00:51,  8.79it/s]2024-08-13 21:38:53,691 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:53,759 - INFO - joeynmt.prediction - Generation took 0.0667[sec].\n",
            "2024-08-13 21:38:53,763 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:53,929 - INFO - joeynmt.prediction - Generation took 0.1627[sec].\n",
            " 70%|██████▉   | 1024/1471 [02:20<00:52,  8.58it/s]2024-08-13 21:38:53,933 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:54,032 - INFO - joeynmt.prediction - Generation took 0.0951[sec].\n",
            " 70%|██████▉   | 1025/1471 [02:20<00:50,  8.77it/s]2024-08-13 21:38:54,037 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:54,135 - INFO - joeynmt.prediction - Generation took 0.0958[sec].\n",
            " 70%|██████▉   | 1026/1471 [02:20<00:49,  9.01it/s]2024-08-13 21:38:54,141 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:54,336 - INFO - joeynmt.prediction - Generation took 0.1938[sec].\n",
            " 70%|██████▉   | 1027/1471 [02:20<00:59,  7.43it/s]2024-08-13 21:38:54,345 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:54,488 - INFO - joeynmt.prediction - Generation took 0.1379[sec].\n",
            " 70%|██████▉   | 1028/1471 [02:21<01:01,  7.24it/s]2024-08-13 21:38:54,493 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:54,590 - INFO - joeynmt.prediction - Generation took 0.0922[sec].\n",
            " 70%|██████▉   | 1029/1471 [02:21<00:56,  7.83it/s]2024-08-13 21:38:54,595 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:54,830 - INFO - joeynmt.prediction - Generation took 0.2330[sec].\n",
            " 70%|███████   | 1030/1471 [02:21<01:10,  6.28it/s]2024-08-13 21:38:54,834 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:54,930 - INFO - joeynmt.prediction - Generation took 0.0939[sec].\n",
            " 70%|███████   | 1031/1471 [02:21<01:02,  7.02it/s]2024-08-13 21:38:54,935 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:55,139 - INFO - joeynmt.prediction - Generation took 0.2025[sec].\n",
            " 70%|███████   | 1032/1471 [02:21<01:11,  6.18it/s]2024-08-13 21:38:55,144 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:55,342 - INFO - joeynmt.prediction - Generation took 0.1949[sec].\n",
            " 70%|███████   | 1033/1471 [02:21<01:16,  5.72it/s]2024-08-13 21:38:55,350 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:55,428 - INFO - joeynmt.prediction - Generation took 0.0761[sec].\n",
            "2024-08-13 21:38:55,434 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:56,331 - INFO - joeynmt.prediction - Generation took 0.8955[sec].\n",
            " 70%|███████   | 1035/1471 [02:22<02:19,  3.12it/s]2024-08-13 21:38:56,340 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:56,517 - INFO - joeynmt.prediction - Generation took 0.1743[sec].\n",
            " 70%|███████   | 1036/1471 [02:23<02:04,  3.49it/s]2024-08-13 21:38:56,522 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:56,695 - INFO - joeynmt.prediction - Generation took 0.1706[sec].\n",
            " 70%|███████   | 1037/1471 [02:23<01:52,  3.87it/s]2024-08-13 21:38:56,699 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:57,047 - INFO - joeynmt.prediction - Generation took 0.3427[sec].\n",
            " 71%|███████   | 1038/1471 [02:23<02:02,  3.52it/s]2024-08-13 21:38:57,051 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:57,254 - INFO - joeynmt.prediction - Generation took 0.2003[sec].\n",
            " 71%|███████   | 1039/1471 [02:23<01:53,  3.81it/s]2024-08-13 21:38:57,258 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:57,355 - INFO - joeynmt.prediction - Generation took 0.0949[sec].\n",
            " 71%|███████   | 1040/1471 [02:23<01:33,  4.62it/s]2024-08-13 21:38:57,360 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:57,566 - INFO - joeynmt.prediction - Generation took 0.2038[sec].\n",
            " 71%|███████   | 1041/1471 [02:24<01:32,  4.66it/s]2024-08-13 21:38:57,571 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:57,746 - INFO - joeynmt.prediction - Generation took 0.1730[sec].\n",
            " 71%|███████   | 1042/1471 [02:24<01:27,  4.89it/s]2024-08-13 21:38:57,751 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:57,942 - INFO - joeynmt.prediction - Generation took 0.1884[sec].\n",
            " 71%|███████   | 1043/1471 [02:24<01:26,  4.95it/s]2024-08-13 21:38:57,949 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:58,071 - INFO - joeynmt.prediction - Generation took 0.1206[sec].\n",
            " 71%|███████   | 1044/1471 [02:24<01:17,  5.54it/s]2024-08-13 21:38:58,076 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:58,146 - INFO - joeynmt.prediction - Generation took 0.0684[sec].\n",
            "2024-08-13 21:38:58,148 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:58,295 - INFO - joeynmt.prediction - Generation took 0.1443[sec].\n",
            " 71%|███████   | 1046/1471 [02:24<01:03,  6.71it/s]2024-08-13 21:38:58,299 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:58,556 - INFO - joeynmt.prediction - Generation took 0.2542[sec].\n",
            " 71%|███████   | 1047/1471 [02:25<01:15,  5.65it/s]2024-08-13 21:38:58,561 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:58,636 - INFO - joeynmt.prediction - Generation took 0.0702[sec].\n",
            "2024-08-13 21:38:58,638 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:58,697 - INFO - joeynmt.prediction - Generation took 0.0547[sec].\n",
            " 71%|███████▏  | 1049/1471 [02:25<00:56,  7.53it/s]2024-08-13 21:38:58,701 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:58,765 - INFO - joeynmt.prediction - Generation took 0.0616[sec].\n",
            "2024-08-13 21:38:58,768 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:58,897 - INFO - joeynmt.prediction - Generation took 0.1255[sec].\n",
            " 71%|███████▏  | 1051/1471 [02:25<00:50,  8.31it/s]2024-08-13 21:38:58,901 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:59,108 - INFO - joeynmt.prediction - Generation took 0.2047[sec].\n",
            " 72%|███████▏  | 1052/1471 [02:25<00:58,  7.17it/s]2024-08-13 21:38:59,112 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:59,287 - INFO - joeynmt.prediction - Generation took 0.1717[sec].\n",
            " 72%|███████▏  | 1053/1471 [02:25<01:02,  6.73it/s]2024-08-13 21:38:59,291 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:59,387 - INFO - joeynmt.prediction - Generation took 0.0927[sec].\n",
            "2024-08-13 21:38:59,388 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:59,459 - INFO - joeynmt.prediction - Generation took 0.0674[sec].\n",
            " 72%|███████▏  | 1055/1471 [02:26<00:51,  8.08it/s]2024-08-13 21:38:59,463 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:59,726 - INFO - joeynmt.prediction - Generation took 0.2611[sec].\n",
            " 72%|███████▏  | 1056/1471 [02:26<01:04,  6.43it/s]2024-08-13 21:38:59,731 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:59,810 - INFO - joeynmt.prediction - Generation took 0.0763[sec].\n",
            "2024-08-13 21:38:59,814 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:38:59,915 - INFO - joeynmt.prediction - Generation took 0.0993[sec].\n",
            " 72%|███████▏  | 1058/1471 [02:26<00:54,  7.58it/s]2024-08-13 21:38:59,919 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:00,185 - INFO - joeynmt.prediction - Generation took 0.2636[sec].\n",
            " 72%|███████▏  | 1059/1471 [02:26<01:06,  6.18it/s]2024-08-13 21:39:00,189 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:00,273 - INFO - joeynmt.prediction - Generation took 0.0816[sec].\n",
            "2024-08-13 21:39:00,275 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:00,380 - INFO - joeynmt.prediction - Generation took 0.1021[sec].\n",
            " 72%|███████▏  | 1061/1471 [02:26<00:56,  7.29it/s]2024-08-13 21:39:00,385 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:00,541 - INFO - joeynmt.prediction - Generation took 0.1545[sec].\n",
            " 72%|███████▏  | 1062/1471 [02:27<00:58,  7.03it/s]2024-08-13 21:39:00,546 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:00,611 - INFO - joeynmt.prediction - Generation took 0.0608[sec].\n",
            "2024-08-13 21:39:00,613 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:00,711 - INFO - joeynmt.prediction - Generation took 0.0959[sec].\n",
            " 72%|███████▏  | 1064/1471 [02:27<00:49,  8.28it/s]2024-08-13 21:39:00,717 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:00,838 - INFO - joeynmt.prediction - Generation took 0.1191[sec].\n",
            " 72%|███████▏  | 1065/1471 [02:27<00:49,  8.20it/s]2024-08-13 21:39:00,843 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:00,970 - INFO - joeynmt.prediction - Generation took 0.1249[sec].\n",
            " 72%|███████▏  | 1066/1471 [02:27<00:50,  8.06it/s]2024-08-13 21:39:00,974 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:01,121 - INFO - joeynmt.prediction - Generation took 0.1446[sec].\n",
            " 73%|███████▎  | 1067/1471 [02:27<00:52,  7.63it/s]2024-08-13 21:39:01,126 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:01,358 - INFO - joeynmt.prediction - Generation took 0.2303[sec].\n",
            " 73%|███████▎  | 1068/1471 [02:27<01:03,  6.30it/s]2024-08-13 21:39:01,363 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:01,558 - INFO - joeynmt.prediction - Generation took 0.1924[sec].\n",
            " 73%|███████▎  | 1069/1471 [02:28<01:08,  5.87it/s]2024-08-13 21:39:01,564 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:01,644 - INFO - joeynmt.prediction - Generation took 0.0775[sec].\n",
            "2024-08-13 21:39:01,646 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:01,825 - INFO - joeynmt.prediction - Generation took 0.1760[sec].\n",
            " 73%|███████▎  | 1071/1471 [02:28<01:01,  6.50it/s]2024-08-13 21:39:01,829 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:01,930 - INFO - joeynmt.prediction - Generation took 0.0971[sec].\n",
            " 73%|███████▎  | 1072/1471 [02:28<00:56,  7.02it/s]2024-08-13 21:39:01,934 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:02,117 - INFO - joeynmt.prediction - Generation took 0.1805[sec].\n",
            " 73%|███████▎  | 1073/1471 [02:28<01:01,  6.51it/s]2024-08-13 21:39:02,121 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:02,231 - INFO - joeynmt.prediction - Generation took 0.1083[sec].\n",
            " 73%|███████▎  | 1074/1471 [02:28<00:56,  6.99it/s]2024-08-13 21:39:02,235 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:02,319 - INFO - joeynmt.prediction - Generation took 0.0817[sec].\n",
            "2024-08-13 21:39:02,322 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:02,675 - INFO - joeynmt.prediction - Generation took 0.3514[sec].\n",
            " 73%|███████▎  | 1076/1471 [02:29<01:10,  5.63it/s]2024-08-13 21:39:02,681 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:02,748 - INFO - joeynmt.prediction - Generation took 0.0637[sec].\n",
            "2024-08-13 21:39:02,750 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:02,883 - INFO - joeynmt.prediction - Generation took 0.1300[sec].\n",
            " 73%|███████▎  | 1078/1471 [02:29<00:58,  6.71it/s]2024-08-13 21:39:02,887 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:02,973 - INFO - joeynmt.prediction - Generation took 0.0844[sec].\n",
            "2024-08-13 21:39:02,975 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:03,093 - INFO - joeynmt.prediction - Generation took 0.1153[sec].\n",
            " 73%|███████▎  | 1080/1471 [02:29<00:52,  7.49it/s]2024-08-13 21:39:03,097 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:03,260 - INFO - joeynmt.prediction - Generation took 0.1612[sec].\n",
            " 73%|███████▎  | 1081/1471 [02:29<00:54,  7.12it/s]2024-08-13 21:39:03,265 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:03,429 - INFO - joeynmt.prediction - Generation took 0.1619[sec].\n",
            " 74%|███████▎  | 1082/1471 [02:30<00:57,  6.82it/s]2024-08-13 21:39:03,434 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:03,621 - INFO - joeynmt.prediction - Generation took 0.1850[sec].\n",
            " 74%|███████▎  | 1083/1471 [02:30<01:01,  6.34it/s]2024-08-13 21:39:03,625 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:03,826 - INFO - joeynmt.prediction - Generation took 0.1982[sec].\n",
            " 74%|███████▎  | 1084/1471 [02:30<01:05,  5.89it/s]2024-08-13 21:39:03,830 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:03,940 - INFO - joeynmt.prediction - Generation took 0.1071[sec].\n",
            " 74%|███████▍  | 1085/1471 [02:30<00:59,  6.47it/s]2024-08-13 21:39:03,944 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:04,057 - INFO - joeynmt.prediction - Generation took 0.1109[sec].\n",
            " 74%|███████▍  | 1086/1471 [02:30<00:55,  6.92it/s]2024-08-13 21:39:04,061 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:04,211 - INFO - joeynmt.prediction - Generation took 0.1478[sec].\n",
            " 74%|███████▍  | 1087/1471 [02:30<00:56,  6.80it/s]2024-08-13 21:39:04,215 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:04,366 - INFO - joeynmt.prediction - Generation took 0.1479[sec].\n",
            " 74%|███████▍  | 1088/1471 [02:30<00:57,  6.70it/s]2024-08-13 21:39:04,371 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:04,511 - INFO - joeynmt.prediction - Generation took 0.1370[sec].\n",
            " 74%|███████▍  | 1089/1471 [02:31<00:56,  6.74it/s]2024-08-13 21:39:04,515 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:04,641 - INFO - joeynmt.prediction - Generation took 0.1235[sec].\n",
            " 74%|███████▍  | 1090/1471 [02:31<00:54,  7.00it/s]2024-08-13 21:39:04,645 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:04,723 - INFO - joeynmt.prediction - Generation took 0.0756[sec].\n",
            "2024-08-13 21:39:04,726 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:04,819 - INFO - joeynmt.prediction - Generation took 0.0914[sec].\n",
            " 74%|███████▍  | 1092/1471 [02:31<00:44,  8.45it/s]2024-08-13 21:39:04,824 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:05,106 - INFO - joeynmt.prediction - Generation took 0.2807[sec].\n",
            " 74%|███████▍  | 1093/1471 [02:31<01:00,  6.26it/s]2024-08-13 21:39:05,111 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:05,185 - INFO - joeynmt.prediction - Generation took 0.0721[sec].\n",
            "2024-08-13 21:39:05,188 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:05,247 - INFO - joeynmt.prediction - Generation took 0.0565[sec].\n",
            " 74%|███████▍  | 1095/1471 [02:31<00:46,  8.14it/s]2024-08-13 21:39:05,251 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:05,353 - INFO - joeynmt.prediction - Generation took 0.0993[sec].\n",
            " 75%|███████▍  | 1096/1471 [02:31<00:44,  8.41it/s]2024-08-13 21:39:05,357 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:05,566 - INFO - joeynmt.prediction - Generation took 0.2074[sec].\n",
            " 75%|███████▍  | 1097/1471 [02:32<00:53,  7.03it/s]2024-08-13 21:39:05,571 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:05,683 - INFO - joeynmt.prediction - Generation took 0.1099[sec].\n",
            " 75%|███████▍  | 1098/1471 [02:32<00:50,  7.38it/s]2024-08-13 21:39:05,687 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:05,825 - INFO - joeynmt.prediction - Generation took 0.1358[sec].\n",
            " 75%|███████▍  | 1099/1471 [02:32<00:51,  7.28it/s]2024-08-13 21:39:05,829 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:06,019 - INFO - joeynmt.prediction - Generation took 0.1881[sec].\n",
            " 75%|███████▍  | 1100/1471 [02:32<00:56,  6.52it/s]2024-08-13 21:39:06,024 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:06,099 - INFO - joeynmt.prediction - Generation took 0.0738[sec].\n",
            "2024-08-13 21:39:06,102 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:06,163 - INFO - joeynmt.prediction - Generation took 0.0585[sec].\n",
            " 75%|███████▍  | 1102/1471 [02:32<00:43,  8.55it/s]2024-08-13 21:39:06,167 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:06,323 - INFO - joeynmt.prediction - Generation took 0.1541[sec].\n",
            " 75%|███████▍  | 1103/1471 [02:32<00:46,  7.84it/s]2024-08-13 21:39:06,328 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:06,411 - INFO - joeynmt.prediction - Generation took 0.0806[sec].\n",
            "2024-08-13 21:39:06,414 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:06,502 - INFO - joeynmt.prediction - Generation took 0.0844[sec].\n",
            " 75%|███████▌  | 1105/1471 [02:33<00:40,  8.94it/s]2024-08-13 21:39:06,506 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:06,756 - INFO - joeynmt.prediction - Generation took 0.2466[sec].\n",
            " 75%|███████▌  | 1106/1471 [02:33<00:52,  6.94it/s]2024-08-13 21:39:06,760 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:06,844 - INFO - joeynmt.prediction - Generation took 0.0813[sec].\n",
            "2024-08-13 21:39:06,846 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:06,919 - INFO - joeynmt.prediction - Generation took 0.0703[sec].\n",
            " 75%|███████▌  | 1108/1471 [02:33<00:43,  8.37it/s]2024-08-13 21:39:06,923 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:07,009 - INFO - joeynmt.prediction - Generation took 0.0833[sec].\n",
            "2024-08-13 21:39:07,011 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:07,065 - INFO - joeynmt.prediction - Generation took 0.0515[sec].\n",
            " 75%|███████▌  | 1110/1471 [02:33<00:37,  9.73it/s]2024-08-13 21:39:07,069 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:07,131 - INFO - joeynmt.prediction - Generation took 0.0595[sec].\n",
            "2024-08-13 21:39:07,133 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:07,353 - INFO - joeynmt.prediction - Generation took 0.2177[sec].\n",
            " 76%|███████▌  | 1112/1471 [02:33<00:42,  8.50it/s]2024-08-13 21:39:07,362 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:07,470 - INFO - joeynmt.prediction - Generation took 0.1064[sec].\n",
            " 76%|███████▌  | 1113/1471 [02:34<00:41,  8.57it/s]2024-08-13 21:39:07,476 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:07,610 - INFO - joeynmt.prediction - Generation took 0.1311[sec].\n",
            " 76%|███████▌  | 1114/1471 [02:34<00:43,  8.22it/s]2024-08-13 21:39:07,615 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:07,685 - INFO - joeynmt.prediction - Generation took 0.0677[sec].\n",
            "2024-08-13 21:39:07,690 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:07,836 - INFO - joeynmt.prediction - Generation took 0.1437[sec].\n",
            " 76%|███████▌  | 1116/1471 [02:34<00:42,  8.44it/s]2024-08-13 21:39:07,841 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:08,042 - INFO - joeynmt.prediction - Generation took 0.1991[sec].\n",
            " 76%|███████▌  | 1117/1471 [02:34<00:48,  7.29it/s]2024-08-13 21:39:08,047 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:08,110 - INFO - joeynmt.prediction - Generation took 0.0609[sec].\n",
            "2024-08-13 21:39:08,112 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:08,210 - INFO - joeynmt.prediction - Generation took 0.0957[sec].\n",
            " 76%|███████▌  | 1119/1471 [02:34<00:41,  8.55it/s]2024-08-13 21:39:08,214 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:08,432 - INFO - joeynmt.prediction - Generation took 0.2161[sec].\n",
            " 76%|███████▌  | 1120/1471 [02:35<00:48,  7.17it/s]2024-08-13 21:39:08,436 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:08,540 - INFO - joeynmt.prediction - Generation took 0.0976[sec].\n",
            " 76%|███████▌  | 1121/1471 [02:35<00:46,  7.57it/s]2024-08-13 21:39:08,545 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:08,628 - INFO - joeynmt.prediction - Generation took 0.0798[sec].\n",
            "2024-08-13 21:39:08,630 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:08,732 - INFO - joeynmt.prediction - Generation took 0.0983[sec].\n",
            " 76%|███████▋  | 1123/1471 [02:35<00:40,  8.51it/s]2024-08-13 21:39:08,736 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:08,940 - INFO - joeynmt.prediction - Generation took 0.2022[sec].\n",
            " 76%|███████▋  | 1124/1471 [02:35<00:47,  7.26it/s]2024-08-13 21:39:08,944 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:09,145 - INFO - joeynmt.prediction - Generation took 0.1987[sec].\n",
            " 76%|███████▋  | 1125/1471 [02:35<00:53,  6.48it/s]2024-08-13 21:39:09,151 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:09,388 - INFO - joeynmt.prediction - Generation took 0.2342[sec].\n",
            " 77%|███████▋  | 1126/1471 [02:36<01:00,  5.66it/s]2024-08-13 21:39:09,393 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:09,523 - INFO - joeynmt.prediction - Generation took 0.1279[sec].\n",
            " 77%|███████▋  | 1127/1471 [02:36<00:56,  6.04it/s]2024-08-13 21:39:09,528 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:09,753 - INFO - joeynmt.prediction - Generation took 0.2230[sec].\n",
            " 77%|███████▋  | 1128/1471 [02:36<01:02,  5.44it/s]2024-08-13 21:39:09,759 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:10,034 - INFO - joeynmt.prediction - Generation took 0.2724[sec].\n",
            " 77%|███████▋  | 1129/1471 [02:36<01:12,  4.74it/s]2024-08-13 21:39:10,039 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:10,230 - INFO - joeynmt.prediction - Generation took 0.1872[sec].\n",
            " 77%|███████▋  | 1130/1471 [02:36<01:10,  4.84it/s]2024-08-13 21:39:10,234 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:10,534 - INFO - joeynmt.prediction - Generation took 0.2970[sec].\n",
            " 77%|███████▋  | 1131/1471 [02:37<01:19,  4.26it/s]2024-08-13 21:39:10,539 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:10,620 - INFO - joeynmt.prediction - Generation took 0.0793[sec].\n",
            "2024-08-13 21:39:10,622 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:10,749 - INFO - joeynmt.prediction - Generation took 0.1243[sec].\n",
            " 77%|███████▋  | 1133/1471 [02:37<00:59,  5.65it/s]2024-08-13 21:39:10,754 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:10,963 - INFO - joeynmt.prediction - Generation took 0.2067[sec].\n",
            " 77%|███████▋  | 1134/1471 [02:37<01:02,  5.37it/s]2024-08-13 21:39:10,969 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:11,406 - INFO - joeynmt.prediction - Generation took 0.4350[sec].\n",
            " 77%|███████▋  | 1135/1471 [02:38<01:24,  3.96it/s]2024-08-13 21:39:11,411 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:12,045 - INFO - joeynmt.prediction - Generation took 0.6317[sec].\n",
            " 77%|███████▋  | 1136/1471 [02:38<01:59,  2.80it/s]2024-08-13 21:39:12,049 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:12,130 - INFO - joeynmt.prediction - Generation took 0.0781[sec].\n",
            "2024-08-13 21:39:12,131 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:12,341 - INFO - joeynmt.prediction - Generation took 0.2059[sec].\n",
            " 77%|███████▋  | 1138/1471 [02:38<01:28,  3.76it/s]2024-08-13 21:39:12,347 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:12,398 - INFO - joeynmt.prediction - Generation took 0.0482[sec].\n",
            "2024-08-13 21:39:12,400 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:12,493 - INFO - joeynmt.prediction - Generation took 0.0899[sec].\n",
            " 77%|███████▋  | 1140/1471 [02:39<01:03,  5.18it/s]2024-08-13 21:39:12,497 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:12,587 - INFO - joeynmt.prediction - Generation took 0.0880[sec].\n",
            "2024-08-13 21:39:12,590 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:12,833 - INFO - joeynmt.prediction - Generation took 0.2394[sec].\n",
            " 78%|███████▊  | 1142/1471 [02:39<01:00,  5.41it/s]2024-08-13 21:39:12,837 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:13,011 - INFO - joeynmt.prediction - Generation took 0.1705[sec].\n",
            " 78%|███████▊  | 1143/1471 [02:39<01:00,  5.45it/s]2024-08-13 21:39:13,015 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:13,217 - INFO - joeynmt.prediction - Generation took 0.1995[sec].\n",
            " 78%|███████▊  | 1144/1471 [02:39<01:01,  5.30it/s]2024-08-13 21:39:13,222 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:13,413 - INFO - joeynmt.prediction - Generation took 0.1881[sec].\n",
            " 78%|███████▊  | 1145/1471 [02:40<01:02,  5.26it/s]2024-08-13 21:39:13,417 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:13,510 - INFO - joeynmt.prediction - Generation took 0.0905[sec].\n",
            "2024-08-13 21:39:13,514 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:13,697 - INFO - joeynmt.prediction - Generation took 0.1798[sec].\n",
            " 78%|███████▊  | 1147/1471 [02:40<00:55,  5.85it/s]2024-08-13 21:39:13,704 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:13,767 - INFO - joeynmt.prediction - Generation took 0.0601[sec].\n",
            "2024-08-13 21:39:13,770 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:13,825 - INFO - joeynmt.prediction - Generation took 0.0519[sec].\n",
            " 78%|███████▊  | 1149/1471 [02:40<00:42,  7.63it/s]2024-08-13 21:39:13,829 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:14,051 - INFO - joeynmt.prediction - Generation took 0.2207[sec].\n",
            " 78%|███████▊  | 1150/1471 [02:40<00:48,  6.62it/s]2024-08-13 21:39:14,056 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:14,257 - INFO - joeynmt.prediction - Generation took 0.1968[sec].\n",
            " 78%|███████▊  | 1151/1471 [02:40<00:52,  6.11it/s]2024-08-13 21:39:14,261 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:14,340 - INFO - joeynmt.prediction - Generation took 0.0771[sec].\n",
            "2024-08-13 21:39:14,342 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:14,387 - INFO - joeynmt.prediction - Generation took 0.0424[sec].\n",
            " 78%|███████▊  | 1153/1471 [02:41<00:39,  8.03it/s]2024-08-13 21:39:14,392 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:14,472 - INFO - joeynmt.prediction - Generation took 0.0781[sec].\n",
            "2024-08-13 21:39:14,475 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:14,550 - INFO - joeynmt.prediction - Generation took 0.0713[sec].\n",
            " 79%|███████▊  | 1155/1471 [02:41<00:34,  9.17it/s]2024-08-13 21:39:14,557 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:14,634 - INFO - joeynmt.prediction - Generation took 0.0742[sec].\n",
            "2024-08-13 21:39:14,636 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:14,699 - INFO - joeynmt.prediction - Generation took 0.0607[sec].\n",
            " 79%|███████▊  | 1157/1471 [02:41<00:30, 10.29it/s]2024-08-13 21:39:14,704 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:14,853 - INFO - joeynmt.prediction - Generation took 0.1465[sec].\n",
            "2024-08-13 21:39:14,855 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:14,922 - INFO - joeynmt.prediction - Generation took 0.0643[sec].\n",
            " 79%|███████▉  | 1159/1471 [02:41<00:31,  9.81it/s]2024-08-13 21:39:14,926 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:15,012 - INFO - joeynmt.prediction - Generation took 0.0836[sec].\n",
            "2024-08-13 21:39:15,015 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:15,092 - INFO - joeynmt.prediction - Generation took 0.0748[sec].\n",
            " 79%|███████▉  | 1161/1471 [02:41<00:29, 10.37it/s]2024-08-13 21:39:15,096 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:15,174 - INFO - joeynmt.prediction - Generation took 0.0760[sec].\n",
            "2024-08-13 21:39:15,175 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:15,248 - INFO - joeynmt.prediction - Generation took 0.0692[sec].\n",
            " 79%|███████▉  | 1163/1471 [02:41<00:27, 11.04it/s]2024-08-13 21:39:15,252 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:15,332 - INFO - joeynmt.prediction - Generation took 0.0777[sec].\n",
            "2024-08-13 21:39:15,334 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:15,454 - INFO - joeynmt.prediction - Generation took 0.1172[sec].\n",
            " 79%|███████▉  | 1165/1471 [02:42<00:28, 10.58it/s]2024-08-13 21:39:15,459 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:15,624 - INFO - joeynmt.prediction - Generation took 0.1587[sec].\n",
            "2024-08-13 21:39:15,626 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:15,765 - INFO - joeynmt.prediction - Generation took 0.1360[sec].\n",
            " 79%|███████▉  | 1167/1471 [02:42<00:34,  8.83it/s]2024-08-13 21:39:15,770 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:15,910 - INFO - joeynmt.prediction - Generation took 0.1364[sec].\n",
            " 79%|███████▉  | 1168/1471 [02:42<00:35,  8.42it/s]2024-08-13 21:39:15,914 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:16,114 - INFO - joeynmt.prediction - Generation took 0.1986[sec].\n",
            " 79%|███████▉  | 1169/1471 [02:42<00:41,  7.33it/s]2024-08-13 21:39:16,119 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:16,257 - INFO - joeynmt.prediction - Generation took 0.1360[sec].\n",
            " 80%|███████▉  | 1170/1471 [02:42<00:41,  7.27it/s]2024-08-13 21:39:16,262 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:16,509 - INFO - joeynmt.prediction - Generation took 0.2452[sec].\n",
            " 80%|███████▉  | 1171/1471 [02:43<00:49,  6.03it/s]2024-08-13 21:39:16,515 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:16,694 - INFO - joeynmt.prediction - Generation took 0.1766[sec].\n",
            " 80%|███████▉  | 1172/1471 [02:43<00:51,  5.86it/s]2024-08-13 21:39:16,699 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:16,880 - INFO - joeynmt.prediction - Generation took 0.1782[sec].\n",
            " 80%|███████▉  | 1173/1471 [02:43<00:52,  5.72it/s]2024-08-13 21:39:16,885 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:17,517 - INFO - joeynmt.prediction - Generation took 0.6300[sec].\n",
            " 80%|███████▉  | 1174/1471 [02:44<01:30,  3.30it/s]2024-08-13 21:39:17,521 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:17,646 - INFO - joeynmt.prediction - Generation took 0.1224[sec].\n",
            " 80%|███████▉  | 1175/1471 [02:44<01:15,  3.94it/s]2024-08-13 21:39:17,650 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:17,867 - INFO - joeynmt.prediction - Generation took 0.2141[sec].\n",
            " 80%|███████▉  | 1176/1471 [02:44<01:12,  4.09it/s]2024-08-13 21:39:17,871 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:18,001 - INFO - joeynmt.prediction - Generation took 0.1281[sec].\n",
            " 80%|████████  | 1177/1471 [02:44<01:02,  4.71it/s]2024-08-13 21:39:18,005 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:18,105 - INFO - joeynmt.prediction - Generation took 0.0968[sec].\n",
            " 80%|████████  | 1178/1471 [02:44<00:52,  5.55it/s]2024-08-13 21:39:18,109 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:18,197 - INFO - joeynmt.prediction - Generation took 0.0850[sec].\n",
            "2024-08-13 21:39:18,199 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:18,352 - INFO - joeynmt.prediction - Generation took 0.1503[sec].\n",
            " 80%|████████  | 1180/1471 [02:44<00:44,  6.48it/s]2024-08-13 21:39:18,356 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:18,476 - INFO - joeynmt.prediction - Generation took 0.1181[sec].\n",
            " 80%|████████  | 1181/1471 [02:45<00:42,  6.80it/s]2024-08-13 21:39:18,481 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:18,568 - INFO - joeynmt.prediction - Generation took 0.0841[sec].\n",
            "2024-08-13 21:39:18,571 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:18,629 - INFO - joeynmt.prediction - Generation took 0.0555[sec].\n",
            " 80%|████████  | 1183/1471 [02:45<00:33,  8.50it/s]2024-08-13 21:39:18,633 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:18,731 - INFO - joeynmt.prediction - Generation took 0.0957[sec].\n",
            " 80%|████████  | 1184/1471 [02:45<00:32,  8.76it/s]2024-08-13 21:39:18,735 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:18,833 - INFO - joeynmt.prediction - Generation took 0.0960[sec].\n",
            " 81%|████████  | 1185/1471 [02:45<00:31,  8.99it/s]2024-08-13 21:39:18,837 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:18,903 - INFO - joeynmt.prediction - Generation took 0.0635[sec].\n",
            "2024-08-13 21:39:18,905 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:18,998 - INFO - joeynmt.prediction - Generation took 0.0907[sec].\n",
            " 81%|████████  | 1187/1471 [02:45<00:28, 10.06it/s]2024-08-13 21:39:19,003 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:19,108 - INFO - joeynmt.prediction - Generation took 0.1028[sec].\n",
            "2024-08-13 21:39:19,110 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:19,198 - INFO - joeynmt.prediction - Generation took 0.0854[sec].\n",
            " 81%|████████  | 1189/1471 [02:45<00:28, 10.05it/s]2024-08-13 21:39:19,202 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:19,284 - INFO - joeynmt.prediction - Generation took 0.0793[sec].\n",
            "2024-08-13 21:39:19,286 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:19,410 - INFO - joeynmt.prediction - Generation took 0.1213[sec].\n",
            " 81%|████████  | 1191/1471 [02:46<00:28,  9.82it/s]2024-08-13 21:39:19,414 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:19,496 - INFO - joeynmt.prediction - Generation took 0.0795[sec].\n",
            "2024-08-13 21:39:19,499 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:19,693 - INFO - joeynmt.prediction - Generation took 0.1923[sec].\n",
            " 81%|████████  | 1193/1471 [02:46<00:31,  8.70it/s]2024-08-13 21:39:19,700 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:19,772 - INFO - joeynmt.prediction - Generation took 0.0697[sec].\n",
            "2024-08-13 21:39:19,774 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:20,151 - INFO - joeynmt.prediction - Generation took 0.3750[sec].\n",
            " 81%|████████  | 1195/1471 [02:46<00:41,  6.60it/s]2024-08-13 21:39:20,155 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:20,219 - INFO - joeynmt.prediction - Generation took 0.0616[sec].\n",
            "2024-08-13 21:39:20,221 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:20,447 - INFO - joeynmt.prediction - Generation took 0.2237[sec].\n",
            " 81%|████████▏ | 1197/1471 [02:47<00:41,  6.64it/s]2024-08-13 21:39:20,453 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:20,527 - INFO - joeynmt.prediction - Generation took 0.0712[sec].\n",
            "2024-08-13 21:39:20,530 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:20,584 - INFO - joeynmt.prediction - Generation took 0.0516[sec].\n",
            " 82%|████████▏ | 1199/1471 [02:47<00:34,  8.00it/s]2024-08-13 21:39:20,589 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:20,664 - INFO - joeynmt.prediction - Generation took 0.0727[sec].\n",
            "2024-08-13 21:39:20,666 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:20,741 - INFO - joeynmt.prediction - Generation took 0.0714[sec].\n",
            " 82%|████████▏ | 1201/1471 [02:47<00:29,  9.03it/s]2024-08-13 21:39:20,747 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:20,818 - INFO - joeynmt.prediction - Generation took 0.0672[sec].\n",
            "2024-08-13 21:39:20,820 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:20,876 - INFO - joeynmt.prediction - Generation took 0.0540[sec].\n",
            " 82%|████████▏ | 1203/1471 [02:47<00:26, 10.25it/s]2024-08-13 21:39:20,880 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:20,973 - INFO - joeynmt.prediction - Generation took 0.0905[sec].\n",
            "2024-08-13 21:39:20,976 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:21,061 - INFO - joeynmt.prediction - Generation took 0.0813[sec].\n",
            " 82%|████████▏ | 1205/1471 [02:47<00:25, 10.42it/s]2024-08-13 21:39:21,065 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:21,137 - INFO - joeynmt.prediction - Generation took 0.0699[sec].\n",
            "2024-08-13 21:39:21,139 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:21,207 - INFO - joeynmt.prediction - Generation took 0.0651[sec].\n",
            " 82%|████████▏ | 1207/1471 [02:47<00:23, 11.24it/s]2024-08-13 21:39:21,211 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:21,269 - INFO - joeynmt.prediction - Generation took 0.0565[sec].\n",
            "2024-08-13 21:39:21,271 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:21,343 - INFO - joeynmt.prediction - Generation took 0.0686[sec].\n",
            " 82%|████████▏ | 1209/1471 [02:47<00:21, 12.10it/s]2024-08-13 21:39:21,347 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:21,417 - INFO - joeynmt.prediction - Generation took 0.0682[sec].\n",
            "2024-08-13 21:39:21,419 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:21,576 - INFO - joeynmt.prediction - Generation took 0.1528[sec].\n",
            " 82%|████████▏ | 1211/1471 [02:48<00:24, 10.74it/s]2024-08-13 21:39:21,583 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:21,755 - INFO - joeynmt.prediction - Generation took 0.1685[sec].\n",
            "2024-08-13 21:39:21,757 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:21,825 - INFO - joeynmt.prediction - Generation took 0.0651[sec].\n",
            " 82%|████████▏ | 1213/1471 [02:48<00:26,  9.77it/s]2024-08-13 21:39:21,831 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:21,997 - INFO - joeynmt.prediction - Generation took 0.1614[sec].\n",
            "2024-08-13 21:39:22,000 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:22,092 - INFO - joeynmt.prediction - Generation took 0.0894[sec].\n",
            " 83%|████████▎ | 1215/1471 [02:48<00:28,  8.96it/s]2024-08-13 21:39:22,095 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:22,257 - INFO - joeynmt.prediction - Generation took 0.1595[sec].\n",
            " 83%|████████▎ | 1216/1471 [02:48<00:30,  8.25it/s]2024-08-13 21:39:22,262 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:22,332 - INFO - joeynmt.prediction - Generation took 0.0685[sec].\n",
            "2024-08-13 21:39:22,334 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:22,420 - INFO - joeynmt.prediction - Generation took 0.0835[sec].\n",
            " 83%|████████▎ | 1218/1471 [02:49<00:27,  9.27it/s]2024-08-13 21:39:22,424 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:22,583 - INFO - joeynmt.prediction - Generation took 0.1567[sec].\n",
            " 83%|████████▎ | 1219/1471 [02:49<00:29,  8.43it/s]2024-08-13 21:39:22,587 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:22,687 - INFO - joeynmt.prediction - Generation took 0.0959[sec].\n",
            " 83%|████████▎ | 1220/1471 [02:49<00:29,  8.62it/s]2024-08-13 21:39:22,694 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:22,820 - INFO - joeynmt.prediction - Generation took 0.1247[sec].\n",
            " 83%|████████▎ | 1221/1471 [02:49<00:29,  8.38it/s]2024-08-13 21:39:22,824 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:22,906 - INFO - joeynmt.prediction - Generation took 0.0803[sec].\n",
            "2024-08-13 21:39:22,909 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:22,976 - INFO - joeynmt.prediction - Generation took 0.0639[sec].\n",
            " 83%|████████▎ | 1223/1471 [02:49<00:25,  9.75it/s]2024-08-13 21:39:22,980 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:23,040 - INFO - joeynmt.prediction - Generation took 0.0573[sec].\n",
            "2024-08-13 21:39:23,042 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:23,220 - INFO - joeynmt.prediction - Generation took 0.1756[sec].\n",
            " 83%|████████▎ | 1225/1471 [02:49<00:27,  9.10it/s]2024-08-13 21:39:23,226 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:23,385 - INFO - joeynmt.prediction - Generation took 0.1574[sec].\n",
            " 83%|████████▎ | 1226/1471 [02:50<00:29,  8.24it/s]2024-08-13 21:39:23,393 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:23,559 - INFO - joeynmt.prediction - Generation took 0.1630[sec].\n",
            " 83%|████████▎ | 1227/1471 [02:50<00:32,  7.47it/s]2024-08-13 21:39:23,566 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:23,650 - INFO - joeynmt.prediction - Generation took 0.0819[sec].\n",
            "2024-08-13 21:39:23,654 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:23,889 - INFO - joeynmt.prediction - Generation took 0.2330[sec].\n",
            " 84%|████████▎ | 1229/1471 [02:50<00:35,  6.87it/s]2024-08-13 21:39:23,896 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:23,998 - INFO - joeynmt.prediction - Generation took 0.0997[sec].\n",
            " 84%|████████▎ | 1230/1471 [02:50<00:33,  7.25it/s]2024-08-13 21:39:24,004 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:24,242 - INFO - joeynmt.prediction - Generation took 0.2329[sec].\n",
            " 84%|████████▎ | 1231/1471 [02:50<00:39,  6.12it/s]2024-08-13 21:39:24,251 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:24,365 - INFO - joeynmt.prediction - Generation took 0.1111[sec].\n",
            " 84%|████████▍ | 1232/1471 [02:50<00:36,  6.51it/s]2024-08-13 21:39:24,373 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:24,733 - INFO - joeynmt.prediction - Generation took 0.3567[sec].\n",
            " 84%|████████▍ | 1233/1471 [02:51<00:50,  4.75it/s]2024-08-13 21:39:24,742 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:24,884 - INFO - joeynmt.prediction - Generation took 0.1402[sec].\n",
            " 84%|████████▍ | 1234/1471 [02:51<00:45,  5.17it/s]2024-08-13 21:39:24,889 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:25,095 - INFO - joeynmt.prediction - Generation took 0.2043[sec].\n",
            " 84%|████████▍ | 1235/1471 [02:51<00:46,  5.04it/s]2024-08-13 21:39:25,100 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:25,156 - INFO - joeynmt.prediction - Generation took 0.0534[sec].\n",
            "2024-08-13 21:39:25,159 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:25,418 - INFO - joeynmt.prediction - Generation took 0.2574[sec].\n",
            " 84%|████████▍ | 1237/1471 [02:52<00:42,  5.49it/s]2024-08-13 21:39:25,424 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:25,587 - INFO - joeynmt.prediction - Generation took 0.1604[sec].\n",
            " 84%|████████▍ | 1238/1471 [02:52<00:41,  5.59it/s]2024-08-13 21:39:25,593 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:25,669 - INFO - joeynmt.prediction - Generation took 0.0745[sec].\n",
            "2024-08-13 21:39:25,675 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:25,857 - INFO - joeynmt.prediction - Generation took 0.1800[sec].\n",
            " 84%|████████▍ | 1240/1471 [02:52<00:37,  6.21it/s]2024-08-13 21:39:25,863 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:26,099 - INFO - joeynmt.prediction - Generation took 0.2345[sec].\n",
            " 84%|████████▍ | 1241/1471 [02:52<00:41,  5.57it/s]2024-08-13 21:39:26,106 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:26,177 - INFO - joeynmt.prediction - Generation took 0.0680[sec].\n",
            "2024-08-13 21:39:26,181 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:26,478 - INFO - joeynmt.prediction - Generation took 0.2958[sec].\n",
            " 85%|████████▍ | 1243/1471 [02:53<00:41,  5.45it/s]2024-08-13 21:39:26,485 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:26,659 - INFO - joeynmt.prediction - Generation took 0.1720[sec].\n",
            " 85%|████████▍ | 1244/1471 [02:53<00:41,  5.49it/s]2024-08-13 21:39:26,663 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:26,809 - INFO - joeynmt.prediction - Generation took 0.1443[sec].\n",
            " 85%|████████▍ | 1245/1471 [02:53<00:39,  5.72it/s]2024-08-13 21:39:26,814 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:27,002 - INFO - joeynmt.prediction - Generation took 0.1837[sec].\n",
            " 85%|████████▍ | 1246/1471 [02:53<00:40,  5.57it/s]2024-08-13 21:39:27,009 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:27,183 - INFO - joeynmt.prediction - Generation took 0.1699[sec].\n",
            " 85%|████████▍ | 1247/1471 [02:53<00:40,  5.56it/s]2024-08-13 21:39:27,187 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:27,413 - INFO - joeynmt.prediction - Generation took 0.2236[sec].\n",
            " 85%|████████▍ | 1248/1471 [02:54<00:43,  5.17it/s]2024-08-13 21:39:27,418 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:27,557 - INFO - joeynmt.prediction - Generation took 0.1362[sec].\n",
            " 85%|████████▍ | 1249/1471 [02:54<00:39,  5.56it/s]2024-08-13 21:39:27,562 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:27,690 - INFO - joeynmt.prediction - Generation took 0.1250[sec].\n",
            " 85%|████████▍ | 1250/1471 [02:54<00:36,  6.02it/s]2024-08-13 21:39:27,695 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:27,890 - INFO - joeynmt.prediction - Generation took 0.1929[sec].\n",
            " 85%|████████▌ | 1251/1471 [02:54<00:38,  5.68it/s]2024-08-13 21:39:27,894 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:28,057 - INFO - joeynmt.prediction - Generation took 0.1578[sec].\n",
            " 85%|████████▌ | 1252/1471 [02:54<00:38,  5.76it/s]2024-08-13 21:39:28,062 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:28,256 - INFO - joeynmt.prediction - Generation took 0.1911[sec].\n",
            " 85%|████████▌ | 1253/1471 [02:54<00:39,  5.53it/s]2024-08-13 21:39:28,261 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:28,405 - INFO - joeynmt.prediction - Generation took 0.1410[sec].\n",
            " 85%|████████▌ | 1254/1471 [02:55<00:37,  5.83it/s]2024-08-13 21:39:28,410 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:28,613 - INFO - joeynmt.prediction - Generation took 0.1999[sec].\n",
            " 85%|████████▌ | 1255/1471 [02:55<00:39,  5.47it/s]2024-08-13 21:39:28,620 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:28,734 - INFO - joeynmt.prediction - Generation took 0.1092[sec].\n",
            " 85%|████████▌ | 1256/1471 [02:55<00:35,  6.11it/s]2024-08-13 21:39:28,738 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:28,946 - INFO - joeynmt.prediction - Generation took 0.2056[sec].\n",
            " 85%|████████▌ | 1257/1471 [02:55<00:38,  5.61it/s]2024-08-13 21:39:28,950 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:29,110 - INFO - joeynmt.prediction - Generation took 0.1584[sec].\n",
            " 86%|████████▌ | 1258/1471 [02:55<00:37,  5.75it/s]2024-08-13 21:39:29,115 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:29,337 - INFO - joeynmt.prediction - Generation took 0.2192[sec].\n",
            " 86%|████████▌ | 1259/1471 [02:55<00:40,  5.27it/s]2024-08-13 21:39:29,341 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:29,517 - INFO - joeynmt.prediction - Generation took 0.1728[sec].\n",
            " 86%|████████▌ | 1260/1471 [02:56<00:39,  5.35it/s]2024-08-13 21:39:29,522 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:29,609 - INFO - joeynmt.prediction - Generation took 0.0853[sec].\n",
            "2024-08-13 21:39:29,611 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:29,794 - INFO - joeynmt.prediction - Generation took 0.1802[sec].\n",
            " 86%|████████▌ | 1262/1471 [02:56<00:34,  6.08it/s]2024-08-13 21:39:29,798 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:29,909 - INFO - joeynmt.prediction - Generation took 0.1094[sec].\n",
            " 86%|████████▌ | 1263/1471 [02:56<00:31,  6.56it/s]2024-08-13 21:39:29,914 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:30,065 - INFO - joeynmt.prediction - Generation took 0.1493[sec].\n",
            " 86%|████████▌ | 1264/1471 [02:56<00:31,  6.52it/s]2024-08-13 21:39:30,070 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:30,291 - INFO - joeynmt.prediction - Generation took 0.2188[sec].\n",
            " 86%|████████▌ | 1265/1471 [02:56<00:35,  5.78it/s]2024-08-13 21:39:30,295 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:30,470 - INFO - joeynmt.prediction - Generation took 0.1719[sec].\n",
            " 86%|████████▌ | 1266/1471 [02:57<00:35,  5.72it/s]2024-08-13 21:39:30,476 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:30,772 - INFO - joeynmt.prediction - Generation took 0.2921[sec].\n",
            " 86%|████████▌ | 1267/1471 [02:57<00:42,  4.74it/s]2024-08-13 21:39:30,778 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:30,904 - INFO - joeynmt.prediction - Generation took 0.1242[sec].\n",
            " 86%|████████▌ | 1268/1471 [02:57<00:38,  5.31it/s]2024-08-13 21:39:30,909 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:31,066 - INFO - joeynmt.prediction - Generation took 0.1540[sec].\n",
            " 86%|████████▋ | 1269/1471 [02:57<00:36,  5.55it/s]2024-08-13 21:39:31,070 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:31,133 - INFO - joeynmt.prediction - Generation took 0.0611[sec].\n",
            "2024-08-13 21:39:31,136 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:31,228 - INFO - joeynmt.prediction - Generation took 0.0901[sec].\n",
            " 86%|████████▋ | 1271/1471 [02:57<00:27,  7.40it/s]2024-08-13 21:39:31,232 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:31,309 - INFO - joeynmt.prediction - Generation took 0.0739[sec].\n",
            "2024-08-13 21:39:31,311 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:31,366 - INFO - joeynmt.prediction - Generation took 0.0524[sec].\n",
            " 87%|████████▋ | 1273/1471 [02:57<00:21,  9.16it/s]2024-08-13 21:39:31,370 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:31,982 - INFO - joeynmt.prediction - Generation took 0.6096[sec].\n",
            " 87%|████████▋ | 1274/1471 [02:58<00:43,  4.53it/s]2024-08-13 21:39:31,988 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:32,042 - INFO - joeynmt.prediction - Generation took 0.0512[sec].\n",
            "2024-08-13 21:39:32,044 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:32,213 - INFO - joeynmt.prediction - Generation took 0.1664[sec].\n",
            " 87%|████████▋ | 1276/1471 [02:58<00:35,  5.56it/s]2024-08-13 21:39:32,217 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:32,408 - INFO - joeynmt.prediction - Generation took 0.1891[sec].\n",
            " 87%|████████▋ | 1277/1471 [02:59<00:35,  5.46it/s]2024-08-13 21:39:32,412 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:32,534 - INFO - joeynmt.prediction - Generation took 0.1199[sec].\n",
            " 87%|████████▋ | 1278/1471 [02:59<00:32,  5.88it/s]2024-08-13 21:39:32,539 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:32,627 - INFO - joeynmt.prediction - Generation took 0.0845[sec].\n",
            "2024-08-13 21:39:32,629 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:32,699 - INFO - joeynmt.prediction - Generation took 0.0668[sec].\n",
            " 87%|████████▋ | 1280/1471 [02:59<00:25,  7.44it/s]2024-08-13 21:39:32,702 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:32,802 - INFO - joeynmt.prediction - Generation took 0.0972[sec].\n",
            " 87%|████████▋ | 1281/1471 [02:59<00:24,  7.84it/s]2024-08-13 21:39:32,806 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:32,897 - INFO - joeynmt.prediction - Generation took 0.0886[sec].\n",
            "2024-08-13 21:39:32,899 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:33,176 - INFO - joeynmt.prediction - Generation took 0.2738[sec].\n",
            " 87%|████████▋ | 1283/1471 [02:59<00:28,  6.63it/s]2024-08-13 21:39:33,182 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:33,246 - INFO - joeynmt.prediction - Generation took 0.0611[sec].\n",
            "2024-08-13 21:39:33,249 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:33,402 - INFO - joeynmt.prediction - Generation took 0.1506[sec].\n",
            " 87%|████████▋ | 1285/1471 [03:00<00:25,  7.28it/s]2024-08-13 21:39:33,407 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:33,497 - INFO - joeynmt.prediction - Generation took 0.0883[sec].\n",
            "2024-08-13 21:39:33,499 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:33,698 - INFO - joeynmt.prediction - Generation took 0.1969[sec].\n",
            " 87%|████████▋ | 1287/1471 [03:00<00:25,  7.10it/s]2024-08-13 21:39:33,703 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:33,792 - INFO - joeynmt.prediction - Generation took 0.0872[sec].\n",
            "2024-08-13 21:39:33,795 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:33,870 - INFO - joeynmt.prediction - Generation took 0.0727[sec].\n",
            " 88%|████████▊ | 1289/1471 [03:00<00:22,  8.13it/s]2024-08-13 21:39:33,874 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:33,972 - INFO - joeynmt.prediction - Generation took 0.0952[sec].\n",
            " 88%|████████▊ | 1290/1471 [03:00<00:21,  8.41it/s]2024-08-13 21:39:33,976 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:34,153 - INFO - joeynmt.prediction - Generation took 0.1746[sec].\n",
            " 88%|████████▊ | 1291/1471 [03:00<00:23,  7.57it/s]2024-08-13 21:39:34,157 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:34,509 - INFO - joeynmt.prediction - Generation took 0.3497[sec].\n",
            " 88%|████████▊ | 1292/1471 [03:01<00:32,  5.43it/s]2024-08-13 21:39:34,517 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:34,815 - INFO - joeynmt.prediction - Generation took 0.2956[sec].\n",
            " 88%|████████▊ | 1293/1471 [03:01<00:38,  4.66it/s]2024-08-13 21:39:34,819 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:35,024 - INFO - joeynmt.prediction - Generation took 0.2021[sec].\n",
            " 88%|████████▊ | 1294/1471 [03:01<00:37,  4.69it/s]2024-08-13 21:39:35,029 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:35,182 - INFO - joeynmt.prediction - Generation took 0.1509[sec].\n",
            " 88%|████████▊ | 1295/1471 [03:01<00:34,  5.04it/s]2024-08-13 21:39:35,187 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:35,268 - INFO - joeynmt.prediction - Generation took 0.0780[sec].\n",
            "2024-08-13 21:39:35,271 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:35,329 - INFO - joeynmt.prediction - Generation took 0.0562[sec].\n",
            " 88%|████████▊ | 1297/1471 [03:01<00:24,  6.96it/s]2024-08-13 21:39:35,334 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:35,434 - INFO - joeynmt.prediction - Generation took 0.0962[sec].\n",
            " 88%|████████▊ | 1298/1471 [03:02<00:23,  7.43it/s]2024-08-13 21:39:35,439 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:35,565 - INFO - joeynmt.prediction - Generation took 0.1240[sec].\n",
            " 88%|████████▊ | 1299/1471 [03:02<00:22,  7.49it/s]2024-08-13 21:39:35,572 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:35,662 - INFO - joeynmt.prediction - Generation took 0.0877[sec].\n",
            "2024-08-13 21:39:35,665 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:35,731 - INFO - joeynmt.prediction - Generation took 0.0633[sec].\n",
            " 88%|████████▊ | 1301/1471 [03:02<00:19,  8.93it/s]2024-08-13 21:39:35,735 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:35,815 - INFO - joeynmt.prediction - Generation took 0.0775[sec].\n",
            "2024-08-13 21:39:35,818 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:36,424 - INFO - joeynmt.prediction - Generation took 0.6035[sec].\n",
            " 89%|████████▊ | 1303/1471 [03:03<00:33,  5.00it/s]2024-08-13 21:39:36,429 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:36,528 - INFO - joeynmt.prediction - Generation took 0.0961[sec].\n",
            " 89%|████████▊ | 1304/1471 [03:03<00:30,  5.56it/s]2024-08-13 21:39:36,532 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:36,626 - INFO - joeynmt.prediction - Generation took 0.0918[sec].\n",
            "2024-08-13 21:39:36,629 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:36,751 - INFO - joeynmt.prediction - Generation took 0.1196[sec].\n",
            " 89%|████████▉ | 1306/1471 [03:03<00:25,  6.49it/s]2024-08-13 21:39:36,755 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:36,984 - INFO - joeynmt.prediction - Generation took 0.2271[sec].\n",
            " 89%|████████▉ | 1307/1471 [03:03<00:28,  5.85it/s]2024-08-13 21:39:36,991 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:37,062 - INFO - joeynmt.prediction - Generation took 0.0682[sec].\n",
            "2024-08-13 21:39:37,064 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:37,150 - INFO - joeynmt.prediction - Generation took 0.0836[sec].\n",
            " 89%|████████▉ | 1309/1471 [03:03<00:22,  7.26it/s]2024-08-13 21:39:37,155 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:37,320 - INFO - joeynmt.prediction - Generation took 0.1627[sec].\n",
            " 89%|████████▉ | 1310/1471 [03:03<00:23,  6.90it/s]2024-08-13 21:39:37,326 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:37,443 - INFO - joeynmt.prediction - Generation took 0.1149[sec].\n",
            " 89%|████████▉ | 1311/1471 [03:04<00:22,  7.18it/s]2024-08-13 21:39:37,447 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:37,520 - INFO - joeynmt.prediction - Generation took 0.0703[sec].\n",
            "2024-08-13 21:39:37,523 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:37,828 - INFO - joeynmt.prediction - Generation took 0.3025[sec].\n",
            " 89%|████████▉ | 1313/1471 [03:04<00:25,  6.23it/s]2024-08-13 21:39:37,835 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:38,089 - INFO - joeynmt.prediction - Generation took 0.2523[sec].\n",
            " 89%|████████▉ | 1314/1471 [03:04<00:28,  5.47it/s]2024-08-13 21:39:38,096 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:38,167 - INFO - joeynmt.prediction - Generation took 0.0681[sec].\n",
            "2024-08-13 21:39:38,170 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:38,250 - INFO - joeynmt.prediction - Generation took 0.0780[sec].\n",
            " 89%|████████▉ | 1316/1471 [03:04<00:22,  6.99it/s]2024-08-13 21:39:38,254 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:38,493 - INFO - joeynmt.prediction - Generation took 0.2364[sec].\n",
            " 90%|████████▉ | 1317/1471 [03:05<00:25,  6.07it/s]2024-08-13 21:39:38,500 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:38,620 - INFO - joeynmt.prediction - Generation took 0.1178[sec].\n",
            " 90%|████████▉ | 1318/1471 [03:05<00:23,  6.42it/s]2024-08-13 21:39:38,624 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:38,744 - INFO - joeynmt.prediction - Generation took 0.1178[sec].\n",
            " 90%|████████▉ | 1319/1471 [03:05<00:22,  6.76it/s]2024-08-13 21:39:38,749 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:38,807 - INFO - joeynmt.prediction - Generation took 0.0524[sec].\n",
            "2024-08-13 21:39:38,809 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:38,890 - INFO - joeynmt.prediction - Generation took 0.0783[sec].\n",
            " 90%|████████▉ | 1321/1471 [03:05<00:17,  8.59it/s]2024-08-13 21:39:38,894 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:39,084 - INFO - joeynmt.prediction - Generation took 0.1873[sec].\n",
            " 90%|████████▉ | 1322/1471 [03:05<00:20,  7.44it/s]2024-08-13 21:39:39,089 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:39,166 - INFO - joeynmt.prediction - Generation took 0.0750[sec].\n",
            "2024-08-13 21:39:39,172 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:39,263 - INFO - joeynmt.prediction - Generation took 0.0890[sec].\n",
            " 90%|█████████ | 1324/1471 [03:05<00:17,  8.59it/s]2024-08-13 21:39:39,267 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:39,571 - INFO - joeynmt.prediction - Generation took 0.2980[sec].\n",
            " 90%|█████████ | 1325/1471 [03:06<00:23,  6.25it/s]2024-08-13 21:39:39,579 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:39,784 - INFO - joeynmt.prediction - Generation took 0.2023[sec].\n",
            " 90%|█████████ | 1326/1471 [03:06<00:24,  5.83it/s]2024-08-13 21:39:39,788 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:39,901 - INFO - joeynmt.prediction - Generation took 0.1100[sec].\n",
            " 90%|█████████ | 1327/1471 [03:06<00:22,  6.30it/s]2024-08-13 21:39:39,910 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:40,018 - INFO - joeynmt.prediction - Generation took 0.1060[sec].\n",
            " 90%|█████████ | 1328/1471 [03:06<00:20,  6.83it/s]2024-08-13 21:39:40,022 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:40,104 - INFO - joeynmt.prediction - Generation took 0.0802[sec].\n",
            "2024-08-13 21:39:40,107 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:40,217 - INFO - joeynmt.prediction - Generation took 0.1078[sec].\n",
            " 90%|█████████ | 1330/1471 [03:06<00:17,  7.93it/s]2024-08-13 21:39:40,221 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:40,307 - INFO - joeynmt.prediction - Generation took 0.0833[sec].\n",
            "2024-08-13 21:39:40,309 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:40,404 - INFO - joeynmt.prediction - Generation took 0.0934[sec].\n",
            " 91%|█████████ | 1332/1471 [03:07<00:15,  8.80it/s]2024-08-13 21:39:40,408 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:40,493 - INFO - joeynmt.prediction - Generation took 0.0830[sec].\n",
            "2024-08-13 21:39:40,496 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:40,584 - INFO - joeynmt.prediction - Generation took 0.0857[sec].\n",
            " 91%|█████████ | 1334/1471 [03:07<00:14,  9.51it/s]2024-08-13 21:39:40,587 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:40,752 - INFO - joeynmt.prediction - Generation took 0.1622[sec].\n",
            " 91%|█████████ | 1335/1471 [03:07<00:16,  8.48it/s]2024-08-13 21:39:40,756 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:40,875 - INFO - joeynmt.prediction - Generation took 0.1129[sec].\n",
            " 91%|█████████ | 1336/1471 [03:07<00:16,  8.40it/s]2024-08-13 21:39:40,879 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:40,961 - INFO - joeynmt.prediction - Generation took 0.0800[sec].\n",
            "2024-08-13 21:39:40,967 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:41,070 - INFO - joeynmt.prediction - Generation took 0.1012[sec].\n",
            " 91%|█████████ | 1338/1471 [03:07<00:14,  9.04it/s]2024-08-13 21:39:41,074 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:41,177 - INFO - joeynmt.prediction - Generation took 0.0996[sec].\n",
            " 91%|█████████ | 1339/1471 [03:07<00:14,  9.09it/s]2024-08-13 21:39:41,181 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:41,251 - INFO - joeynmt.prediction - Generation took 0.0660[sec].\n",
            "2024-08-13 21:39:41,254 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:41,406 - INFO - joeynmt.prediction - Generation took 0.1495[sec].\n",
            " 91%|█████████ | 1341/1471 [03:08<00:14,  8.93it/s]2024-08-13 21:39:41,412 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:41,524 - INFO - joeynmt.prediction - Generation took 0.1096[sec].\n",
            " 91%|█████████ | 1342/1471 [03:08<00:14,  8.86it/s]2024-08-13 21:39:41,529 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:41,817 - INFO - joeynmt.prediction - Generation took 0.2860[sec].\n",
            " 91%|█████████▏| 1343/1471 [03:08<00:19,  6.44it/s]2024-08-13 21:39:41,821 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:41,898 - INFO - joeynmt.prediction - Generation took 0.0744[sec].\n",
            "2024-08-13 21:39:41,901 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:41,969 - INFO - joeynmt.prediction - Generation took 0.0660[sec].\n",
            " 91%|█████████▏| 1345/1471 [03:08<00:15,  8.11it/s]2024-08-13 21:39:41,973 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:42,064 - INFO - joeynmt.prediction - Generation took 0.0891[sec].\n",
            "2024-08-13 21:39:42,067 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:42,309 - INFO - joeynmt.prediction - Generation took 0.2398[sec].\n",
            " 92%|█████████▏| 1347/1471 [03:08<00:17,  7.13it/s]2024-08-13 21:39:42,313 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:42,499 - INFO - joeynmt.prediction - Generation took 0.1836[sec].\n",
            " 92%|█████████▏| 1348/1471 [03:09<00:18,  6.63it/s]2024-08-13 21:39:42,504 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:42,675 - INFO - joeynmt.prediction - Generation took 0.1682[sec].\n",
            " 92%|█████████▏| 1349/1471 [03:09<00:19,  6.40it/s]2024-08-13 21:39:42,679 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:42,910 - INFO - joeynmt.prediction - Generation took 0.2283[sec].\n",
            " 92%|█████████▏| 1350/1471 [03:09<00:21,  5.70it/s]2024-08-13 21:39:42,914 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:43,120 - INFO - joeynmt.prediction - Generation took 0.2041[sec].\n",
            " 92%|█████████▏| 1351/1471 [03:09<00:22,  5.42it/s]2024-08-13 21:39:43,124 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:43,289 - INFO - joeynmt.prediction - Generation took 0.1623[sec].\n",
            " 92%|█████████▏| 1352/1471 [03:09<00:21,  5.53it/s]2024-08-13 21:39:43,295 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:43,475 - INFO - joeynmt.prediction - Generation took 0.1780[sec].\n",
            " 92%|█████████▏| 1353/1471 [03:10<00:21,  5.50it/s]2024-08-13 21:39:43,480 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:43,724 - INFO - joeynmt.prediction - Generation took 0.2388[sec].\n",
            " 92%|█████████▏| 1354/1471 [03:10<00:23,  4.97it/s]2024-08-13 21:39:43,729 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:44,044 - INFO - joeynmt.prediction - Generation took 0.3115[sec].\n",
            " 92%|█████████▏| 1355/1471 [03:10<00:27,  4.25it/s]2024-08-13 21:39:44,048 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:44,194 - INFO - joeynmt.prediction - Generation took 0.1433[sec].\n",
            " 92%|█████████▏| 1356/1471 [03:10<00:24,  4.75it/s]2024-08-13 21:39:44,198 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:44,396 - INFO - joeynmt.prediction - Generation took 0.1956[sec].\n",
            " 92%|█████████▏| 1357/1471 [03:11<00:23,  4.81it/s]2024-08-13 21:39:44,401 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:44,644 - INFO - joeynmt.prediction - Generation took 0.2416[sec].\n",
            " 92%|█████████▏| 1358/1471 [03:11<00:24,  4.55it/s]2024-08-13 21:39:44,649 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:45,032 - INFO - joeynmt.prediction - Generation took 0.3797[sec].\n",
            " 92%|█████████▏| 1359/1471 [03:11<00:30,  3.71it/s]2024-08-13 21:39:45,039 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:45,386 - INFO - joeynmt.prediction - Generation took 0.3442[sec].\n",
            " 92%|█████████▏| 1360/1471 [03:12<00:32,  3.39it/s]2024-08-13 21:39:45,393 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:45,610 - INFO - joeynmt.prediction - Generation took 0.2139[sec].\n",
            " 93%|█████████▎| 1361/1471 [03:12<00:30,  3.65it/s]2024-08-13 21:39:45,615 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:45,771 - INFO - joeynmt.prediction - Generation took 0.1513[sec].\n",
            " 93%|█████████▎| 1362/1471 [03:12<00:26,  4.17it/s]2024-08-13 21:39:45,775 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:46,016 - INFO - joeynmt.prediction - Generation took 0.2383[sec].\n",
            " 93%|█████████▎| 1363/1471 [03:12<00:26,  4.14it/s]2024-08-13 21:39:46,020 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:46,357 - INFO - joeynmt.prediction - Generation took 0.3346[sec].\n",
            " 93%|█████████▎| 1364/1471 [03:12<00:29,  3.68it/s]2024-08-13 21:39:46,365 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:46,661 - INFO - joeynmt.prediction - Generation took 0.2938[sec].\n",
            " 93%|█████████▎| 1365/1471 [03:13<00:29,  3.56it/s]2024-08-13 21:39:46,666 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:46,813 - INFO - joeynmt.prediction - Generation took 0.1451[sec].\n",
            " 93%|█████████▎| 1366/1471 [03:13<00:25,  4.12it/s]2024-08-13 21:39:46,819 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:46,947 - INFO - joeynmt.prediction - Generation took 0.1254[sec].\n",
            " 93%|█████████▎| 1367/1471 [03:13<00:21,  4.77it/s]2024-08-13 21:39:46,951 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:47,069 - INFO - joeynmt.prediction - Generation took 0.1160[sec].\n",
            " 93%|█████████▎| 1368/1471 [03:13<00:18,  5.45it/s]2024-08-13 21:39:47,075 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:47,324 - INFO - joeynmt.prediction - Generation took 0.2455[sec].\n",
            " 93%|█████████▎| 1369/1471 [03:13<00:20,  4.88it/s]2024-08-13 21:39:47,334 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:47,524 - INFO - joeynmt.prediction - Generation took 0.1870[sec].\n",
            " 93%|█████████▎| 1370/1471 [03:14<00:20,  4.92it/s]2024-08-13 21:39:47,529 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:47,611 - INFO - joeynmt.prediction - Generation took 0.0786[sec].\n",
            "2024-08-13 21:39:47,613 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:47,666 - INFO - joeynmt.prediction - Generation took 0.0510[sec].\n",
            " 93%|█████████▎| 1372/1471 [03:14<00:14,  7.02it/s]2024-08-13 21:39:47,671 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:47,772 - INFO - joeynmt.prediction - Generation took 0.0987[sec].\n",
            " 93%|█████████▎| 1373/1471 [03:14<00:13,  7.50it/s]2024-08-13 21:39:47,777 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:47,876 - INFO - joeynmt.prediction - Generation took 0.0963[sec].\n",
            " 93%|█████████▎| 1374/1471 [03:14<00:12,  7.97it/s]2024-08-13 21:39:47,880 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:47,957 - INFO - joeynmt.prediction - Generation took 0.0741[sec].\n",
            "2024-08-13 21:39:47,959 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:48,006 - INFO - joeynmt.prediction - Generation took 0.0444[sec].\n",
            " 94%|█████████▎| 1376/1471 [03:14<00:09, 10.04it/s]2024-08-13 21:39:48,010 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:48,203 - INFO - joeynmt.prediction - Generation took 0.1904[sec].\n",
            "2024-08-13 21:39:48,205 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:48,268 - INFO - joeynmt.prediction - Generation took 0.0599[sec].\n",
            " 94%|█████████▎| 1378/1471 [03:14<00:10,  8.95it/s]2024-08-13 21:39:48,274 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:48,346 - INFO - joeynmt.prediction - Generation took 0.0690[sec].\n",
            "2024-08-13 21:39:48,349 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:48,431 - INFO - joeynmt.prediction - Generation took 0.0800[sec].\n",
            " 94%|█████████▍| 1380/1471 [03:15<00:09,  9.89it/s]2024-08-13 21:39:48,436 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:48,542 - INFO - joeynmt.prediction - Generation took 0.1043[sec].\n",
            "2024-08-13 21:39:48,545 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:48,645 - INFO - joeynmt.prediction - Generation took 0.0966[sec].\n",
            " 94%|█████████▍| 1382/1471 [03:15<00:09,  9.71it/s]2024-08-13 21:39:48,649 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:48,718 - INFO - joeynmt.prediction - Generation took 0.0652[sec].\n",
            "2024-08-13 21:39:48,720 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:48,782 - INFO - joeynmt.prediction - Generation took 0.0606[sec].\n",
            " 94%|█████████▍| 1384/1471 [03:15<00:08, 10.87it/s]2024-08-13 21:39:48,788 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:48,870 - INFO - joeynmt.prediction - Generation took 0.0794[sec].\n",
            "2024-08-13 21:39:48,872 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:49,009 - INFO - joeynmt.prediction - Generation took 0.1324[sec].\n",
            " 94%|█████████▍| 1386/1471 [03:15<00:08, 10.13it/s]2024-08-13 21:39:49,014 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:49,137 - INFO - joeynmt.prediction - Generation took 0.1199[sec].\n",
            "2024-08-13 21:39:49,139 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:49,215 - INFO - joeynmt.prediction - Generation took 0.0721[sec].\n",
            " 94%|█████████▍| 1388/1471 [03:15<00:08,  9.92it/s]2024-08-13 21:39:49,224 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:49,318 - INFO - joeynmt.prediction - Generation took 0.0894[sec].\n",
            "2024-08-13 21:39:49,320 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:49,377 - INFO - joeynmt.prediction - Generation took 0.0551[sec].\n",
            " 94%|█████████▍| 1390/1471 [03:15<00:07, 10.65it/s]2024-08-13 21:39:49,381 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:49,478 - INFO - joeynmt.prediction - Generation took 0.0948[sec].\n",
            "2024-08-13 21:39:49,482 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:49,634 - INFO - joeynmt.prediction - Generation took 0.1488[sec].\n",
            " 95%|█████████▍| 1392/1471 [03:16<00:08,  9.59it/s]2024-08-13 21:39:49,638 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:49,713 - INFO - joeynmt.prediction - Generation took 0.0718[sec].\n",
            "2024-08-13 21:39:49,715 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:49,946 - INFO - joeynmt.prediction - Generation took 0.2285[sec].\n",
            " 95%|█████████▍| 1394/1471 [03:16<00:09,  8.33it/s]2024-08-13 21:39:49,950 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:50,091 - INFO - joeynmt.prediction - Generation took 0.1391[sec].\n",
            " 95%|█████████▍| 1395/1471 [03:16<00:09,  8.03it/s]2024-08-13 21:39:50,095 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:50,165 - INFO - joeynmt.prediction - Generation took 0.0670[sec].\n",
            "2024-08-13 21:39:50,169 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:50,239 - INFO - joeynmt.prediction - Generation took 0.0679[sec].\n",
            " 95%|█████████▍| 1397/1471 [03:16<00:07,  9.31it/s]2024-08-13 21:39:50,242 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:50,428 - INFO - joeynmt.prediction - Generation took 0.1828[sec].\n",
            " 95%|█████████▌| 1398/1471 [03:17<00:09,  8.11it/s]2024-08-13 21:39:50,432 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:50,543 - INFO - joeynmt.prediction - Generation took 0.1085[sec].\n",
            " 95%|█████████▌| 1399/1471 [03:17<00:08,  8.20it/s]2024-08-13 21:39:50,548 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:50,640 - INFO - joeynmt.prediction - Generation took 0.0904[sec].\n",
            "2024-08-13 21:39:50,643 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:50,742 - INFO - joeynmt.prediction - Generation took 0.0972[sec].\n",
            " 95%|█████████▌| 1401/1471 [03:17<00:07,  8.84it/s]2024-08-13 21:39:50,746 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:50,830 - INFO - joeynmt.prediction - Generation took 0.0815[sec].\n",
            "2024-08-13 21:39:50,832 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:50,943 - INFO - joeynmt.prediction - Generation took 0.1089[sec].\n",
            " 95%|█████████▌| 1403/1471 [03:17<00:07,  9.20it/s]2024-08-13 21:39:50,947 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:51,075 - INFO - joeynmt.prediction - Generation took 0.1254[sec].\n",
            " 95%|█████████▌| 1404/1471 [03:17<00:07,  8.84it/s]2024-08-13 21:39:51,079 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:51,206 - INFO - joeynmt.prediction - Generation took 0.1237[sec].\n",
            " 96%|█████████▌| 1405/1471 [03:17<00:07,  8.52it/s]2024-08-13 21:39:51,211 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:51,355 - INFO - joeynmt.prediction - Generation took 0.1409[sec].\n",
            " 96%|█████████▌| 1406/1471 [03:17<00:08,  7.99it/s]2024-08-13 21:39:51,360 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:51,521 - INFO - joeynmt.prediction - Generation took 0.1573[sec].\n",
            " 96%|█████████▌| 1407/1471 [03:18<00:08,  7.37it/s]2024-08-13 21:39:51,526 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:51,944 - INFO - joeynmt.prediction - Generation took 0.4154[sec].\n",
            " 96%|█████████▌| 1408/1471 [03:18<00:13,  4.70it/s]2024-08-13 21:39:51,948 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:52,112 - INFO - joeynmt.prediction - Generation took 0.1620[sec].\n",
            " 96%|█████████▌| 1409/1471 [03:18<00:12,  4.99it/s]2024-08-13 21:39:52,117 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:52,389 - INFO - joeynmt.prediction - Generation took 0.2698[sec].\n",
            " 96%|█████████▌| 1410/1471 [03:19<00:13,  4.51it/s]2024-08-13 21:39:52,393 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:52,492 - INFO - joeynmt.prediction - Generation took 0.0971[sec].\n",
            " 96%|█████████▌| 1411/1471 [03:19<00:11,  5.33it/s]2024-08-13 21:39:52,496 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:52,613 - INFO - joeynmt.prediction - Generation took 0.1093[sec].\n",
            " 96%|█████████▌| 1412/1471 [03:19<00:09,  5.95it/s]2024-08-13 21:39:52,617 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:52,828 - INFO - joeynmt.prediction - Generation took 0.2094[sec].\n",
            " 96%|█████████▌| 1413/1471 [03:19<00:10,  5.49it/s]2024-08-13 21:39:52,837 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:52,930 - INFO - joeynmt.prediction - Generation took 0.0912[sec].\n",
            " 96%|█████████▌| 1414/1471 [03:19<00:09,  6.29it/s]2024-08-13 21:39:52,936 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:53,032 - INFO - joeynmt.prediction - Generation took 0.0938[sec].\n",
            "2024-08-13 21:39:53,034 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:53,095 - INFO - joeynmt.prediction - Generation took 0.0592[sec].\n",
            " 96%|█████████▋| 1416/1471 [03:19<00:06,  8.10it/s]2024-08-13 21:39:53,103 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:53,171 - INFO - joeynmt.prediction - Generation took 0.0667[sec].\n",
            "2024-08-13 21:39:53,174 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:53,252 - INFO - joeynmt.prediction - Generation took 0.0722[sec].\n",
            " 96%|█████████▋| 1418/1471 [03:19<00:05,  9.48it/s]2024-08-13 21:39:53,256 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:53,606 - INFO - joeynmt.prediction - Generation took 0.3472[sec].\n",
            "2024-08-13 21:39:53,609 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:53,708 - INFO - joeynmt.prediction - Generation took 0.0966[sec].\n",
            " 97%|█████████▋| 1420/1471 [03:20<00:07,  6.67it/s]2024-08-13 21:39:53,713 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:53,975 - INFO - joeynmt.prediction - Generation took 0.2606[sec].\n",
            " 97%|█████████▋| 1421/1471 [03:20<00:08,  5.74it/s]2024-08-13 21:39:53,982 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:54,189 - INFO - joeynmt.prediction - Generation took 0.2056[sec].\n",
            " 97%|█████████▋| 1422/1471 [03:20<00:08,  5.47it/s]2024-08-13 21:39:54,195 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:54,256 - INFO - joeynmt.prediction - Generation took 0.0578[sec].\n",
            "2024-08-13 21:39:54,258 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:54,520 - INFO - joeynmt.prediction - Generation took 0.2597[sec].\n",
            " 97%|█████████▋| 1424/1471 [03:21<00:08,  5.65it/s]2024-08-13 21:39:54,529 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:54,632 - INFO - joeynmt.prediction - Generation took 0.1012[sec].\n",
            " 97%|█████████▋| 1425/1471 [03:21<00:07,  6.15it/s]2024-08-13 21:39:54,640 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:54,745 - INFO - joeynmt.prediction - Generation took 0.1031[sec].\n",
            " 97%|█████████▋| 1426/1471 [03:21<00:06,  6.65it/s]2024-08-13 21:39:54,751 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:54,990 - INFO - joeynmt.prediction - Generation took 0.2369[sec].\n",
            " 97%|█████████▋| 1427/1471 [03:21<00:07,  5.74it/s]2024-08-13 21:39:54,996 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:55,069 - INFO - joeynmt.prediction - Generation took 0.0712[sec].\n",
            "2024-08-13 21:39:55,074 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:55,307 - INFO - joeynmt.prediction - Generation took 0.2308[sec].\n",
            " 97%|█████████▋| 1429/1471 [03:21<00:07,  5.97it/s]2024-08-13 21:39:55,312 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:55,532 - INFO - joeynmt.prediction - Generation took 0.2186[sec].\n",
            " 97%|█████████▋| 1430/1471 [03:22<00:07,  5.53it/s]2024-08-13 21:39:55,539 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:55,660 - INFO - joeynmt.prediction - Generation took 0.1200[sec].\n",
            " 97%|█████████▋| 1431/1471 [03:22<00:06,  5.92it/s]2024-08-13 21:39:55,670 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:55,962 - INFO - joeynmt.prediction - Generation took 0.2905[sec].\n",
            " 97%|█████████▋| 1432/1471 [03:22<00:07,  4.93it/s]2024-08-13 21:39:55,969 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:56,099 - INFO - joeynmt.prediction - Generation took 0.1277[sec].\n",
            " 97%|█████████▋| 1433/1471 [03:22<00:07,  5.39it/s]2024-08-13 21:39:56,108 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:56,186 - INFO - joeynmt.prediction - Generation took 0.0762[sec].\n",
            "2024-08-13 21:39:56,191 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:56,261 - INFO - joeynmt.prediction - Generation took 0.0680[sec].\n",
            " 98%|█████████▊| 1435/1471 [03:22<00:04,  7.22it/s]2024-08-13 21:39:56,264 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:56,387 - INFO - joeynmt.prediction - Generation took 0.1209[sec].\n",
            " 98%|█████████▊| 1436/1471 [03:23<00:04,  7.37it/s]2024-08-13 21:39:56,391 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:56,727 - INFO - joeynmt.prediction - Generation took 0.3331[sec].\n",
            " 98%|█████████▊| 1437/1471 [03:23<00:06,  5.33it/s]2024-08-13 21:39:56,732 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:57,009 - INFO - joeynmt.prediction - Generation took 0.2734[sec].\n",
            " 98%|█████████▊| 1438/1471 [03:23<00:07,  4.71it/s]2024-08-13 21:39:57,014 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:57,076 - INFO - joeynmt.prediction - Generation took 0.0585[sec].\n",
            "2024-08-13 21:39:57,079 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:57,179 - INFO - joeynmt.prediction - Generation took 0.0975[sec].\n",
            " 98%|█████████▊| 1440/1471 [03:23<00:04,  6.35it/s]2024-08-13 21:39:57,183 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:57,319 - INFO - joeynmt.prediction - Generation took 0.1340[sec].\n",
            " 98%|█████████▊| 1441/1471 [03:23<00:04,  6.52it/s]2024-08-13 21:39:57,323 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:57,453 - INFO - joeynmt.prediction - Generation took 0.1275[sec].\n",
            " 98%|█████████▊| 1442/1471 [03:24<00:04,  6.73it/s]2024-08-13 21:39:57,458 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:57,586 - INFO - joeynmt.prediction - Generation took 0.1252[sec].\n",
            " 98%|█████████▊| 1443/1471 [03:24<00:04,  6.92it/s]2024-08-13 21:39:57,590 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:57,800 - INFO - joeynmt.prediction - Generation took 0.2067[sec].\n",
            " 98%|█████████▊| 1444/1471 [03:24<00:04,  6.12it/s]2024-08-13 21:39:57,805 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:57,897 - INFO - joeynmt.prediction - Generation took 0.0898[sec].\n",
            "2024-08-13 21:39:57,900 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:57,974 - INFO - joeynmt.prediction - Generation took 0.0713[sec].\n",
            " 98%|█████████▊| 1446/1471 [03:24<00:03,  7.70it/s]2024-08-13 21:39:57,978 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:58,162 - INFO - joeynmt.prediction - Generation took 0.1814[sec].\n",
            " 98%|█████████▊| 1447/1471 [03:24<00:03,  6.95it/s]2024-08-13 21:39:58,167 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:58,244 - INFO - joeynmt.prediction - Generation took 0.0751[sec].\n",
            "2024-08-13 21:39:58,246 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:58,383 - INFO - joeynmt.prediction - Generation took 0.1341[sec].\n",
            " 99%|█████████▊| 1449/1471 [03:24<00:02,  7.68it/s]2024-08-13 21:39:58,387 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:58,502 - INFO - joeynmt.prediction - Generation took 0.1125[sec].\n",
            " 99%|█████████▊| 1450/1471 [03:25<00:02,  7.83it/s]2024-08-13 21:39:58,508 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:58,703 - INFO - joeynmt.prediction - Generation took 0.1919[sec].\n",
            " 99%|█████████▊| 1451/1471 [03:25<00:02,  6.87it/s]2024-08-13 21:39:58,708 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:58,767 - INFO - joeynmt.prediction - Generation took 0.0570[sec].\n",
            "2024-08-13 21:39:58,769 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:58,853 - INFO - joeynmt.prediction - Generation took 0.0816[sec].\n",
            " 99%|█████████▉| 1453/1471 [03:25<00:02,  8.57it/s]2024-08-13 21:39:58,857 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:58,925 - INFO - joeynmt.prediction - Generation took 0.0644[sec].\n",
            "2024-08-13 21:39:58,927 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:59,023 - INFO - joeynmt.prediction - Generation took 0.0941[sec].\n",
            " 99%|█████████▉| 1455/1471 [03:25<00:01,  9.53it/s]2024-08-13 21:39:59,029 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:59,260 - INFO - joeynmt.prediction - Generation took 0.2275[sec].\n",
            " 99%|█████████▉| 1456/1471 [03:25<00:01,  7.56it/s]2024-08-13 21:39:59,264 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:59,331 - INFO - joeynmt.prediction - Generation took 0.0618[sec].\n",
            "2024-08-13 21:39:59,335 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:59,391 - INFO - joeynmt.prediction - Generation took 0.0539[sec].\n",
            " 99%|█████████▉| 1458/1471 [03:26<00:01,  9.30it/s]2024-08-13 21:39:59,395 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:59,474 - INFO - joeynmt.prediction - Generation took 0.0763[sec].\n",
            "2024-08-13 21:39:59,477 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:59,587 - INFO - joeynmt.prediction - Generation took 0.1079[sec].\n",
            " 99%|█████████▉| 1460/1471 [03:26<00:01,  9.59it/s]2024-08-13 21:39:59,592 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:39:59,977 - INFO - joeynmt.prediction - Generation took 0.3830[sec].\n",
            "2024-08-13 21:39:59,981 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:40:00,078 - INFO - joeynmt.prediction - Generation took 0.0922[sec].\n",
            " 99%|█████████▉| 1462/1471 [03:26<00:01,  6.61it/s]2024-08-13 21:40:00,083 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:40:00,159 - INFO - joeynmt.prediction - Generation took 0.0737[sec].\n",
            "2024-08-13 21:40:00,162 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:40:00,231 - INFO - joeynmt.prediction - Generation took 0.0667[sec].\n",
            "100%|█████████▉| 1464/1471 [03:26<00:00,  7.86it/s]2024-08-13 21:40:00,236 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:40:00,404 - INFO - joeynmt.prediction - Generation took 0.1659[sec].\n",
            "100%|█████████▉| 1465/1471 [03:27<00:00,  7.37it/s]2024-08-13 21:40:00,409 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:40:00,505 - INFO - joeynmt.prediction - Generation took 0.0934[sec].\n",
            "100%|█████████▉| 1466/1471 [03:27<00:00,  7.76it/s]2024-08-13 21:40:00,512 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:40:00,583 - INFO - joeynmt.prediction - Generation took 0.0688[sec].\n",
            "2024-08-13 21:40:00,586 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:40:00,779 - INFO - joeynmt.prediction - Generation took 0.1912[sec].\n",
            "100%|█████████▉| 1468/1471 [03:27<00:00,  7.61it/s]2024-08-13 21:40:00,784 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:40:00,930 - INFO - joeynmt.prediction - Generation took 0.1438[sec].\n",
            "100%|█████████▉| 1469/1471 [03:27<00:00,  7.39it/s]2024-08-13 21:40:00,934 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:40:01,049 - INFO - joeynmt.prediction - Generation took 0.1108[sec].\n",
            "100%|█████████▉| 1470/1471 [03:27<00:00,  7.59it/s]2024-08-13 21:40:01,054 - INFO - joeynmt.prediction - Predicting 1 example(s)... (Beam search with beam_size=10, beam_alpha=0.7, n_best=1, min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "2024-08-13 21:40:01,253 - INFO - joeynmt.prediction - Generation took 0.1931[sec].\n",
            "100%|██████████| 1471/1471 [03:27<00:00,  7.08it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "# Convert the validation dataset to a pandas DataFrame\n",
        "validation_data = dataset[\"validation\"]\n",
        "eval_df = pd.DataFrame(validation_data[\"translation\"])\n",
        "\n",
        "# Add a column for the predicted translations\n",
        "eval_df['predicted'] = \"\"\n",
        "\n",
        "# Iterate over the DataFrame and translate the sentences\n",
        "for i, row in tqdm(eval_df.iterrows(), total=eval_df.shape[0]):\n",
        "    predicted = model.translate(sentence=row['dyu'])\n",
        "    eval_df.at[i, 'predicted'] = predicted[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkt3vFPQqhci"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSAi8R902X5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599d321d-b699-400e-b772-bdc481e8e031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall mean BLEU score: 8.087556451584101\n",
            "{'score': 8.087556451584101, 'counts': [1503, 581, 298, 149], 'totals': [6786, 5315, 3854, 2471], 'precisions': [22.148541114058354, 10.931326434619002, 7.732226258432797, 6.0299473897207605], 'bp': 0.7846180751413663, 'sys_len': 6786, 'ref_len': 8432}\n"
          ]
        }
      ],
      "source": [
        "# Copyright 2020 The HuggingFace Evaluate Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\" SACREBLEU metric. \"\"\"\n",
        "\n",
        "import datasets\n",
        "import sacrebleu as scb\n",
        "import evaluate\n",
        "\n",
        "_CITATION = \"\"\"\\\n",
        "@inproceedings{post-2018-call,\n",
        "    title = \"A Call for Clarity in Reporting {BLEU} Scores\",\n",
        "    author = \"Post, Matt\",\n",
        "    booktitle = \"Proceedings of the Third Conference on Machine Translation: Research Papers\",\n",
        "    month = oct,\n",
        "    year = \"2018\",\n",
        "    address = \"Belgium, Brussels\",\n",
        "    publisher = \"Association for Computational Linguistics\",\n",
        "    url = \"https://www.aclweb.org/anthology/W18-6319\",\n",
        "    pages = \"186--191\",\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "_DESCRIPTION = \"\"\"\\\n",
        "SacreBLEU provides hassle-free computation of shareable, comparable, and reproducible BLEU scores.\n",
        "Inspired by Rico Sennrich's `multi-bleu-detok.perl`, it produces the official WMT scores but works with plain text.\n",
        "It also knows all the standard test sets and handles downloading, processing, and tokenization for you.\n",
        "\n",
        "See the [README.md] file at https://github.com/mjpost/sacreBLEU for more information.\n",
        "\"\"\"\n",
        "\n",
        "_KWARGS_DESCRIPTION = \"\"\"\n",
        "Produces BLEU scores along with its sufficient statistics\n",
        "from a source against one or more references.\n",
        "\n",
        "Args:\n",
        "    predictions (`list` of `str`): list of translations to score. Each translation should be tokenized into a list of tokens.\n",
        "    references (`list` of `list` of `str`): A list of lists of references. The contents of the first sub-list are the references for the first prediction, the contents of the second sub-list are for the second prediction, etc. Note that there must be the same number of references for each prediction (i.e. all sub-lists must be of the same length).\n",
        "    smooth_method (`str`): The smoothing method to use, defaults to `'exp'`. Possible values are:\n",
        "        - `'none'`: no smoothing\n",
        "        - `'floor'`: increment zero counts\n",
        "        - `'add-k'`: increment num/denom by k for n>1\n",
        "        - `'exp'`: exponential decay\n",
        "    smooth_value (`float`): The smoothing value. Only valid when `smooth_method='floor'` (in which case `smooth_value` defaults to `0.1`) or `smooth_method='add-k'` (in which case `smooth_value` defaults to `1`).\n",
        "    tokenize (`str`): Tokenization method to use for BLEU. If not provided, defaults to `'zh'` for Chinese, `'ja-mecab'` for Japanese and `'13a'` (mteval) otherwise. Possible values are:\n",
        "        - `'none'`: No tokenization.\n",
        "        - `'zh'`: Chinese tokenization.\n",
        "        - `'13a'`: mimics the `mteval-v13a` script from Moses.\n",
        "        - `'intl'`: International tokenization, mimics the `mteval-v14` script from Moses\n",
        "        - `'char'`: Language-agnostic character-level tokenization.\n",
        "        - `'ja-mecab'`: Japanese tokenization. Uses the [MeCab tokenizer](https://pypi.org/project/mecab-python3).\n",
        "    lowercase (`bool`): If `True`, lowercases the input, enabling case-insensitivity. Defaults to `False`.\n",
        "    force (`bool`): If `True`, insists that your tokenized input is actually detokenized. Defaults to `False`.\n",
        "    use_effective_order (`bool`): If `True`, stops including n-gram orders for which precision is 0. This should be `True`, if sentence-level BLEU will be computed. Defaults to `False`.\n",
        "\n",
        "Returns:\n",
        "    'score': BLEU score,\n",
        "    'counts': Counts,\n",
        "    'totals': Totals,\n",
        "    'precisions': Precisions,\n",
        "    'bp': Brevity penalty,\n",
        "    'sys_len': predictions length,\n",
        "    'ref_len': reference length,\n",
        "\n",
        "Examples:\n",
        "\n",
        "    Example 1:\n",
        "        >>> predictions = [\"hello there general kenobi\", \"foo bar foobar\"]\n",
        "        >>> references = [[\"hello there general kenobi\", \"hello there !\"], [\"foo bar foobar\", \"foo bar foobar\"]]\n",
        "        >>> sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "        >>> results = sacrebleu.compute(predictions=predictions, references=references)\n",
        "        >>> print(list(results.keys()))\n",
        "        ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
        "        >>> print(round(results[\"score\"], 1))\n",
        "        100.0\n",
        "\n",
        "    Example 2:\n",
        "        >>> predictions = [\"hello there general kenobi\", \"on our way to ankh morpork\"]\n",
        "        >>> references = [[\"hello there general kenobi\", \"hello there !\"], [\"goodbye ankh morpork\", \"ankh morpork\"]]\n",
        "        >>> sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "        >>> results = sacrebleu.compute(predictions=predictions, references=references)\n",
        "        >>> print(list(results.keys()))\n",
        "        ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
        "        >>> print(round(results[\"score\"], 1))\n",
        "        39.8\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "@evaluate.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)\n",
        "class Sacrebleu(evaluate.Metric):\n",
        "    def _info(self):\n",
        "        return evaluate.MetricInfo(\n",
        "            description=_DESCRIPTION,\n",
        "            citation=_CITATION,\n",
        "            homepage=\"https://github.com/mjpost/sacreBLEU\",\n",
        "            inputs_description=_KWARGS_DESCRIPTION,\n",
        "            features=[\n",
        "                datasets.Features(\n",
        "                    {\n",
        "                        \"predictions\": datasets.Value(\"string\", id=\"sequence\"),\n",
        "                        \"references\": datasets.Sequence(datasets.Value(\"string\", id=\"sequence\"), id=\"references\"),\n",
        "                    }\n",
        "                ),\n",
        "                datasets.Features(\n",
        "                    {\n",
        "                        \"predictions\": datasets.Value(\"string\", id=\"sequence\"),\n",
        "                        \"references\": datasets.Value(\"string\", id=\"sequence\"),\n",
        "                    }\n",
        "                ),\n",
        "            ],\n",
        "            codebase_urls=[\"https://github.com/mjpost/sacreBLEU\"],\n",
        "            reference_urls=[\n",
        "                \"https://github.com/mjpost/sacreBLEU\",\n",
        "                \"https://en.wikipedia.org/wiki/BLEU\",\n",
        "                \"https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213\",\n",
        "            ],\n",
        "        )\n",
        "\n",
        "    def _compute(\n",
        "        self,\n",
        "        predictions,\n",
        "        references,\n",
        "        smooth_method=\"exp\",\n",
        "        smooth_value=None,\n",
        "        force=False,\n",
        "        lowercase=False,\n",
        "        tokenize=None,\n",
        "        use_effective_order=False,\n",
        "    ):\n",
        "        if isinstance(references[0], str):\n",
        "            references = [[ref] for ref in references]\n",
        "\n",
        "        references_per_prediction = len(references[0])\n",
        "        if any(len(refs) != references_per_prediction for refs in references):\n",
        "            raise ValueError(\"Sacrebleu requires the same number of references for each prediction\")\n",
        "        transformed_references = [[refs[i] for refs in references] for i in range(references_per_prediction)]\n",
        "        output = scb.corpus_bleu(\n",
        "            predictions,\n",
        "            transformed_references,\n",
        "            smooth_method=smooth_method,\n",
        "            smooth_value=smooth_value,\n",
        "            force=force,\n",
        "            lowercase=lowercase,\n",
        "            use_effective_order=use_effective_order,\n",
        "            **(dict(tokenize=tokenize) if tokenize else {}),\n",
        "        )\n",
        "        output_dict = {\n",
        "            \"score\": output.score,\n",
        "            \"counts\": output.counts,\n",
        "            \"totals\": output.totals,\n",
        "            \"precisions\": output.precisions,\n",
        "            \"bp\": output.bp,\n",
        "            \"sys_len\": output.sys_len,\n",
        "            \"ref_len\": output.ref_len,\n",
        "        }\n",
        "        return output_dict\n",
        "\n",
        "\n",
        "import evaluate\n",
        "\n",
        "def bleu_custom(df):\n",
        "    sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "    predictions = df['predicted'].tolist()\n",
        "    references = [[ref] for ref in df['fr'].tolist()]\n",
        "    results = sacrebleu.compute(predictions=predictions, references=references)\n",
        "    mean_bleu = results['score']\n",
        "    print(f\"Overall mean BLEU score: {mean_bleu}\")\n",
        "    return results\n",
        "\n",
        "# Assuming eval_df is already defined and populated with predicted translations\n",
        "result = bleu_custom(eval_df)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6_86 - 7.616578295827822 - 21.059322033898304"
      ],
      "metadata": {
        "id": "NVtG5KL17SC5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqD9nSx-IAg3"
      },
      "source": [
        "Overall mean BLEU score: 3.6887774429328783\n",
        "{'score': 3.6887774429328783, 'counts': [1040, 267, 127, 56], 'totals': [7438, 5967, 4506, 3125], 'precisions': [13.982253293896209]}\n",
        "\n",
        "\n",
        "Overall mean BLEU score: 3.5513888698242932\n",
        "{'score': 3.5513888698242932, 'counts': [1090, 290, 115, 46], 'totals': [7391, 5920, 4455, 3070], 'precisions': [14.747666080368015, 4.898648648648648, 2.5813692480359145, 1.498371335504886], 'bp': 0.868622221529913, 'sys_len': 7391, 'ref_len': 8432}\n",
        "\n",
        "\n",
        "Overall mean BLEU score: 3.5473260597558802\n",
        "{'score': 3.5473260597558802, 'counts': [1087, 277, 114, 48], 'totals': [7328, 5857, 4397, 3018], 'precisions': [14.833515283842795, 4.7293836435035, 2.592676825108028, 1.5904572564612327], 'bp': 0.8601443785123691, 'sys_len': 7328, 'ref_len': 8432}\n",
        "\n",
        "\n",
        "Overall mean BLEU score: 5.540000158701423\n",
        "{'score': 5.540000158701423, 'counts': [1248, 410, 193, 96], 'totals': [7201, 5730, 4270, 2883], 'precisions': [17.330926260241633, 7.155322862129145, 4.519906323185012, 3.3298647242455774], 'bp': 0.8428649972820359, 'sys_len': 7201, 'ref_len': 8432}\n",
        "\n",
        "\n",
        "\n",
        "Overall mean BLEU score: 6.412369271671805\n",
        "{'score': 6.412369271671805, 'counts': [1382, 471, 238, 115], 'totals': [7453, 5982, 4514, 3096], 'precisions': [18.54286864349926, 7.873620862587764, 5.272485600354453, 3.714470284237726], 'bp': 0.8769051013445209, 'sys_len': 7453, 'ref_len': 8432}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVE74T-3W9R3",
        "outputId": "0f685d5b-c63b-4df6-a7f5-48144d977f4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/lean_model/best.ckpt'),\n",
              " PosixPath('/content/lean_model/sp.model'),\n",
              " PosixPath('/content/lean_model/config.yaml'),\n",
              " PosixPath('/content/lean_model/vocab.txt'),\n",
              " PosixPath('/content/lean_model/README.md')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "\n",
        "HF_REPO_NAME = \"Koleshjr/dyu-fr-joeynmt-316-epochs_2_layers_8heads_128_384_plateau_2000_7_95_21_48\"\n",
        "lean_model_dir = \"/content/lean_model\"\n",
        "\n",
        "# Optionally add a model card\n",
        "# Create the config\n",
        "model_card = f\"\"\"---\n",
        "language:\n",
        "- en\n",
        "- fr\n",
        "- multilingual\n",
        "tags:\n",
        "- translation\n",
        "- pytorch\n",
        "model-index:\n",
        "- name: koleshjr/dyu-fr-joeynmt\n",
        "  results: []\n",
        "---\n",
        "\n",
        "# koleshjr/dyu-fr-joeynmt\n",
        "\n",
        "An example of a machine translation model that translates Dyula to French using the [JoeyNMT framework](https://github.com/joeynmt/joeynmt).\n",
        "\n",
        "This following example is based on [this Github repo](https://github.com/data354/koumakanMT-challenge) that was kindly created by [data354](https://data354.com/en/).\n",
        "\n",
        "## Model description\n",
        "\n",
        "More information needed\n",
        "\n",
        "## Intended uses & limitations\n",
        "\n",
        "More information needed\n",
        "\n",
        "## Training and evaluation data\n",
        "\n",
        "More information needed\n",
        "\n",
        "## Usage\n",
        "\n",
        "### Load and use for inference\n",
        "\n",
        "```python\n",
        "import torch\n",
        "from joeynmt.config import load_config, parse_global_args\n",
        "from joeynmt.prediction import predict, prepare\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "# Download model\n",
        "snapshot_download(\n",
        "    repo_id=\"{HF_REPO_NAME}\",\n",
        "    local_dir=\"/path/to/save/locally\"\n",
        ")\n",
        "\n",
        "# Define model interface\n",
        "class JoeyNMTModel:\n",
        "    '''\n",
        "    JoeyNMTModel which load JoeyNMT model for inference.\n",
        "\n",
        "    :param config_path: Path to YAML config file\n",
        "    :param n_best: return this many hypotheses, <= beam (currently only 1)\n",
        "    '''\n",
        "    def __init__(self, config_path: str, n_best: int = 1):\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "        cfg = load_config(config_path)\n",
        "        args = parse_global_args(cfg, rank=0, mode=\"translate\")\n",
        "        self.args = args._replace(test=args.test._replace(n_best=n_best))\n",
        "        # build model\n",
        "        self.model, _, _, self.test_data = prepare(self.args, rank=0, mode=\"translate\")\n",
        "\n",
        "    def _translate_data(self):\n",
        "        _, _, hypotheses, trg_tokens, trg_scores, _ = predict(\n",
        "            model=self.model,\n",
        "            data=self.test_data,\n",
        "            compute_loss=False,\n",
        "            device=self.args.device,\n",
        "            rank=0,\n",
        "            n_gpu=self.args.n_gpu,\n",
        "            normalization=\"none\",\n",
        "            num_workers=self.args.num_workers,\n",
        "            args=self.args.test,\n",
        "            autocast=self.args.autocast,\n",
        "        )\n",
        "        return hypotheses, trg_tokens, trg_scores\n",
        "\n",
        "    def translate(self, sentence) -> list:\n",
        "        '''\n",
        "        Translate the given sentence.\n",
        "\n",
        "        :param sentence: Sentence to be translated\n",
        "        :return:\n",
        "        - translations: (list of str) possible translations of the sentence.\n",
        "        '''\n",
        "        self.test_data.set_item(sentence.strip())\n",
        "        translations, _, _ = self._translate_data()\n",
        "        assert len(translations) == len(self.test_data) * self.args.test.n_best\n",
        "        self.test_data.reset_cache()\n",
        "        return translations\n",
        "\n",
        "# Load model\n",
        "config_path = \"/path/to/lean_model/config_local.yaml\" # Change this to the path to your model congig file\n",
        "model = JoeyNMTModel(config_path=config_path, n_best=1)\n",
        "\n",
        "# Translate\n",
        "model.translate(sentence=\"i tɔgɔ bi cogodɔ\")\n",
        "```\n",
        "\n",
        "## Training procedure\n",
        "\n",
        "### Training hyperparameters\n",
        "\n",
        "More information needed\n",
        "\n",
        "### Training results\n",
        "\n",
        "More information needed\n",
        "\n",
        "### Framework versions\n",
        "\n",
        "- JoeyNMT {joeynmt.__version__}\n",
        "- Torch {torch.__version__}\n",
        "\n",
        "\"\"\"\n",
        "with (Path(lean_model_dir) / \"README.md\").open('w') as f:\n",
        "    f.write(model_card)\n",
        "\n",
        "\n",
        "# List files in the model directory (lean_model)\n",
        "files = []\n",
        "for filename in os.listdir(lean_model_dir):\n",
        "    filepath = os.path.join(lean_model_dir, filename)\n",
        "    if os.path.isfile(filepath):\n",
        "        files.append(Path(filepath))\n",
        "\n",
        "files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254,
          "referenced_widgets": [
            "d99e094425694ff0a692969243ba06ca",
            "b87083d44c70476ab5bc341a7bec44d2",
            "f74de680121f4be781dade77276440ff",
            "583ca8108d6545a499f2b191b1244ca1",
            "ae8df8c2adda4d90948a0858442611db",
            "5263539797e1431082f75ed7a7b6c383",
            "4b04101b30ec4454ab7c3a6989791ab6",
            "f9919c260c2b4d97bc3beac61dd27b63",
            "7c7a387a1bf64ed5a5f2c8b3f7c3d054",
            "fba79780265946c58eaa3e78531359fa",
            "dfd7e87c25f24fbca129b4594d0f9947",
            "1fe5dc523e954dcbaf93bbd0e5ea25e2",
            "7097df83ac064028a3117a9d835032dd",
            "980c9f97ef064f18a209248e97ee46af",
            "d39df1fd08e344ab8c7576079f6e34c7",
            "a126a48fc1944801a32f65bebd5cae31",
            "47d15b6962e945f79b6bcb34818821ac",
            "2cb80ae3322e433fba1be42b48339aab",
            "e6fdc3b7fca7444ba4b39b4d667f9265",
            "94d0061c4504429d9cfac89e97edb392",
            "5a18c2f950b044079430c7e4946e48a5",
            "6bb4f1108cb1431484f6b0320d33b286"
          ]
        },
        "id": "IYZI7jFG6I9P",
        "outputId": "91b73e8f-005c-4b9c-fae0-ef6e28c1cec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best.ckpt\n",
            "/content/lean_model/best.ckpt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "best.ckpt:   0%|          | 0.00/124M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d99e094425694ff0a692969243ba06ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sp.model\n",
            "/content/lean_model/sp.model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sp.model:   0%|          | 0.00/269k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fe5dc523e954dcbaf93bbd0e5ea25e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.yaml\n",
            "/content/lean_model/config.yaml\n",
            "vocab.txt\n",
            "/content/lean_model/vocab.txt\n",
            "README.md\n",
            "/content/lean_model/README.md\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for file_path in files:\n",
        "    print(file_path.name)\n",
        "    print(str(file_path))\n",
        "    api.upload_file(\n",
        "        path_or_fileobj=file_path,\n",
        "        path_in_repo=file_path.name,\n",
        "        repo_id=HF_REPO_NAME,\n",
        "\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-02Jw_8Bnrb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "86cbb6199ac846b5861864442270b806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69bb9ccecf6f4dc39e95afc53b064808",
              "IPY_MODEL_d2a9aa16a0954a70b069da16f22d75a1",
              "IPY_MODEL_e68e0ca02cc04a9689fc5a6b8159a0b0"
            ],
            "layout": "IPY_MODEL_7df9b6cfb56b480c8e8830fe159eab72"
          }
        },
        "69bb9ccecf6f4dc39e95afc53b064808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc9977e85e2044c389cf494bfd2e8e10",
            "placeholder": "​",
            "style": "IPY_MODEL_dccc0e8f2a0142eda729369cb77a4052",
            "value": "Downloading data: 100%"
          }
        },
        "d2a9aa16a0954a70b069da16f22d75a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcdd4e34a03e462296e7c19448a09b24",
            "max": 529641,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_373f924c5e7c4571b5d2924f3dd6e0e2",
            "value": 529641
          }
        },
        "e68e0ca02cc04a9689fc5a6b8159a0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24addc98f168445d8cb78615e46e17b9",
            "placeholder": "​",
            "style": "IPY_MODEL_6f36ac6d938f4622a1db82540d4ade79",
            "value": " 530k/530k [00:00&lt;00:00, 1.09MB/s]"
          }
        },
        "7df9b6cfb56b480c8e8830fe159eab72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc9977e85e2044c389cf494bfd2e8e10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dccc0e8f2a0142eda729369cb77a4052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcdd4e34a03e462296e7c19448a09b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "373f924c5e7c4571b5d2924f3dd6e0e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24addc98f168445d8cb78615e46e17b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f36ac6d938f4622a1db82540d4ade79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae079020874c4143ac2c91e81b7faa96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6bf4795f6984148938b5c9ea12fc2bb",
              "IPY_MODEL_3647bc3efc254a20b53c1d7ce24d615a",
              "IPY_MODEL_4db51b73bb6b4e97aa4b44274a46c6d7"
            ],
            "layout": "IPY_MODEL_da759690f2124d43bd2e35accaf42ddb"
          }
        },
        "e6bf4795f6984148938b5c9ea12fc2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f77d9504e69459bbbb44235d690b759",
            "placeholder": "​",
            "style": "IPY_MODEL_4893f3c1154343e5a6015440cfde2927",
            "value": "Downloading data: 100%"
          }
        },
        "3647bc3efc254a20b53c1d7ce24d615a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b399fd9d8ceb4a7f9a4daf53afeffacb",
            "max": 102335,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db16357f666645be97a15853183acfdd",
            "value": 102335
          }
        },
        "4db51b73bb6b4e97aa4b44274a46c6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a44407b5aedc41f7adc35b72abc4d073",
            "placeholder": "​",
            "style": "IPY_MODEL_91583a4064334fd99f0454ac88dd1e37",
            "value": " 102k/102k [00:00&lt;00:00, 283kB/s]"
          }
        },
        "da759690f2124d43bd2e35accaf42ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f77d9504e69459bbbb44235d690b759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4893f3c1154343e5a6015440cfde2927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b399fd9d8ceb4a7f9a4daf53afeffacb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db16357f666645be97a15853183acfdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a44407b5aedc41f7adc35b72abc4d073": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91583a4064334fd99f0454ac88dd1e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3edb51310aa04a29b713236f5f005831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e810a4cdfca043878721bcd7b38d33bd",
              "IPY_MODEL_426a3c81b39b4428bb355be1f4b77e40",
              "IPY_MODEL_8816f715061d48ef9e563442dd73d913"
            ],
            "layout": "IPY_MODEL_dd89f762cd3a46baa14d36f79c9a2183"
          }
        },
        "e810a4cdfca043878721bcd7b38d33bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_630e98380a0b493b9a4c34dc5322dd89",
            "placeholder": "​",
            "style": "IPY_MODEL_2fed48365faf4feba1f441d7f77d59ad",
            "value": "Downloading data: 100%"
          }
        },
        "426a3c81b39b4428bb355be1f4b77e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_071b00ee9b784232a68e7b35b3939d4a",
            "max": 55816,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4427de5f34e94bc28b97b72e7b62acdc",
            "value": 55816
          }
        },
        "8816f715061d48ef9e563442dd73d913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81725190ebfb47a39f3c0d69b6a3bc4c",
            "placeholder": "​",
            "style": "IPY_MODEL_4526b28abb194675bbb7ce410b1cef46",
            "value": " 55.8k/55.8k [00:00&lt;00:00, 157kB/s]"
          }
        },
        "dd89f762cd3a46baa14d36f79c9a2183": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "630e98380a0b493b9a4c34dc5322dd89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fed48365faf4feba1f441d7f77d59ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "071b00ee9b784232a68e7b35b3939d4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4427de5f34e94bc28b97b72e7b62acdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81725190ebfb47a39f3c0d69b6a3bc4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4526b28abb194675bbb7ce410b1cef46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "623a038d4e92438699a13844e617e453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d1960f96ac348159f625044d3cea888",
              "IPY_MODEL_8e901e515d3843898462ee1d83b42875",
              "IPY_MODEL_e352b51563d64e4fb748cdbbcc625e51"
            ],
            "layout": "IPY_MODEL_35017c855e7448d89485bdda5755b06e"
          }
        },
        "3d1960f96ac348159f625044d3cea888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d8ecbfa860b4ee79a8926bf9ef5f2a7",
            "placeholder": "​",
            "style": "IPY_MODEL_3bfc7b87c278422f8c6e446e8276cae6",
            "value": "Generating train split: 100%"
          }
        },
        "8e901e515d3843898462ee1d83b42875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_573bd90b1b944cfca0a0fe1ddb463a1d",
            "max": 8065,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eff289ef73294778adbbf82d10ae4308",
            "value": 8065
          }
        },
        "e352b51563d64e4fb748cdbbcc625e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c51d04ec8a9e464793980f8aee69e2ba",
            "placeholder": "​",
            "style": "IPY_MODEL_d207c6d2fa7d4203bb04a190d474f00c",
            "value": " 8065/8065 [00:00&lt;00:00, 9886.89 examples/s]"
          }
        },
        "35017c855e7448d89485bdda5755b06e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d8ecbfa860b4ee79a8926bf9ef5f2a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bfc7b87c278422f8c6e446e8276cae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "573bd90b1b944cfca0a0fe1ddb463a1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eff289ef73294778adbbf82d10ae4308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c51d04ec8a9e464793980f8aee69e2ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d207c6d2fa7d4203bb04a190d474f00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33d693b5c9714c0da9f175a3c9a9c794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0ac7bd53caa4e319d7454f6c5aa9447",
              "IPY_MODEL_2dbf0a4b3e0045a3b2fe6e9f941c42fb",
              "IPY_MODEL_65f83541b6c74adba1311b3eb7f3179b"
            ],
            "layout": "IPY_MODEL_6729822c2b34464eb2d28b30e6e83b86"
          }
        },
        "e0ac7bd53caa4e319d7454f6c5aa9447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99cf1c76dcec48c4bed435757a1b7338",
            "placeholder": "​",
            "style": "IPY_MODEL_387dec4d234f45af8a02cd067932cc79",
            "value": "Generating validation split: 100%"
          }
        },
        "2dbf0a4b3e0045a3b2fe6e9f941c42fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6e167671e2145c2a9e283acb8ceeb16",
            "max": 1471,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94087d97c42543bb86f5e7be5a7ad80d",
            "value": 1471
          }
        },
        "65f83541b6c74adba1311b3eb7f3179b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28e04156d2f54a41922e4ad7d7afc99d",
            "placeholder": "​",
            "style": "IPY_MODEL_a01d986036214cac9f7989ec49d19893",
            "value": " 1471/1471 [00:00&lt;00:00, 13984.47 examples/s]"
          }
        },
        "6729822c2b34464eb2d28b30e6e83b86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99cf1c76dcec48c4bed435757a1b7338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387dec4d234f45af8a02cd067932cc79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6e167671e2145c2a9e283acb8ceeb16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94087d97c42543bb86f5e7be5a7ad80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28e04156d2f54a41922e4ad7d7afc99d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a01d986036214cac9f7989ec49d19893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e29e09b9ad749f5b66707e028684611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4dbd12987bf496c9f00157b05564099",
              "IPY_MODEL_e0443c2722b5469b9f00eaca30e9fa9f",
              "IPY_MODEL_5d312dcb91e04cdeb6d7e4a4b78c2eda"
            ],
            "layout": "IPY_MODEL_1117d668a4684f65b536624a1f4e3106"
          }
        },
        "c4dbd12987bf496c9f00157b05564099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d116fa0e2e7141fd85404e193e2561ec",
            "placeholder": "​",
            "style": "IPY_MODEL_7751aee579914082bab027e87b665e66",
            "value": "Generating test split: 100%"
          }
        },
        "e0443c2722b5469b9f00eaca30e9fa9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff411ac53e9a4f0eaba98eacbc33ec0c",
            "max": 1393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94a3a1b8455c411687321bedcf7aa342",
            "value": 1393
          }
        },
        "5d312dcb91e04cdeb6d7e4a4b78c2eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_847adcc5cd2f4db0a34b60514716f5a8",
            "placeholder": "​",
            "style": "IPY_MODEL_86755e977ea94e4f912e8c36e2b4e5da",
            "value": " 1393/1393 [00:00&lt;00:00, 11795.31 examples/s]"
          }
        },
        "1117d668a4684f65b536624a1f4e3106": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d116fa0e2e7141fd85404e193e2561ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7751aee579914082bab027e87b665e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff411ac53e9a4f0eaba98eacbc33ec0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94a3a1b8455c411687321bedcf7aa342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "847adcc5cd2f4db0a34b60514716f5a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86755e977ea94e4f912e8c36e2b4e5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa15cfc20a894267a4841aa955b03ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba47051858564a199e6fd093d348642b",
              "IPY_MODEL_64bc479d01974ce7ae345f216827cd50",
              "IPY_MODEL_6b29e289b162455880fd15f405203c1c"
            ],
            "layout": "IPY_MODEL_f791aa5f5b114ef192f44873ecb19786"
          }
        },
        "ba47051858564a199e6fd093d348642b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36977cb95f044eb398561dc83cf1409a",
            "placeholder": "​",
            "style": "IPY_MODEL_79791f011a1b4abbb4201c2a0ec1bd3f",
            "value": "Map: 100%"
          }
        },
        "64bc479d01974ce7ae345f216827cd50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b9fa7b41107439087bd21a4e5786284",
            "max": 8065,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec6744a933ca4c47be5628aca6206b88",
            "value": 8065
          }
        },
        "6b29e289b162455880fd15f405203c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_772acad5b27c4a08bef3c60707cfe422",
            "placeholder": "​",
            "style": "IPY_MODEL_7131e12f433247c6903fcb29301a3c36",
            "value": " 8065/8065 [00:00&lt;00:00, 11054.64 examples/s]"
          }
        },
        "f791aa5f5b114ef192f44873ecb19786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36977cb95f044eb398561dc83cf1409a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79791f011a1b4abbb4201c2a0ec1bd3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b9fa7b41107439087bd21a4e5786284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec6744a933ca4c47be5628aca6206b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "772acad5b27c4a08bef3c60707cfe422": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7131e12f433247c6903fcb29301a3c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffbdbe21815a46f78b1ec91f96c8b3d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ad7634d658f40f0b65a45f05a613f1b",
              "IPY_MODEL_2a38c62642e84a02864232ca5b121942",
              "IPY_MODEL_e2eba9e03aac466ba19ef17097075aba"
            ],
            "layout": "IPY_MODEL_e579da44bf8d42f589d005cd289d0e72"
          }
        },
        "8ad7634d658f40f0b65a45f05a613f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9f03291baeb4d5c93d4e4f01832d9e5",
            "placeholder": "​",
            "style": "IPY_MODEL_cfab66060b5b4ab2bc86b0348ebf5d6d",
            "value": "Map: 100%"
          }
        },
        "2a38c62642e84a02864232ca5b121942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1102eddd6c2d47c9a9cefa1f0544c546",
            "max": 1471,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ee8bfda0ded4d12bdc880c67aed6859",
            "value": 1471
          }
        },
        "e2eba9e03aac466ba19ef17097075aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ccbe560ab3f4e48be1f786d2d0f6561",
            "placeholder": "​",
            "style": "IPY_MODEL_83d8090070d242f181ed637902768d94",
            "value": " 1471/1471 [00:00&lt;00:00, 8995.72 examples/s]"
          }
        },
        "e579da44bf8d42f589d005cd289d0e72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9f03291baeb4d5c93d4e4f01832d9e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfab66060b5b4ab2bc86b0348ebf5d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1102eddd6c2d47c9a9cefa1f0544c546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ee8bfda0ded4d12bdc880c67aed6859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ccbe560ab3f4e48be1f786d2d0f6561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83d8090070d242f181ed637902768d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b6eb0ac55a64643a797d3c9ef13b72f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcb1c133d7904f938eaf0bfeae629cd6",
              "IPY_MODEL_e1a77f01f25b4e33ae09a2363dab7910",
              "IPY_MODEL_65e95854622340e6adcfca1ab9224019"
            ],
            "layout": "IPY_MODEL_39dc4ff2b3bb42298ff475348e5a7682"
          }
        },
        "bcb1c133d7904f938eaf0bfeae629cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdee8c1ae7a24db4b94a3db6df2d4aeb",
            "placeholder": "​",
            "style": "IPY_MODEL_f88fbeb447f5460bbddb157c3b4f435d",
            "value": "Map: 100%"
          }
        },
        "e1a77f01f25b4e33ae09a2363dab7910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c7b0d689f0046c995cc0638af7fc51d",
            "max": 1393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2ca69b411194b2ba3821a6df7fedb99",
            "value": 1393
          }
        },
        "65e95854622340e6adcfca1ab9224019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74581617f4bf403abb18e152ab7e9b97",
            "placeholder": "​",
            "style": "IPY_MODEL_b7c62b580a29456b8d3069b20833afc8",
            "value": " 1393/1393 [00:00&lt;00:00, 10943.06 examples/s]"
          }
        },
        "39dc4ff2b3bb42298ff475348e5a7682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdee8c1ae7a24db4b94a3db6df2d4aeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f88fbeb447f5460bbddb157c3b4f435d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c7b0d689f0046c995cc0638af7fc51d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ca69b411194b2ba3821a6df7fedb99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74581617f4bf403abb18e152ab7e9b97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7c62b580a29456b8d3069b20833afc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ddf2f51eaa24d8a8c5f6de2510647bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_240800939b2a4ffeb320e0266e223753",
              "IPY_MODEL_d2b84a8d88d74329b3e65d468cfb78fb",
              "IPY_MODEL_478f20b743b8400185a791989b2adcf4"
            ],
            "layout": "IPY_MODEL_7fef453d44ae41a49703a64497e21635"
          }
        },
        "240800939b2a4ffeb320e0266e223753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b4eb33aa693476a95bf8fc8ea80a283",
            "placeholder": "​",
            "style": "IPY_MODEL_f70f0df417c64fa89a42b5ae76226290",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "d2b84a8d88d74329b3e65d468cfb78fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2eabb820d734461ad1f41e783722343",
            "max": 8065,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71ca769d80794cccbc901fc16ba942a1",
            "value": 8065
          }
        },
        "478f20b743b8400185a791989b2adcf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb298804b0254e8e9f334805522f1149",
            "placeholder": "​",
            "style": "IPY_MODEL_b03a0a9c2393413a976a95c66c393486",
            "value": " 8065/8065 [00:00&lt;00:00, 237591.30 examples/s]"
          }
        },
        "7fef453d44ae41a49703a64497e21635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b4eb33aa693476a95bf8fc8ea80a283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f70f0df417c64fa89a42b5ae76226290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2eabb820d734461ad1f41e783722343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71ca769d80794cccbc901fc16ba942a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb298804b0254e8e9f334805522f1149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b03a0a9c2393413a976a95c66c393486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06db7dfe0782498fac01a7635bbfdbf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc670536a52e46269f011ce1f2271555",
              "IPY_MODEL_8f998966e69e4994a49e0fafbdfebf22",
              "IPY_MODEL_afc8e6b0241d4f7c92ed864bb18d2c34"
            ],
            "layout": "IPY_MODEL_696a2018f5204338aabff0d85aa8e003"
          }
        },
        "cc670536a52e46269f011ce1f2271555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbeb089342434da0bc5b376cd1e2bbbd",
            "placeholder": "​",
            "style": "IPY_MODEL_84fa6d0eef6c430292a615e1f18b6fef",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "8f998966e69e4994a49e0fafbdfebf22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9dbf7a8aba242f89d72cb41af6ea387",
            "max": 1471,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b1e72e496cf41be8872b04d0299eb11",
            "value": 1471
          }
        },
        "afc8e6b0241d4f7c92ed864bb18d2c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56362e99caec4c4380f90e14992fe2cf",
            "placeholder": "​",
            "style": "IPY_MODEL_b018d74742f148fb97e5a13eefab48f4",
            "value": " 1471/1471 [00:00&lt;00:00, 32959.15 examples/s]"
          }
        },
        "696a2018f5204338aabff0d85aa8e003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbeb089342434da0bc5b376cd1e2bbbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84fa6d0eef6c430292a615e1f18b6fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9dbf7a8aba242f89d72cb41af6ea387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b1e72e496cf41be8872b04d0299eb11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56362e99caec4c4380f90e14992fe2cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b018d74742f148fb97e5a13eefab48f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00cafe5ca9264bd29841bd9a6aa898c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39edee19f06242169f97ffe984645356",
              "IPY_MODEL_78630c5e278d45fc90b1d70aea78bcab",
              "IPY_MODEL_b586c5fd617346adaa9e026026dff16e"
            ],
            "layout": "IPY_MODEL_cea2c8fe3a3d43d1a3b273690dc211d9"
          }
        },
        "39edee19f06242169f97ffe984645356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d276bbab303c4f4e979df1348489aee4",
            "placeholder": "​",
            "style": "IPY_MODEL_fec580d4cca946e190c8b4c98357bf15",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "78630c5e278d45fc90b1d70aea78bcab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_715dd252373c439290474d619a27efe0",
            "max": 1393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1d7f65a4fae4752a16f087be6e2a5a8",
            "value": 1393
          }
        },
        "b586c5fd617346adaa9e026026dff16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6b23e5318c04f71b7b5627a671c1f82",
            "placeholder": "​",
            "style": "IPY_MODEL_25d6b2b1a41143f0b589017be5a564cc",
            "value": " 1393/1393 [00:00&lt;00:00, 41616.50 examples/s]"
          }
        },
        "cea2c8fe3a3d43d1a3b273690dc211d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d276bbab303c4f4e979df1348489aee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fec580d4cca946e190c8b4c98357bf15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "715dd252373c439290474d619a27efe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1d7f65a4fae4752a16f087be6e2a5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6b23e5318c04f71b7b5627a671c1f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25d6b2b1a41143f0b589017be5a564cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8e3a3f72e8943e3a4d62ff119e67625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8ff644d4bcf4d9aad6652df255461b1",
              "IPY_MODEL_fe12e916304044e1948b26fc0c650a83",
              "IPY_MODEL_2d6ed5077ec949cd95bdfe9ff5763f96",
              "IPY_MODEL_0f644e3c45e1462dad8754f338f3e8bc",
              "IPY_MODEL_6a55f0d2df344903aa4e783f3cb73463"
            ],
            "layout": "IPY_MODEL_7d551f3a8c194018a3a1984414d67dd5"
          }
        },
        "f8ff644d4bcf4d9aad6652df255461b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_685382331bbc4d5a8f04a26e905818f7",
            "placeholder": "​",
            "style": "IPY_MODEL_65dbdb71d42748d4a3ebaac097c3118c",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "fe12e916304044e1948b26fc0c650a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9fed4bbdc5de44ebb6d4bc27c0001561",
            "placeholder": "​",
            "style": "IPY_MODEL_47ed62a50f8140ef9f4f0052d78a1a71",
            "value": ""
          }
        },
        "2d6ed5077ec949cd95bdfe9ff5763f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_b6479a952cd44f84be0a1714aa5584b5",
            "style": "IPY_MODEL_54f9d641b6794f86ba37d28ff1c51445",
            "value": true
          }
        },
        "0f644e3c45e1462dad8754f338f3e8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_696aaf1f393449b5a9a5c1e039e76d33",
            "style": "IPY_MODEL_72fba3ad8ade45f9931cce9ceba91f2f",
            "tooltip": ""
          }
        },
        "6a55f0d2df344903aa4e783f3cb73463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eb8cc5c969046eab4093ff15ee48714",
            "placeholder": "​",
            "style": "IPY_MODEL_54ae13f47a234ab5bc4fed43aa377068",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "7d551f3a8c194018a3a1984414d67dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "685382331bbc4d5a8f04a26e905818f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65dbdb71d42748d4a3ebaac097c3118c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fed4bbdc5de44ebb6d4bc27c0001561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47ed62a50f8140ef9f4f0052d78a1a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6479a952cd44f84be0a1714aa5584b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54f9d641b6794f86ba37d28ff1c51445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "696aaf1f393449b5a9a5c1e039e76d33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72fba3ad8ade45f9931cce9ceba91f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "4eb8cc5c969046eab4093ff15ee48714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54ae13f47a234ab5bc4fed43aa377068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d99e094425694ff0a692969243ba06ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b87083d44c70476ab5bc341a7bec44d2",
              "IPY_MODEL_f74de680121f4be781dade77276440ff",
              "IPY_MODEL_583ca8108d6545a499f2b191b1244ca1"
            ],
            "layout": "IPY_MODEL_ae8df8c2adda4d90948a0858442611db"
          }
        },
        "b87083d44c70476ab5bc341a7bec44d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5263539797e1431082f75ed7a7b6c383",
            "placeholder": "​",
            "style": "IPY_MODEL_4b04101b30ec4454ab7c3a6989791ab6",
            "value": "best.ckpt: 100%"
          }
        },
        "f74de680121f4be781dade77276440ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9919c260c2b4d97bc3beac61dd27b63",
            "max": 124079502,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c7a387a1bf64ed5a5f2c8b3f7c3d054",
            "value": 124079502
          }
        },
        "583ca8108d6545a499f2b191b1244ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fba79780265946c58eaa3e78531359fa",
            "placeholder": "​",
            "style": "IPY_MODEL_dfd7e87c25f24fbca129b4594d0f9947",
            "value": " 124M/124M [00:05&lt;00:00, 31.7MB/s]"
          }
        },
        "ae8df8c2adda4d90948a0858442611db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5263539797e1431082f75ed7a7b6c383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b04101b30ec4454ab7c3a6989791ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9919c260c2b4d97bc3beac61dd27b63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c7a387a1bf64ed5a5f2c8b3f7c3d054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fba79780265946c58eaa3e78531359fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfd7e87c25f24fbca129b4594d0f9947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fe5dc523e954dcbaf93bbd0e5ea25e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7097df83ac064028a3117a9d835032dd",
              "IPY_MODEL_980c9f97ef064f18a209248e97ee46af",
              "IPY_MODEL_d39df1fd08e344ab8c7576079f6e34c7"
            ],
            "layout": "IPY_MODEL_a126a48fc1944801a32f65bebd5cae31"
          }
        },
        "7097df83ac064028a3117a9d835032dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47d15b6962e945f79b6bcb34818821ac",
            "placeholder": "​",
            "style": "IPY_MODEL_2cb80ae3322e433fba1be42b48339aab",
            "value": "sp.model: 100%"
          }
        },
        "980c9f97ef064f18a209248e97ee46af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6fdc3b7fca7444ba4b39b4d667f9265",
            "max": 269406,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94d0061c4504429d9cfac89e97edb392",
            "value": 269406
          }
        },
        "d39df1fd08e344ab8c7576079f6e34c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a18c2f950b044079430c7e4946e48a5",
            "placeholder": "​",
            "style": "IPY_MODEL_6bb4f1108cb1431484f6b0320d33b286",
            "value": " 269k/269k [00:00&lt;00:00, 1.12MB/s]"
          }
        },
        "a126a48fc1944801a32f65bebd5cae31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47d15b6962e945f79b6bcb34818821ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cb80ae3322e433fba1be42b48339aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6fdc3b7fca7444ba4b39b4d667f9265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94d0061c4504429d9cfac89e97edb392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a18c2f950b044079430c7e4946e48a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bb4f1108cb1431484f6b0320d33b286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}